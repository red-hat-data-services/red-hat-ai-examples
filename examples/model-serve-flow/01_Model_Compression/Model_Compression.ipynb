{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7375209-d552-4543-9e7f-1c9a03117314",
   "metadata": {},
   "source": [
    "## Compress the Base LLM using LLM Compressor:\n",
    "In this step, a Large Language Model(which we refere to as the base model for this use case) is compressed to reduce its memory footprint and improve inference efficiency without significantly impacting accuracy. We will be using data-aware quantization.\n",
    "\n",
    "**Goal**: Reduce model size (e.g., FP16 → INT8/INT4) while retaining performance.\n",
    "\n",
    "**Key Actions**:\n",
    "\n",
    "- Load the base model.\n",
    "\n",
    "- Measure its size and memory usage.\n",
    "\n",
    "- Use a calibration dataset (e.g., WikiText, UltraChat) to collect activation statistics.\n",
    "\n",
    "- Apply a quantization recipe (e.g., SmoothQuant + GPTQ modifier).\n",
    "\n",
    "- Save the compressed model and verify size reduction.\n",
    "\n",
    "**Outcome**:\n",
    "\n",
    "- Compressed model saved on disk.\n",
    "\n",
    "- Model size reduced, typically by 50% (depending on quantization scheme)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7d76ec6-9bab-4a4b-bda8-0e5663510937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from llmcompressor import oneshot\n",
    "from llmcompressor.modifiers.quantization import GPTQModifier\n",
    "from llmcompressor.modifiers.smoothquant import SmoothQuantModifier\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from utils import model_size_gb, tokenize_for_calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0bb9620-ca7b-44e4-bc75-b2de8bd992c1",
   "metadata": {
    "tags": [
     "parameters",
     "keep_output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check available device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6585cb-614e-403b-beb1-36a9c03f66b8",
   "metadata": {},
   "source": [
    "### Loading Base Model\n",
    "You can use the model of your choice by modifying the `model_name` variable.\n",
    "While loading the model using **from_pretrained** using transformers' **AutoModelForCausalLM** class, we specify the data type using the **torch_dtype** parameter and set it to **auto** so the model is loaded in the data type specified in its config.\n",
    "Otherwise, PyTorch loads the weights in **full precision (fp32)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "799031ae-0932-4924-86e6-68d7917c482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up variables\n",
    "model_name = \"RedHatAI/Llama-3.1-8B-Instruct\"\n",
    "base_model_path = \"../base_model\"\n",
    "compressed_model_path = \"../Llama_3.1_8B_Instruct_int8_dynamic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb655abf-5d22-49e4-b278-eb5d92fa26d5",
   "metadata": {
    "tags": [
     "parameters",
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [02:01<00:00, 30.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model saved at: ../base_model\n"
     ]
    }
   ],
   "source": [
    "# loading model and tokenizer from huggingfaceabs\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "model.config.dtype = \"bfloat16\"\n",
    "# saving model and tokenizer\n",
    "model.save_pretrained(base_model_path)\n",
    "tokenizer.save_pretrained(base_model_path)\n",
    "\n",
    "print(\"Base model saved at:\", base_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5725441f-ed72-44fd-8f6d-8db56b637049",
   "metadata": {
    "tags": [
     "parameters",
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the base model is: 14.9575GB\n"
     ]
    }
   ],
   "source": [
    "# check model size\n",
    "# !du -sh {base_model_path}\n",
    "model_size = model_size_gb(model)\n",
    "print(f\"The size of the base model is: {model_size:.4f}GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701b8093-b984-4d58-a552-65692dc7944c",
   "metadata": {},
   "source": [
    "### Preparing Calibration Dataset\n",
    "\n",
    "Since we are using data-aware quantization to compress the base model, we need a dataset to calibrate the model with real or representative inputs. For the sake of this example, we will use a small, general-purpose dataset for faster processing. Specifically, we use the `wikitext-2-raw-v1` version of the WikiText dataset which is the smaller version.  More information on why to use a calibration dataset is provided in [Compression.md](Compression.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de6dd2e2-58d1-47e8-b17b-2a0d78627e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset to use for calibration\n",
    "dataset_id = \"wikitext\"\n",
    "\n",
    "# Specify the configuration / version of the dataset\n",
    "config = \"wikitext-2-raw-v1\"  # Small version (~2M tokens), raw text format\n",
    "\n",
    "# Set the number of calibration samples based on available device\n",
    "# - On GPU: use more samples to get more accurate activation statistics\n",
    "# - On CPU: reduce samples to prevent memory issues and keep demo fast\n",
    "num_calibration_samples = 512 if device == \"cuda\" else 16\n",
    "\n",
    "# Set the maximum sequence length for calibration\n",
    "max_sequence_length = 1024 if device == \"cuda\" else 16\n",
    "\n",
    "# Load the dataset using Hugging Face Datasets API\n",
    "# This downloads train split of the dataset\n",
    "ds = load_dataset(dataset_id, config, split=\"train\")\n",
    "# Shuffle and grab only the number of samples we need\n",
    "ds = ds.shuffle(seed=42).select(range(num_calibration_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a43b24ce-6980-4aff-937c-e0276eb58a6a",
   "metadata": {
    "tags": [
     "parameters",
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns in the wikitext: ['text']\n",
      "\n",
      "{'text': ' Continuous , short @-@ arc , high pressure xenon arc lamps have a color temperature closely approximating noon sunlight and are used in solar simulators . That is , the chromaticity of these lamps closely approximates a heated black body radiator that has a temperature close to that observed from the Sun . After they were first introduced during the 1940s , these lamps began replacing the shorter @-@ lived carbon arc lamps in movie projectors . They are employed in typical 35mm , IMAX and the new digital projectors film projection systems , automotive HID headlights , high @-@ end \" tactical \" flashlights and other specialized uses . These arc lamps are an excellent source of short wavelength ultraviolet radiation and they have intense emissions in the near infrared , which is used in some night vision systems . \\n'}\n"
     ]
    }
   ],
   "source": [
    "# inspect the dataset\n",
    "print(f\"columns in the {dataset_id}: {ds.column_names}\\n\")\n",
    "print(ds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7e60f8-6420-41aa-91da-266b2ce828c1",
   "metadata": {},
   "source": [
    "**Datset inspection shows the we need to extract column ```text``` and pass it as input to the model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf853df6-2fbd-4a95-ae92-52c7b11577a4",
   "metadata": {},
   "source": [
    "### When to Use a Custom Template for Calibration\n",
    "\n",
    "Use a **custom template** when you want the calibration text to closely mimic the input format your model will see in production.  \n",
    "\n",
    "For example, if your model is **instruction-following** or **chat-based**, providing the template the model was originally trained on or the template that will be used during inference ensures that the activation statistics collected during calibration reflect realistic usage patterns. \n",
    "\n",
    "This can improve the accuracy of quantization and compression.\n",
    "\n",
    "If your model can handle raw text and doesn’t require a specific format, you can rely on the default template instead.\n",
    "\n",
    "A custom template can be provided to the `tokenize_for_calibration` function using the `custom_template` argument. It accepts the following format:\n",
    "\n",
    "```python\n",
    "custom_template = {\n",
    " \"template_text\": \"Instruction: {content}\\nOutput:\", \n",
    " \"placeholder\": \"content\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54934efc-9564-446c-a37b-daf58dcb5ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get activations for the calibration dataset, we need to:\n",
    "# 1. extract the samples from the dataset\n",
    "# 2. tokenize samples in the dataset\n",
    "input_column = \"text\"\n",
    "\n",
    "# Call tokenize_for_calibration using dataset.map\n",
    "tokenized_dataset = ds.map(\n",
    "    lambda batch: tokenize_for_calibration(\n",
    "        examples=batch,  # batch from Hugging Face dataset\n",
    "        input_column=input_column,  # the column containing text to calibrate\n",
    "        tokenizer=tokenizer,  # your Hugging Face tokenizer\n",
    "        max_length=max_sequence_length,  # maximum sequence length\n",
    "        model_type=\"chat\",  # use chat template if no custom template\n",
    "        custom_template=None,  # optional, provide a dict if you want a custom template\n",
    "    ),\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40ea72af-71a5-4cc8-91fc-69bf7b642b45",
   "metadata": {
    "tags": [
     "parameters",
     "keep_output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 512\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5357d71-6eed-40fa-972b-d7e428422414",
   "metadata": {},
   "source": [
    "### Quantizing/Compressing Base Model to INT8\n",
    "After perparing the dataset calibration, we define a recipe for quantization. For quantization scheme `W8A8-INT8`, we use `SmoothQuantModifier` followed by `GPTQModifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d30b5686-60b4-42f1-991a-21260466797c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 133.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:07:34.196038+0000 | reset | INFO - Compression lifecycle reset\n",
      "2025-12-23T12:07:34.198521+0000 | from_modifiers | INFO - Creating recipe from modifiers\n",
      "2025-12-23T12:07:34.199082+0000 | _infer_mappings_from_model | INFO - No SmoothQuantModifier.mappings provided, inferring from model...\n",
      "2025-12-23T12:07:34.239420+0000 | initialize | INFO - Compression lifecycle initialized for 2 modifiers\n",
      "2025-12-23T12:07:34.239866+0000 | IndependentPipeline | INFO - Inferred `SequentialPipeline` for `SmoothQuantModifier`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing cache: 100%|██████████| 512/512 [00:00<00:00, 1023.40it/s]\n",
      "(1/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 134.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:07:38.747525+0000 | _apply_smoothing | INFO - Smoothing with model.layers.0.input_layernorm\n",
      "2025-12-23T12:07:38.754398+0000 | _apply_smoothing | INFO - Smoothing with model.layers.0.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(1/33): Propagating: 100%|██████████| 512/512 [00:04<00:00, 122.48it/s]\n",
      "(2/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 240.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:07:45.311277+0000 | _apply_smoothing | INFO - Smoothing with model.layers.1.input_layernorm\n",
      "2025-12-23T12:07:45.312645+0000 | _apply_smoothing | INFO - Smoothing with model.layers.1.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(2/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.98it/s]\n",
      "(3/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 232.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:07:50.618261+0000 | _apply_smoothing | INFO - Smoothing with model.layers.2.input_layernorm\n",
      "2025-12-23T12:07:50.619709+0000 | _apply_smoothing | INFO - Smoothing with model.layers.2.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(3/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.22it/s]\n",
      "(4/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 243.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:07:55.829023+0000 | _apply_smoothing | INFO - Smoothing with model.layers.3.input_layernorm\n",
      "2025-12-23T12:07:55.830421+0000 | _apply_smoothing | INFO - Smoothing with model.layers.3.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(4/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 165.67it/s]\n",
      "(5/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 239.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:08:01.130480+0000 | _apply_smoothing | INFO - Smoothing with model.layers.4.input_layernorm\n",
      "2025-12-23T12:08:01.131839+0000 | _apply_smoothing | INFO - Smoothing with model.layers.4.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(5/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.39it/s]\n",
      "(6/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 243.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:08:06.328969+0000 | _apply_smoothing | INFO - Smoothing with model.layers.5.input_layernorm\n",
      "2025-12-23T12:08:06.330368+0000 | _apply_smoothing | INFO - Smoothing with model.layers.5.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(6/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.52it/s]\n",
      "(7/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 239.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:08:11.561027+0000 | _apply_smoothing | INFO - Smoothing with model.layers.6.input_layernorm\n",
      "2025-12-23T12:08:11.562346+0000 | _apply_smoothing | INFO - Smoothing with model.layers.6.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(7/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 165.91it/s]\n",
      "(8/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 243.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:08:16.822515+0000 | _apply_smoothing | INFO - Smoothing with model.layers.7.input_layernorm\n",
      "2025-12-23T12:08:16.823819+0000 | _apply_smoothing | INFO - Smoothing with model.layers.7.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(8/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.78it/s]\n",
      "(9/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 243.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:08:22.013711+0000 | _apply_smoothing | INFO - Smoothing with model.layers.8.input_layernorm\n",
      "2025-12-23T12:08:22.015207+0000 | _apply_smoothing | INFO - Smoothing with model.layers.8.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(9/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.67it/s]\n",
      "(10/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 242.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:08:27.361997+0000 | _apply_smoothing | INFO - Smoothing with model.layers.9.input_layernorm\n",
      "2025-12-23T12:08:27.363409+0000 | _apply_smoothing | INFO - Smoothing with model.layers.9.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(10/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.21it/s]\n",
      "(11/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 238.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:08:32.602596+0000 | _apply_smoothing | INFO - Smoothing with model.layers.10.input_layernorm\n",
      "2025-12-23T12:08:32.603757+0000 | _apply_smoothing | INFO - Smoothing with model.layers.10.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(11/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 165.60it/s]\n",
      "(12/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 243.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:08:37.871123+0000 | _apply_smoothing | INFO - Smoothing with model.layers.11.input_layernorm\n",
      "2025-12-23T12:08:37.872475+0000 | _apply_smoothing | INFO - Smoothing with model.layers.11.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(12/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.65it/s]\n",
      "(13/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 243.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:08:43.087272+0000 | _apply_smoothing | INFO - Smoothing with model.layers.12.input_layernorm\n",
      "2025-12-23T12:08:43.088628+0000 | _apply_smoothing | INFO - Smoothing with model.layers.12.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(13/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.57it/s]\n",
      "(14/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 243.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:08:48.301994+0000 | _apply_smoothing | INFO - Smoothing with model.layers.13.input_layernorm\n",
      "2025-12-23T12:08:48.303403+0000 | _apply_smoothing | INFO - Smoothing with model.layers.13.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(14/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.97it/s]\n",
      "(15/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 243.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:08:53.510974+0000 | _apply_smoothing | INFO - Smoothing with model.layers.14.input_layernorm\n",
      "2025-12-23T12:08:53.512378+0000 | _apply_smoothing | INFO - Smoothing with model.layers.14.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(15/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.85it/s]\n",
      "(16/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 243.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:08:58.720903+0000 | _apply_smoothing | INFO - Smoothing with model.layers.15.input_layernorm\n",
      "2025-12-23T12:08:58.722394+0000 | _apply_smoothing | INFO - Smoothing with model.layers.15.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(16/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.66it/s]\n",
      "(17/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 243.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:09:03.935972+0000 | _apply_smoothing | INFO - Smoothing with model.layers.16.input_layernorm\n",
      "2025-12-23T12:09:03.937400+0000 | _apply_smoothing | INFO - Smoothing with model.layers.16.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(17/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.67it/s]\n",
      "(18/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 234.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:09:09.226053+0000 | _apply_smoothing | INFO - Smoothing with model.layers.17.input_layernorm\n",
      "2025-12-23T12:09:09.227494+0000 | _apply_smoothing | INFO - Smoothing with model.layers.17.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(18/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 167.13it/s]\n",
      "(19/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 242.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:09:14.477827+0000 | _apply_smoothing | INFO - Smoothing with model.layers.18.input_layernorm\n",
      "2025-12-23T12:09:14.479131+0000 | _apply_smoothing | INFO - Smoothing with model.layers.18.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(19/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 167.92it/s]\n",
      "(20/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 241.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:09:19.859450+0000 | _apply_smoothing | INFO - Smoothing with model.layers.19.input_layernorm\n",
      "2025-12-23T12:09:19.860851+0000 | _apply_smoothing | INFO - Smoothing with model.layers.19.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(20/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.00it/s]\n",
      "(21/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 241.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:09:25.102287+0000 | _apply_smoothing | INFO - Smoothing with model.layers.20.input_layernorm\n",
      "2025-12-23T12:09:25.103657+0000 | _apply_smoothing | INFO - Smoothing with model.layers.20.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(21/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.03it/s]\n",
      "(22/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 240.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:09:30.484308+0000 | _apply_smoothing | INFO - Smoothing with model.layers.21.input_layernorm\n",
      "2025-12-23T12:09:30.485639+0000 | _apply_smoothing | INFO - Smoothing with model.layers.21.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(22/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 167.43it/s]\n",
      "(23/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 236.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:09:35.784204+0000 | _apply_smoothing | INFO - Smoothing with model.layers.22.input_layernorm\n",
      "2025-12-23T12:09:35.785689+0000 | _apply_smoothing | INFO - Smoothing with model.layers.22.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(23/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 166.24it/s]\n",
      "(24/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 242.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:09:41.049541+0000 | _apply_smoothing | INFO - Smoothing with model.layers.23.input_layernorm\n",
      "2025-12-23T12:09:41.050837+0000 | _apply_smoothing | INFO - Smoothing with model.layers.23.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(24/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.31it/s]\n",
      "(25/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 241.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:09:46.278985+0000 | _apply_smoothing | INFO - Smoothing with model.layers.24.input_layernorm\n",
      "2025-12-23T12:09:46.280485+0000 | _apply_smoothing | INFO - Smoothing with model.layers.24.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(25/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.18it/s]\n",
      "(26/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 241.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:09:51.516310+0000 | _apply_smoothing | INFO - Smoothing with model.layers.25.input_layernorm\n",
      "2025-12-23T12:09:51.517782+0000 | _apply_smoothing | INFO - Smoothing with model.layers.25.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(26/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.04it/s]\n",
      "(27/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 240.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:09:56.760849+0000 | _apply_smoothing | INFO - Smoothing with model.layers.26.input_layernorm\n",
      "2025-12-23T12:09:56.762030+0000 | _apply_smoothing | INFO - Smoothing with model.layers.26.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(27/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 167.89it/s]\n",
      "(28/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 240.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:10:02.007617+0000 | _apply_smoothing | INFO - Smoothing with model.layers.27.input_layernorm\n",
      "2025-12-23T12:10:02.008993+0000 | _apply_smoothing | INFO - Smoothing with model.layers.27.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(28/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 167.78it/s]\n",
      "(29/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 233.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:10:07.329429+0000 | _apply_smoothing | INFO - Smoothing with model.layers.28.input_layernorm\n",
      "2025-12-23T12:10:07.330849+0000 | _apply_smoothing | INFO - Smoothing with model.layers.28.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(29/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 167.38it/s]\n",
      "(30/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 241.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:10:12.579397+0000 | _apply_smoothing | INFO - Smoothing with model.layers.29.input_layernorm\n",
      "2025-12-23T12:10:12.580804+0000 | _apply_smoothing | INFO - Smoothing with model.layers.29.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(30/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.03it/s]\n",
      "(31/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 221.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:10:18.010107+0000 | _apply_smoothing | INFO - Smoothing with model.layers.30.input_layernorm\n",
      "2025-12-23T12:10:18.011450+0000 | _apply_smoothing | INFO - Smoothing with model.layers.30.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(31/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.05it/s]\n",
      "(32/33): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 242.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:10:23.242275+0000 | _apply_smoothing | INFO - Smoothing with model.layers.31.input_layernorm\n",
      "2025-12-23T12:10:23.243548+0000 | _apply_smoothing | INFO - Smoothing with model.layers.31.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(32/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 167.11it/s]\n",
      "(33/33): Calibrating: 100%|██████████| 512/512 [00:00<00:00, 1038.29it/s]\n",
      "(33/33): Propagating: 100%|██████████| 512/512 [00:00<00:00, 1061.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:10:27.581683+0000 | IndependentPipeline | INFO - Inferred `SequentialPipeline` for `GPTQModifier`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing cache: 100%|██████████| 512/512 [00:00<00:00, 1029.82it/s]\n",
      "(1/33): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 46.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:10:39.237411+0000 | compress_modules | INFO - Quantizing model.layers.0.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:10:40.904373+0000 | compress | METRIC - time 1.67s\n",
      "2025-12-23T12:10:40.905254+0000 | compress | METRIC - error 3.32\n",
      "2025-12-23T12:10:40.906182+0000 | compress | METRIC - GPU 0 | usage: 45.36% | total memory: 48 GB\n",
      "2025-12-23T12:10:40.906592+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:10:40.907218+0000 | compress_modules | INFO - Quantizing model.layers.0.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:10:42.423821+0000 | compress | METRIC - time 1.52s\n",
      "2025-12-23T12:10:42.424675+0000 | compress | METRIC - error 2.32\n",
      "2025-12-23T12:10:42.425552+0000 | compress | METRIC - GPU 0 | usage: 45.37% | total memory: 48 GB\n",
      "2025-12-23T12:10:42.425924+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:10:42.426529+0000 | compress_modules | INFO - Quantizing model.layers.0.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:10:43.924826+0000 | compress | METRIC - time 1.50s\n",
      "2025-12-23T12:10:43.925687+0000 | compress | METRIC - error 0.00\n",
      "2025-12-23T12:10:43.926578+0000 | compress | METRIC - GPU 0 | usage: 45.37% | total memory: 48 GB\n",
      "2025-12-23T12:10:43.926957+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:10:43.927636+0000 | compress_modules | INFO - Quantizing model.layers.0.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:10:45.424068+0000 | compress | METRIC - time 1.50s\n",
      "2025-12-23T12:10:45.425080+0000 | compress | METRIC - error 0.00\n",
      "2025-12-23T12:10:45.425757+0000 | compress | METRIC - GPU 0 | usage: 45.37% | total memory: 48 GB\n",
      "2025-12-23T12:10:45.426148+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:10:45.426779+0000 | compress_modules | INFO - Quantizing model.layers.0.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:10:47.045202+0000 | compress | METRIC - time 1.62s\n",
      "2025-12-23T12:10:47.046276+0000 | compress | METRIC - error 0.59\n",
      "2025-12-23T12:10:47.046910+0000 | compress | METRIC - GPU 0 | usage: 45.37% | total memory: 48 GB\n",
      "2025-12-23T12:10:47.047268+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:10:47.047856+0000 | compress_modules | INFO - Quantizing model.layers.0.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:10:48.656894+0000 | compress | METRIC - time 1.61s\n",
      "2025-12-23T12:10:48.657929+0000 | compress | METRIC - error 0.41\n",
      "2025-12-23T12:10:48.658607+0000 | compress | METRIC - GPU 0 | usage: 45.37% | total memory: 48 GB\n",
      "2025-12-23T12:10:48.658957+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:10:48.659685+0000 | compress_modules | INFO - Quantizing model.layers.0.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:10:54.333968+0000 | compress | METRIC - time 5.67s\n",
      "2025-12-23T12:10:54.335923+0000 | compress | METRIC - error 0.00\n",
      "2025-12-23T12:10:54.336752+0000 | compress | METRIC - GPU 0 | usage: 47.07% | total memory: 48 GB\n",
      "2025-12-23T12:10:54.337258+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(1/33): Propagating: 100%|██████████| 512/512 [00:04<00:00, 111.78it/s]\n",
      "(2/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:11:08.871421+0000 | compress_modules | INFO - Quantizing model.layers.1.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:11:10.347786+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:11:10.348676+0000 | compress | METRIC - error 5.00\n",
      "2025-12-23T12:11:10.349493+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:11:10.349891+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:11:10.350498+0000 | compress_modules | INFO - Quantizing model.layers.1.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:11:11.805606+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-23T12:11:11.806633+0000 | compress | METRIC - error 2.87\n",
      "2025-12-23T12:11:11.807520+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:11:11.807912+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:11:11.808564+0000 | compress_modules | INFO - Quantizing model.layers.1.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:11:13.263816+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-23T12:11:13.264532+0000 | compress | METRIC - error 0.03\n",
      "2025-12-23T12:11:13.265176+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:11:13.265540+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:11:13.266177+0000 | compress_modules | INFO - Quantizing model.layers.1.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:11:14.742660+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:11:14.743590+0000 | compress | METRIC - error 0.00\n",
      "2025-12-23T12:11:14.744523+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:11:14.745196+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:11:14.745757+0000 | compress_modules | INFO - Quantizing model.layers.1.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:11:16.304944+0000 | compress | METRIC - time 1.56s\n",
      "2025-12-23T12:11:16.306126+0000 | compress | METRIC - error 0.82\n",
      "2025-12-23T12:11:16.347212+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:11:16.348255+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:11:16.349262+0000 | compress_modules | INFO - Quantizing model.layers.1.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:11:17.911239+0000 | compress | METRIC - time 1.56s\n",
      "2025-12-23T12:11:17.912453+0000 | compress | METRIC - error 0.67\n",
      "2025-12-23T12:11:17.913149+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:11:17.913564+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:11:17.914242+0000 | compress_modules | INFO - Quantizing model.layers.1.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:11:23.450585+0000 | compress | METRIC - time 5.54s\n",
      "2025-12-23T12:11:23.451984+0000 | compress | METRIC - error 0.57\n",
      "2025-12-23T12:11:23.452785+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:11:23.453174+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(2/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 164.24it/s]\n",
      "(3/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 53.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:11:36.289916+0000 | compress_modules | INFO - Quantizing model.layers.2.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:11:37.771473+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:11:37.772295+0000 | compress | METRIC - error 13.90\n",
      "2025-12-23T12:11:37.773313+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:11:37.773950+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:11:37.774558+0000 | compress_modules | INFO - Quantizing model.layers.2.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:11:39.229541+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-23T12:11:39.230578+0000 | compress | METRIC - error 9.68\n",
      "2025-12-23T12:11:39.231461+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:11:39.231854+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:11:39.232474+0000 | compress_modules | INFO - Quantizing model.layers.2.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:11:40.684592+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-23T12:11:40.685414+0000 | compress | METRIC - error 0.14\n",
      "2025-12-23T12:11:40.686465+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:11:40.687053+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:11:40.687710+0000 | compress_modules | INFO - Quantizing model.layers.2.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:11:42.166644+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:11:42.167462+0000 | compress | METRIC - error 0.00\n",
      "2025-12-23T12:11:42.168107+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:11:42.168496+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:11:42.169183+0000 | compress_modules | INFO - Quantizing model.layers.2.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:11:43.730495+0000 | compress | METRIC - time 1.56s\n",
      "2025-12-23T12:11:43.731950+0000 | compress | METRIC - error 1.86\n",
      "2025-12-23T12:11:43.732733+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:11:43.733161+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:11:43.733828+0000 | compress_modules | INFO - Quantizing model.layers.2.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:11:45.310247+0000 | compress | METRIC - time 1.58s\n",
      "2025-12-23T12:11:45.311530+0000 | compress | METRIC - error 1.18\n",
      "2025-12-23T12:11:45.312218+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:11:45.312612+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:11:45.313274+0000 | compress_modules | INFO - Quantizing model.layers.2.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:11:50.826192+0000 | compress | METRIC - time 5.51s\n",
      "2025-12-23T12:11:50.827287+0000 | compress | METRIC - error 0.01\n",
      "2025-12-23T12:11:50.827952+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:11:50.828326+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(3/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 163.25it/s]\n",
      "(4/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 53.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:12:03.674181+0000 | compress_modules | INFO - Quantizing model.layers.3.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:12:05.160691+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:12:05.161599+0000 | compress | METRIC - error 8.63\n",
      "2025-12-23T12:12:05.162469+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:12:05.162857+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:12:05.163496+0000 | compress_modules | INFO - Quantizing model.layers.3.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:12:06.616724+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-23T12:12:06.617630+0000 | compress | METRIC - error 5.41\n",
      "2025-12-23T12:12:06.618425+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:12:06.618786+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:12:06.619396+0000 | compress_modules | INFO - Quantizing model.layers.3.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:12:08.078025+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-23T12:12:08.078885+0000 | compress | METRIC - error 0.21\n",
      "2025-12-23T12:12:08.079564+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:12:08.079942+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:12:08.080569+0000 | compress_modules | INFO - Quantizing model.layers.3.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:12:09.557346+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:12:09.558237+0000 | compress | METRIC - error 0.00\n",
      "2025-12-23T12:12:09.558852+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:12:09.559247+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:12:09.559858+0000 | compress_modules | INFO - Quantizing model.layers.3.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:12:11.130958+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-23T12:12:11.131955+0000 | compress | METRIC - error 3.43\n",
      "2025-12-23T12:12:11.132654+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:12:11.133055+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:12:11.133677+0000 | compress_modules | INFO - Quantizing model.layers.3.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:12:12.703633+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-23T12:12:12.704570+0000 | compress | METRIC - error 1.84\n",
      "2025-12-23T12:12:12.705177+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:12:12.705548+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:12:12.706190+0000 | compress_modules | INFO - Quantizing model.layers.3.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:12:18.192086+0000 | compress | METRIC - time 5.49s\n",
      "2025-12-23T12:12:18.193810+0000 | compress | METRIC - error 0.02\n",
      "2025-12-23T12:12:18.210847+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:12:18.211698+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(4/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 163.10it/s]\n",
      "(5/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 53.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:12:31.043260+0000 | compress_modules | INFO - Quantizing model.layers.4.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:12:32.525574+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:12:32.526477+0000 | compress | METRIC - error 10.70\n",
      "2025-12-23T12:12:32.527250+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:12:32.527634+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:12:32.528230+0000 | compress_modules | INFO - Quantizing model.layers.4.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:12:33.984336+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-23T12:12:33.985320+0000 | compress | METRIC - error 7.13\n",
      "2025-12-23T12:12:33.986290+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:12:33.986827+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:12:33.987494+0000 | compress_modules | INFO - Quantizing model.layers.4.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:12:35.442617+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-23T12:12:35.443597+0000 | compress | METRIC - error 0.22\n",
      "2025-12-23T12:12:35.444453+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:12:35.444871+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:12:35.445614+0000 | compress_modules | INFO - Quantizing model.layers.4.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:12:36.918392+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-23T12:12:36.919660+0000 | compress | METRIC - error 0.02\n",
      "2025-12-23T12:12:36.920234+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:12:36.920588+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:12:36.921333+0000 | compress_modules | INFO - Quantizing model.layers.4.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:12:38.482242+0000 | compress | METRIC - time 1.56s\n",
      "2025-12-23T12:12:38.483210+0000 | compress | METRIC - error 6.41\n",
      "2025-12-23T12:12:38.483849+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:12:38.484250+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:12:38.484846+0000 | compress_modules | INFO - Quantizing model.layers.4.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:12:40.050990+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-23T12:12:40.051954+0000 | compress | METRIC - error 3.10\n",
      "2025-12-23T12:12:40.052629+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:12:40.053030+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:12:40.053642+0000 | compress_modules | INFO - Quantizing model.layers.4.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:12:45.565648+0000 | compress | METRIC - time 5.51s\n",
      "2025-12-23T12:12:45.566660+0000 | compress | METRIC - error 0.03\n",
      "2025-12-23T12:12:45.567594+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:12:45.568230+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(5/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 163.33it/s]\n",
      "(6/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 53.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:12:58.402109+0000 | compress_modules | INFO - Quantizing model.layers.5.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:12:59.889049+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:12:59.889942+0000 | compress | METRIC - error 18.75\n",
      "2025-12-23T12:12:59.890670+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:12:59.891099+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:12:59.891741+0000 | compress_modules | INFO - Quantizing model.layers.5.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:13:01.347087+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-23T12:13:01.347939+0000 | compress | METRIC - error 12.42\n",
      "2025-12-23T12:13:01.348597+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:13:01.348987+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:13:01.349611+0000 | compress_modules | INFO - Quantizing model.layers.5.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:13:02.799307+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-23T12:13:02.800174+0000 | compress | METRIC - error 0.29\n",
      "2025-12-23T12:13:02.801111+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:13:02.801498+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:13:02.802150+0000 | compress_modules | INFO - Quantizing model.layers.5.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:13:04.280615+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:13:04.281688+0000 | compress | METRIC - error 0.01\n",
      "2025-12-23T12:13:04.282436+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:13:04.282812+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:13:04.283463+0000 | compress_modules | INFO - Quantizing model.layers.5.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:13:05.842041+0000 | compress | METRIC - time 1.56s\n",
      "2025-12-23T12:13:05.843068+0000 | compress | METRIC - error 7.90\n",
      "2025-12-23T12:13:05.843679+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:13:05.844203+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:13:05.844995+0000 | compress_modules | INFO - Quantizing model.layers.5.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:13:07.405870+0000 | compress | METRIC - time 1.56s\n",
      "2025-12-23T12:13:07.406861+0000 | compress | METRIC - error 3.77\n",
      "2025-12-23T12:13:07.407556+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:13:07.407942+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:13:07.408567+0000 | compress_modules | INFO - Quantizing model.layers.5.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:13:12.905125+0000 | compress | METRIC - time 5.50s\n",
      "2025-12-23T12:13:12.906368+0000 | compress | METRIC - error 0.06\n",
      "2025-12-23T12:13:12.907497+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:13:12.908222+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(6/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 163.01it/s]\n",
      "(7/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 53.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:13:25.750152+0000 | compress_modules | INFO - Quantizing model.layers.6.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:13:27.262262+0000 | compress | METRIC - time 1.51s\n",
      "2025-12-23T12:13:27.262914+0000 | compress | METRIC - error 15.86\n",
      "2025-12-23T12:13:27.263563+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:13:27.263928+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:13:27.264555+0000 | compress_modules | INFO - Quantizing model.layers.6.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:13:28.738308+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-23T12:13:28.739136+0000 | compress | METRIC - error 11.35\n",
      "2025-12-23T12:13:28.740038+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:13:28.740412+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:13:28.741053+0000 | compress_modules | INFO - Quantizing model.layers.6.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:13:30.215775+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-23T12:13:30.216771+0000 | compress | METRIC - error 0.23\n",
      "2025-12-23T12:13:30.217439+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:13:30.217828+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:13:30.218466+0000 | compress_modules | INFO - Quantizing model.layers.6.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:13:31.708375+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:13:31.709455+0000 | compress | METRIC - error 0.02\n",
      "2025-12-23T12:13:31.710474+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:13:31.711087+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:13:31.712156+0000 | compress_modules | INFO - Quantizing model.layers.6.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:13:33.288634+0000 | compress | METRIC - time 1.58s\n",
      "2025-12-23T12:13:33.289686+0000 | compress | METRIC - error 10.99\n",
      "2025-12-23T12:13:33.290422+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:13:33.290829+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:13:33.291458+0000 | compress_modules | INFO - Quantizing model.layers.6.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:13:34.871207+0000 | compress | METRIC - time 1.58s\n",
      "2025-12-23T12:13:34.872119+0000 | compress | METRIC - error 4.36\n",
      "2025-12-23T12:13:34.872760+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:13:34.873169+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:13:34.873811+0000 | compress_modules | INFO - Quantizing model.layers.6.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:13:40.415943+0000 | compress | METRIC - time 5.54s\n",
      "2025-12-23T12:13:40.417568+0000 | compress | METRIC - error 0.05\n",
      "2025-12-23T12:13:40.418488+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:13:40.418955+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(7/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 162.78it/s]\n",
      "(8/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 53.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:13:53.300860+0000 | compress_modules | INFO - Quantizing model.layers.7.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:13:54.802070+0000 | compress | METRIC - time 1.50s\n",
      "2025-12-23T12:13:54.802831+0000 | compress | METRIC - error 14.81\n",
      "2025-12-23T12:13:54.803759+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:13:54.804193+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:13:54.804819+0000 | compress_modules | INFO - Quantizing model.layers.7.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:13:56.323397+0000 | compress | METRIC - time 1.52s\n",
      "2025-12-23T12:13:56.324450+0000 | compress | METRIC - error 10.28\n",
      "2025-12-23T12:13:56.325232+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:13:56.325640+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:13:56.326349+0000 | compress_modules | INFO - Quantizing model.layers.7.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:13:57.793686+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-23T12:13:57.795023+0000 | compress | METRIC - error 0.30\n",
      "2025-12-23T12:13:57.795682+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:13:57.796078+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:13:57.796686+0000 | compress_modules | INFO - Quantizing model.layers.7.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:13:59.291982+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:13:59.292723+0000 | compress | METRIC - error 0.04\n",
      "2025-12-23T12:13:59.293348+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:13:59.293736+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:13:59.294409+0000 | compress_modules | INFO - Quantizing model.layers.7.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:14:00.874351+0000 | compress | METRIC - time 1.58s\n",
      "2025-12-23T12:14:00.875363+0000 | compress | METRIC - error 11.94\n",
      "2025-12-23T12:14:00.876226+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:14:00.876766+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:14:00.877464+0000 | compress_modules | INFO - Quantizing model.layers.7.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:14:02.462692+0000 | compress | METRIC - time 1.58s\n",
      "2025-12-23T12:14:02.463720+0000 | compress | METRIC - error 5.25\n",
      "2025-12-23T12:14:02.464415+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:14:02.464794+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:14:02.465453+0000 | compress_modules | INFO - Quantizing model.layers.7.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:14:08.059760+0000 | compress | METRIC - time 5.59s\n",
      "2025-12-23T12:14:08.060823+0000 | compress | METRIC - error 0.07\n",
      "2025-12-23T12:14:08.061572+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:14:08.061989+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(8/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 161.86it/s]\n",
      "(9/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:14:21.000789+0000 | compress_modules | INFO - Quantizing model.layers.8.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:14:23.073155+0000 | compress | METRIC - time 2.07s\n",
      "2025-12-23T12:14:23.074038+0000 | compress | METRIC - error 21.65\n",
      "2025-12-23T12:14:23.075208+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:14:23.075858+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:14:23.076814+0000 | compress_modules | INFO - Quantizing model.layers.8.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:14:24.530284+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-23T12:14:24.531211+0000 | compress | METRIC - error 18.99\n",
      "2025-12-23T12:14:24.531973+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:14:24.532357+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:14:24.532953+0000 | compress_modules | INFO - Quantizing model.layers.8.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:14:25.992464+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-23T12:14:25.993365+0000 | compress | METRIC - error 0.39\n",
      "2025-12-23T12:14:25.994587+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:14:25.994948+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:14:25.995584+0000 | compress_modules | INFO - Quantizing model.layers.8.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:14:27.467810+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-23T12:14:27.468757+0000 | compress | METRIC - error 0.07\n",
      "2025-12-23T12:14:27.469375+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:14:27.469838+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:14:27.470858+0000 | compress_modules | INFO - Quantizing model.layers.8.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:14:29.043962+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-23T12:14:29.044721+0000 | compress | METRIC - error 13.91\n",
      "2025-12-23T12:14:29.045433+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:14:29.045832+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:14:29.046553+0000 | compress_modules | INFO - Quantizing model.layers.8.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:14:30.613259+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-23T12:14:30.614336+0000 | compress | METRIC - error 5.80\n",
      "2025-12-23T12:14:30.615477+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:14:30.615852+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:14:30.616488+0000 | compress_modules | INFO - Quantizing model.layers.8.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:14:36.145271+0000 | compress | METRIC - time 5.53s\n",
      "2025-12-23T12:14:36.146261+0000 | compress | METRIC - error 0.08\n",
      "2025-12-23T12:14:36.146798+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:14:36.147201+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(9/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 161.82it/s]\n",
      "(10/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:14:49.161910+0000 | compress_modules | INFO - Quantizing model.layers.9.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:14:50.653531+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:14:50.654639+0000 | compress | METRIC - error 23.30\n",
      "2025-12-23T12:14:50.655481+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:14:50.655932+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:14:50.656653+0000 | compress_modules | INFO - Quantizing model.layers.9.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:14:52.134382+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:14:52.135339+0000 | compress | METRIC - error 22.46\n",
      "2025-12-23T12:14:52.136035+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:14:52.136418+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:14:52.137046+0000 | compress_modules | INFO - Quantizing model.layers.9.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:14:53.595842+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-23T12:14:53.596639+0000 | compress | METRIC - error 0.43\n",
      "2025-12-23T12:14:53.597271+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:14:53.597613+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:14:53.598264+0000 | compress_modules | INFO - Quantizing model.layers.9.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:14:55.080102+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:14:55.081026+0000 | compress | METRIC - error 0.08\n",
      "2025-12-23T12:14:55.081919+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:14:55.082310+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:14:55.083189+0000 | compress_modules | INFO - Quantizing model.layers.9.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:14:56.652146+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-23T12:14:56.653148+0000 | compress | METRIC - error 15.41\n",
      "2025-12-23T12:14:56.653876+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:14:56.654270+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:14:56.654973+0000 | compress_modules | INFO - Quantizing model.layers.9.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:14:58.220104+0000 | compress | METRIC - time 1.56s\n",
      "2025-12-23T12:14:58.221083+0000 | compress | METRIC - error 6.68\n",
      "2025-12-23T12:14:58.222056+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:14:58.222415+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:14:58.223416+0000 | compress_modules | INFO - Quantizing model.layers.9.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:15:03.753440+0000 | compress | METRIC - time 5.53s\n",
      "2025-12-23T12:15:03.754754+0000 | compress | METRIC - error 0.08\n",
      "2025-12-23T12:15:03.755499+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:15:03.755949+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(10/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 161.85it/s]\n",
      "(11/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:15:16.731869+0000 | compress_modules | INFO - Quantizing model.layers.10.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:15:18.223090+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:15:18.223919+0000 | compress | METRIC - error 27.78\n",
      "2025-12-23T12:15:18.224587+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:15:18.224908+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:15:18.225630+0000 | compress_modules | INFO - Quantizing model.layers.10.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:15:19.680368+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-23T12:15:19.681279+0000 | compress | METRIC - error 27.40\n",
      "2025-12-23T12:15:19.681921+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:15:19.682309+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:15:19.682877+0000 | compress_modules | INFO - Quantizing model.layers.10.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:15:21.140530+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-23T12:15:21.141434+0000 | compress | METRIC - error 0.42\n",
      "2025-12-23T12:15:21.142076+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:15:21.142522+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:15:21.143577+0000 | compress_modules | INFO - Quantizing model.layers.10.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:15:22.616764+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-23T12:15:22.617695+0000 | compress | METRIC - error 0.06\n",
      "2025-12-23T12:15:22.742229+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:15:22.743103+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:15:22.744559+0000 | compress_modules | INFO - Quantizing model.layers.10.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:15:24.305430+0000 | compress | METRIC - time 1.56s\n",
      "2025-12-23T12:15:24.306528+0000 | compress | METRIC - error 12.76\n",
      "2025-12-23T12:15:24.307189+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:15:24.307645+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:15:24.308693+0000 | compress_modules | INFO - Quantizing model.layers.10.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:15:25.873057+0000 | compress | METRIC - time 1.56s\n",
      "2025-12-23T12:15:25.874035+0000 | compress | METRIC - error 6.14\n",
      "2025-12-23T12:15:25.874862+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:15:25.875285+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:15:25.876424+0000 | compress_modules | INFO - Quantizing model.layers.10.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:15:31.401707+0000 | compress | METRIC - time 5.52s\n",
      "2025-12-23T12:15:31.403270+0000 | compress | METRIC - error 0.08\n",
      "2025-12-23T12:15:31.404166+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:15:31.404588+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(11/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 162.31it/s]\n",
      "(12/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:15:44.415460+0000 | compress_modules | INFO - Quantizing model.layers.11.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:15:45.909910+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:15:45.910770+0000 | compress | METRIC - error 22.79\n",
      "2025-12-23T12:15:45.911665+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:15:45.912068+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:15:45.912663+0000 | compress_modules | INFO - Quantizing model.layers.11.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:15:47.387206+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-23T12:15:47.388304+0000 | compress | METRIC - error 21.79\n",
      "2025-12-23T12:15:47.389000+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:15:47.389520+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:15:47.390815+0000 | compress_modules | INFO - Quantizing model.layers.11.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:15:48.864465+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-23T12:15:48.865416+0000 | compress | METRIC - error 0.52\n",
      "2025-12-23T12:15:48.866125+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:15:48.866676+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:15:48.867670+0000 | compress_modules | INFO - Quantizing model.layers.11.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:15:50.359411+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:15:50.360485+0000 | compress | METRIC - error 0.07\n",
      "2025-12-23T12:15:50.361350+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:15:50.361794+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:15:50.362431+0000 | compress_modules | INFO - Quantizing model.layers.11.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:15:51.940687+0000 | compress | METRIC - time 1.58s\n",
      "2025-12-23T12:15:51.941694+0000 | compress | METRIC - error 14.09\n",
      "2025-12-23T12:15:51.942461+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:15:51.942894+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:15:51.943570+0000 | compress_modules | INFO - Quantizing model.layers.11.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:15:53.509573+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-23T12:15:53.511114+0000 | compress | METRIC - error 6.97\n",
      "2025-12-23T12:15:53.511974+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:15:53.512585+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:15:53.513220+0000 | compress_modules | INFO - Quantizing model.layers.11.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:15:59.025619+0000 | compress | METRIC - time 5.51s\n",
      "2025-12-23T12:15:59.026696+0000 | compress | METRIC - error 0.12\n",
      "2025-12-23T12:15:59.027361+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:15:59.027831+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(12/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 161.67it/s]\n",
      "(13/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:16:11.994347+0000 | compress_modules | INFO - Quantizing model.layers.12.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:16:13.489105+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:16:13.489990+0000 | compress | METRIC - error 24.04\n",
      "2025-12-23T12:16:13.490716+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:16:13.491122+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:16:13.491749+0000 | compress_modules | INFO - Quantizing model.layers.12.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:16:14.961672+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-23T12:16:14.962611+0000 | compress | METRIC - error 16.54\n",
      "2025-12-23T12:16:14.963576+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:16:14.964310+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:16:14.964868+0000 | compress_modules | INFO - Quantizing model.layers.12.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:16:16.420445+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-23T12:16:16.421737+0000 | compress | METRIC - error 0.57\n",
      "2025-12-23T12:16:16.422431+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:16:16.422822+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:16:16.423446+0000 | compress_modules | INFO - Quantizing model.layers.12.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:16:17.892707+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-23T12:16:17.893593+0000 | compress | METRIC - error 0.08\n",
      "2025-12-23T12:16:17.894512+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:16:17.894877+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:16:17.895501+0000 | compress_modules | INFO - Quantizing model.layers.12.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:16:19.459167+0000 | compress | METRIC - time 1.56s\n",
      "2025-12-23T12:16:19.460200+0000 | compress | METRIC - error 15.90\n",
      "2025-12-23T12:16:19.460864+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:16:19.461305+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:16:19.461948+0000 | compress_modules | INFO - Quantizing model.layers.12.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:16:21.022765+0000 | compress | METRIC - time 1.56s\n",
      "2025-12-23T12:16:21.023763+0000 | compress | METRIC - error 8.46\n",
      "2025-12-23T12:16:21.024726+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:16:21.025120+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:16:21.026230+0000 | compress_modules | INFO - Quantizing model.layers.12.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:16:26.535863+0000 | compress | METRIC - time 5.51s\n",
      "2025-12-23T12:16:26.536756+0000 | compress | METRIC - error 0.11\n",
      "2025-12-23T12:16:26.537449+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:16:26.537837+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(13/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 161.24it/s]\n",
      "(14/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:16:39.532652+0000 | compress_modules | INFO - Quantizing model.layers.13.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:16:41.015143+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:16:41.015991+0000 | compress | METRIC - error 27.85\n",
      "2025-12-23T12:16:41.017078+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:16:41.017481+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:16:41.018128+0000 | compress_modules | INFO - Quantizing model.layers.13.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:16:42.499847+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:16:42.500706+0000 | compress | METRIC - error 40.92\n",
      "2025-12-23T12:16:42.501537+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:16:42.501931+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:16:42.502585+0000 | compress_modules | INFO - Quantizing model.layers.13.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:16:43.997859+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:16:43.998731+0000 | compress | METRIC - error 0.69\n",
      "2025-12-23T12:16:43.999609+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:16:43.999989+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:16:44.000629+0000 | compress_modules | INFO - Quantizing model.layers.13.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:16:45.511184+0000 | compress | METRIC - time 1.51s\n",
      "2025-12-23T12:16:45.512173+0000 | compress | METRIC - error 0.07\n",
      "2025-12-23T12:16:45.512805+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:16:45.513230+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:16:45.513846+0000 | compress_modules | INFO - Quantizing model.layers.13.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:16:47.081057+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-23T12:16:47.082230+0000 | compress | METRIC - error 17.49\n",
      "2025-12-23T12:16:47.083055+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:16:47.083787+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:16:47.084652+0000 | compress_modules | INFO - Quantizing model.layers.13.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:16:48.644393+0000 | compress | METRIC - time 1.56s\n",
      "2025-12-23T12:16:48.645390+0000 | compress | METRIC - error 8.50\n",
      "2025-12-23T12:16:48.646060+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:16:48.646441+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:16:48.647080+0000 | compress_modules | INFO - Quantizing model.layers.13.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:16:54.173325+0000 | compress | METRIC - time 5.53s\n",
      "2025-12-23T12:16:54.174474+0000 | compress | METRIC - error 0.11\n",
      "2025-12-23T12:16:54.175157+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:16:54.175541+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(14/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 161.05it/s]\n",
      "(15/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:17:07.274927+0000 | compress_modules | INFO - Quantizing model.layers.14.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:17:08.765459+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:17:08.766353+0000 | compress | METRIC - error 30.33\n",
      "2025-12-23T12:17:08.767304+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:17:08.767720+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:17:08.768309+0000 | compress_modules | INFO - Quantizing model.layers.14.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:17:10.228852+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-23T12:17:10.229711+0000 | compress | METRIC - error 41.84\n",
      "2025-12-23T12:17:10.230469+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:17:10.230829+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:17:10.231455+0000 | compress_modules | INFO - Quantizing model.layers.14.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:17:11.687967+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-23T12:17:11.688766+0000 | compress | METRIC - error 0.94\n",
      "2025-12-23T12:17:11.689975+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:17:11.690357+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:17:11.690959+0000 | compress_modules | INFO - Quantizing model.layers.14.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:17:13.172000+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:17:13.172997+0000 | compress | METRIC - error 0.09\n",
      "2025-12-23T12:17:13.173650+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:17:13.174061+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:17:13.174669+0000 | compress_modules | INFO - Quantizing model.layers.14.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:17:14.746468+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-23T12:17:14.747370+0000 | compress | METRIC - error 21.36\n",
      "2025-12-23T12:17:14.747986+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:17:14.748355+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:17:14.748962+0000 | compress_modules | INFO - Quantizing model.layers.14.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:17:16.315329+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-23T12:17:16.316313+0000 | compress | METRIC - error 9.25\n",
      "2025-12-23T12:17:16.316962+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:17:16.317489+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:17:16.318502+0000 | compress_modules | INFO - Quantizing model.layers.14.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:17:21.856037+0000 | compress | METRIC - time 5.54s\n",
      "2025-12-23T12:17:21.857242+0000 | compress | METRIC - error 0.14\n",
      "2025-12-23T12:17:21.858026+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:17:21.858440+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(15/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 163.98it/s]\n",
      "(16/33): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:17:35.804068+0000 | compress_modules | INFO - Quantizing model.layers.15.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:17:37.328149+0000 | compress | METRIC - time 1.52s\n",
      "2025-12-23T12:17:37.328959+0000 | compress | METRIC - error 42.70\n",
      "2025-12-23T12:17:37.329659+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:17:37.330103+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:17:37.331179+0000 | compress_modules | INFO - Quantizing model.layers.15.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:17:38.819049+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:17:38.819835+0000 | compress | METRIC - error 38.32\n",
      "2025-12-23T12:17:38.820527+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:17:38.820896+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:17:38.821516+0000 | compress_modules | INFO - Quantizing model.layers.15.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:17:40.309571+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:17:40.310364+0000 | compress | METRIC - error 0.98\n",
      "2025-12-23T12:17:40.311387+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:17:40.311935+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:17:40.312630+0000 | compress_modules | INFO - Quantizing model.layers.15.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:17:41.855276+0000 | compress | METRIC - time 1.54s\n",
      "2025-12-23T12:17:41.856179+0000 | compress | METRIC - error 0.07\n",
      "2025-12-23T12:17:41.856816+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:17:41.857356+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:17:41.858503+0000 | compress_modules | INFO - Quantizing model.layers.15.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:17:43.465104+0000 | compress | METRIC - time 1.61s\n",
      "2025-12-23T12:17:43.466171+0000 | compress | METRIC - error 25.75\n",
      "2025-12-23T12:17:43.466786+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:17:43.467211+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:17:43.467815+0000 | compress_modules | INFO - Quantizing model.layers.15.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:17:45.070671+0000 | compress | METRIC - time 1.60s\n",
      "2025-12-23T12:17:45.071680+0000 | compress | METRIC - error 9.09\n",
      "2025-12-23T12:17:45.072531+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:17:45.072898+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:17:45.073522+0000 | compress_modules | INFO - Quantizing model.layers.15.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:17:50.677947+0000 | compress | METRIC - time 5.60s\n",
      "2025-12-23T12:17:50.679238+0000 | compress | METRIC - error 0.14\n",
      "2025-12-23T12:17:50.679976+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:17:50.680410+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(16/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 161.76it/s]\n",
      "(17/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:18:03.626125+0000 | compress_modules | INFO - Quantizing model.layers.16.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:18:05.105170+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:18:05.105941+0000 | compress | METRIC - error 36.99\n",
      "2025-12-23T12:18:05.106619+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:18:05.107003+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:18:05.107588+0000 | compress_modules | INFO - Quantizing model.layers.16.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:18:06.565042+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-23T12:18:06.565991+0000 | compress | METRIC - error 41.47\n",
      "2025-12-23T12:18:06.566667+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:18:06.567074+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:18:06.567678+0000 | compress_modules | INFO - Quantizing model.layers.16.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:18:08.033943+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-23T12:18:08.034807+0000 | compress | METRIC - error 1.28\n",
      "2025-12-23T12:18:08.035485+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:18:08.035831+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:18:08.036474+0000 | compress_modules | INFO - Quantizing model.layers.16.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:18:09.507024+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-23T12:18:09.507957+0000 | compress | METRIC - error 0.06\n",
      "2025-12-23T12:18:09.508584+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:18:09.508939+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:18:09.509564+0000 | compress_modules | INFO - Quantizing model.layers.16.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:18:11.066586+0000 | compress | METRIC - time 1.56s\n",
      "2025-12-23T12:18:11.067394+0000 | compress | METRIC - error 22.06\n",
      "2025-12-23T12:18:11.068117+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:18:11.068746+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:18:11.069929+0000 | compress_modules | INFO - Quantizing model.layers.16.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:18:12.626264+0000 | compress | METRIC - time 1.56s\n",
      "2025-12-23T12:18:12.627314+0000 | compress | METRIC - error 8.37\n",
      "2025-12-23T12:18:12.627983+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:18:12.628411+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:18:12.629083+0000 | compress_modules | INFO - Quantizing model.layers.16.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:18:18.130338+0000 | compress | METRIC - time 5.50s\n",
      "2025-12-23T12:18:18.131915+0000 | compress | METRIC - error 0.16\n",
      "2025-12-23T12:18:18.132657+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:18:18.133086+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(17/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 162.25it/s]\n",
      "(18/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:18:31.047114+0000 | compress_modules | INFO - Quantizing model.layers.17.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:18:32.531745+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:18:32.532664+0000 | compress | METRIC - error 34.65\n",
      "2025-12-23T12:18:32.533357+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:18:32.533730+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:18:32.534361+0000 | compress_modules | INFO - Quantizing model.layers.17.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:18:33.994688+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-23T12:18:33.995538+0000 | compress | METRIC - error 40.34\n",
      "2025-12-23T12:18:33.996760+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:18:33.997149+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:18:33.997797+0000 | compress_modules | INFO - Quantizing model.layers.17.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:18:35.451094+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-23T12:18:35.451892+0000 | compress | METRIC - error 0.79\n",
      "2025-12-23T12:18:35.452503+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:18:35.452865+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:18:35.453482+0000 | compress_modules | INFO - Quantizing model.layers.17.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:18:36.963965+0000 | compress | METRIC - time 1.51s\n",
      "2025-12-23T12:18:36.965034+0000 | compress | METRIC - error 0.05\n",
      "2025-12-23T12:18:36.965743+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:18:36.966414+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:18:36.967362+0000 | compress_modules | INFO - Quantizing model.layers.17.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:18:38.561696+0000 | compress | METRIC - time 1.59s\n",
      "2025-12-23T12:18:38.562810+0000 | compress | METRIC - error 22.79\n",
      "2025-12-23T12:18:38.563550+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:18:38.563947+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:18:38.564613+0000 | compress_modules | INFO - Quantizing model.layers.17.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:18:40.170536+0000 | compress | METRIC - time 1.61s\n",
      "2025-12-23T12:18:40.171349+0000 | compress | METRIC - error 8.25\n",
      "2025-12-23T12:18:40.172001+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:18:40.172402+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:18:40.173089+0000 | compress_modules | INFO - Quantizing model.layers.17.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:18:45.875442+0000 | compress | METRIC - time 5.70s\n",
      "2025-12-23T12:18:45.877309+0000 | compress | METRIC - error 0.18\n",
      "2025-12-23T12:18:45.878099+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:18:45.878530+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(18/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 161.85it/s]\n",
      "(19/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:18:58.816874+0000 | compress_modules | INFO - Quantizing model.layers.18.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:19:00.335360+0000 | compress | METRIC - time 1.52s\n",
      "2025-12-23T12:19:00.336196+0000 | compress | METRIC - error 38.66\n",
      "2025-12-23T12:19:00.337191+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:19:00.337713+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:19:00.338348+0000 | compress_modules | INFO - Quantizing model.layers.18.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:19:01.821453+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:19:01.822419+0000 | compress | METRIC - error 43.10\n",
      "2025-12-23T12:19:01.823194+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:19:01.823576+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:19:01.824213+0000 | compress_modules | INFO - Quantizing model.layers.18.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:19:03.331614+0000 | compress | METRIC - time 1.51s\n",
      "2025-12-23T12:19:03.332516+0000 | compress | METRIC - error 1.39\n",
      "2025-12-23T12:19:03.333369+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:19:03.333964+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:19:03.334692+0000 | compress_modules | INFO - Quantizing model.layers.18.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:19:04.845754+0000 | compress | METRIC - time 1.51s\n",
      "2025-12-23T12:19:04.846892+0000 | compress | METRIC - error 0.03\n",
      "2025-12-23T12:19:04.847659+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:19:04.848380+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:19:04.849348+0000 | compress_modules | INFO - Quantizing model.layers.18.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:19:06.446876+0000 | compress | METRIC - time 1.60s\n",
      "2025-12-23T12:19:06.447904+0000 | compress | METRIC - error 19.45\n",
      "2025-12-23T12:19:06.448558+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:19:06.448941+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:19:06.449604+0000 | compress_modules | INFO - Quantizing model.layers.18.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:19:08.048607+0000 | compress | METRIC - time 1.60s\n",
      "2025-12-23T12:19:08.049642+0000 | compress | METRIC - error 7.73\n",
      "2025-12-23T12:19:08.050946+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:19:08.051347+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:19:08.051997+0000 | compress_modules | INFO - Quantizing model.layers.18.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:19:13.758749+0000 | compress | METRIC - time 5.71s\n",
      "2025-12-23T12:19:13.760575+0000 | compress | METRIC - error 0.16\n",
      "2025-12-23T12:19:13.761499+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:19:13.761967+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(19/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 161.87it/s]\n",
      "(20/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:19:26.717121+0000 | compress_modules | INFO - Quantizing model.layers.19.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:19:28.234925+0000 | compress | METRIC - time 1.52s\n",
      "2025-12-23T12:19:28.235712+0000 | compress | METRIC - error 36.65\n",
      "2025-12-23T12:19:28.323746+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:19:28.324643+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:19:28.325592+0000 | compress_modules | INFO - Quantizing model.layers.19.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:19:29.803404+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:19:29.804318+0000 | compress | METRIC - error 32.89\n",
      "2025-12-23T12:19:29.805138+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:19:29.805548+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:19:29.806203+0000 | compress_modules | INFO - Quantizing model.layers.19.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:19:31.290746+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:19:31.291760+0000 | compress | METRIC - error 1.61\n",
      "2025-12-23T12:19:31.292462+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:19:31.292999+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:19:31.294087+0000 | compress_modules | INFO - Quantizing model.layers.19.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:19:32.803191+0000 | compress | METRIC - time 1.51s\n",
      "2025-12-23T12:19:32.804093+0000 | compress | METRIC - error 0.02\n",
      "2025-12-23T12:19:32.805157+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:19:32.805728+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:19:32.806517+0000 | compress_modules | INFO - Quantizing model.layers.19.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:19:34.396470+0000 | compress | METRIC - time 1.59s\n",
      "2025-12-23T12:19:34.397547+0000 | compress | METRIC - error 18.72\n",
      "2025-12-23T12:19:34.398313+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:19:34.398719+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:19:34.399460+0000 | compress_modules | INFO - Quantizing model.layers.19.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:19:35.985837+0000 | compress | METRIC - time 1.59s\n",
      "2025-12-23T12:19:35.986955+0000 | compress | METRIC - error 7.65\n",
      "2025-12-23T12:19:35.987664+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:19:35.988135+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:19:35.988824+0000 | compress_modules | INFO - Quantizing model.layers.19.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:19:41.597541+0000 | compress | METRIC - time 5.61s\n",
      "2025-12-23T12:19:41.598766+0000 | compress | METRIC - error 0.18\n",
      "2025-12-23T12:19:41.599455+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:19:41.599831+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(20/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 161.35it/s]\n",
      "(21/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:19:54.609986+0000 | compress_modules | INFO - Quantizing model.layers.20.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:19:56.122176+0000 | compress | METRIC - time 1.51s\n",
      "2025-12-23T12:19:56.123028+0000 | compress | METRIC - error 40.54\n",
      "2025-12-23T12:19:56.124000+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:19:56.124669+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:19:56.125222+0000 | compress_modules | INFO - Quantizing model.layers.20.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:19:57.608137+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:19:57.608951+0000 | compress | METRIC - error 40.47\n",
      "2025-12-23T12:19:57.609894+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:19:57.610314+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:19:57.611347+0000 | compress_modules | INFO - Quantizing model.layers.20.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:19:59.098357+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:19:59.099247+0000 | compress | METRIC - error 1.40\n",
      "2025-12-23T12:19:59.100089+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:19:59.100463+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:19:59.101117+0000 | compress_modules | INFO - Quantizing model.layers.20.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:20:00.604969+0000 | compress | METRIC - time 1.50s\n",
      "2025-12-23T12:20:00.605954+0000 | compress | METRIC - error 0.03\n",
      "2025-12-23T12:20:00.606801+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:20:00.607244+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:20:00.607895+0000 | compress_modules | INFO - Quantizing model.layers.20.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:20:02.191413+0000 | compress | METRIC - time 1.58s\n",
      "2025-12-23T12:20:02.192538+0000 | compress | METRIC - error 19.73\n",
      "2025-12-23T12:20:02.193324+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:20:02.193722+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:20:02.194406+0000 | compress_modules | INFO - Quantizing model.layers.20.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:20:03.788239+0000 | compress | METRIC - time 1.59s\n",
      "2025-12-23T12:20:03.789938+0000 | compress | METRIC - error 8.26\n",
      "2025-12-23T12:20:03.790692+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:20:03.791122+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:20:03.791760+0000 | compress_modules | INFO - Quantizing model.layers.20.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:20:09.409194+0000 | compress | METRIC - time 5.62s\n",
      "2025-12-23T12:20:09.410185+0000 | compress | METRIC - error 0.19\n",
      "2025-12-23T12:20:09.410825+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:20:09.411207+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(21/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 161.32it/s]\n",
      "(22/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:20:22.462793+0000 | compress_modules | INFO - Quantizing model.layers.21.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:20:23.954722+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:20:23.955655+0000 | compress | METRIC - error 43.36\n",
      "2025-12-23T12:20:23.956547+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:20:23.956953+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:20:23.957621+0000 | compress_modules | INFO - Quantizing model.layers.21.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:20:25.425993+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-23T12:20:25.426873+0000 | compress | METRIC - error 39.41\n",
      "2025-12-23T12:20:25.427812+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:20:25.428413+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:20:25.428981+0000 | compress_modules | INFO - Quantizing model.layers.21.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:20:26.901169+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-23T12:20:26.901948+0000 | compress | METRIC - error 1.96\n",
      "2025-12-23T12:20:26.902779+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:20:26.903165+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:20:26.903780+0000 | compress_modules | INFO - Quantizing model.layers.21.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:20:28.398549+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:20:28.399656+0000 | compress | METRIC - error 0.03\n",
      "2025-12-23T12:20:28.400367+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:20:28.400885+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:20:28.401960+0000 | compress_modules | INFO - Quantizing model.layers.21.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:20:29.971497+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-23T12:20:29.973045+0000 | compress | METRIC - error 23.16\n",
      "2025-12-23T12:20:30.020247+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:20:30.021190+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:20:30.022283+0000 | compress_modules | INFO - Quantizing model.layers.21.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:20:31.604194+0000 | compress | METRIC - time 1.58s\n",
      "2025-12-23T12:20:31.605215+0000 | compress | METRIC - error 9.13\n",
      "2025-12-23T12:20:31.606084+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:20:31.606481+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:20:31.607538+0000 | compress_modules | INFO - Quantizing model.layers.21.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:20:37.164989+0000 | compress | METRIC - time 5.56s\n",
      "2025-12-23T12:20:37.166033+0000 | compress | METRIC - error 0.25\n",
      "2025-12-23T12:20:37.166647+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:20:37.167184+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(22/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 161.86it/s]\n",
      "(23/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:20:50.212724+0000 | compress_modules | INFO - Quantizing model.layers.22.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:20:51.718480+0000 | compress | METRIC - time 1.51s\n",
      "2025-12-23T12:20:51.719461+0000 | compress | METRIC - error 45.21\n",
      "2025-12-23T12:20:51.720131+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:20:51.720675+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:20:51.721686+0000 | compress_modules | INFO - Quantizing model.layers.22.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:20:53.192073+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-23T12:20:53.192976+0000 | compress | METRIC - error 44.53\n",
      "2025-12-23T12:20:53.193860+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:20:53.194267+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:20:53.194908+0000 | compress_modules | INFO - Quantizing model.layers.22.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:20:54.671592+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:20:54.672449+0000 | compress | METRIC - error 2.09\n",
      "2025-12-23T12:20:54.673100+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:20:54.673463+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:20:54.674118+0000 | compress_modules | INFO - Quantizing model.layers.22.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:20:56.161033+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:20:56.162073+0000 | compress | METRIC - error 0.03\n",
      "2025-12-23T12:20:56.162966+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:20:56.163579+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:20:56.164213+0000 | compress_modules | INFO - Quantizing model.layers.22.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:20:57.736092+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-23T12:20:57.737187+0000 | compress | METRIC - error 24.86\n",
      "2025-12-23T12:20:57.738190+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:20:57.738735+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:20:57.739388+0000 | compress_modules | INFO - Quantizing model.layers.22.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:20:59.312806+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-23T12:20:59.314305+0000 | compress | METRIC - error 9.50\n",
      "2025-12-23T12:20:59.314965+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:20:59.315364+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:20:59.316376+0000 | compress_modules | INFO - Quantizing model.layers.22.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:21:05.033249+0000 | compress | METRIC - time 5.72s\n",
      "2025-12-23T12:21:05.034279+0000 | compress | METRIC - error 0.23\n",
      "2025-12-23T12:21:05.035263+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:21:05.035815+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(23/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 161.98it/s]\n",
      "(24/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:21:17.995156+0000 | compress_modules | INFO - Quantizing model.layers.23.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:21:19.499464+0000 | compress | METRIC - time 1.50s\n",
      "2025-12-23T12:21:19.500308+0000 | compress | METRIC - error 46.31\n",
      "2025-12-23T12:21:19.500935+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:21:19.501364+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:21:19.501968+0000 | compress_modules | INFO - Quantizing model.layers.23.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:21:20.978207+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:21:20.979271+0000 | compress | METRIC - error 39.65\n",
      "2025-12-23T12:21:20.979958+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:21:20.980385+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:21:20.980996+0000 | compress_modules | INFO - Quantizing model.layers.23.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:21:22.467937+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:21:22.468714+0000 | compress | METRIC - error 2.04\n",
      "2025-12-23T12:21:22.469743+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:21:22.470348+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:21:22.470984+0000 | compress_modules | INFO - Quantizing model.layers.23.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:21:24.004390+0000 | compress | METRIC - time 1.53s\n",
      "2025-12-23T12:21:24.005398+0000 | compress | METRIC - error 0.02\n",
      "2025-12-23T12:21:24.006061+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:21:24.006428+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:21:24.007064+0000 | compress_modules | INFO - Quantizing model.layers.23.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:21:25.624080+0000 | compress | METRIC - time 1.62s\n",
      "2025-12-23T12:21:25.625300+0000 | compress | METRIC - error 23.61\n",
      "2025-12-23T12:21:25.626125+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:21:25.626554+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:21:25.627267+0000 | compress_modules | INFO - Quantizing model.layers.23.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:21:27.251971+0000 | compress | METRIC - time 1.62s\n",
      "2025-12-23T12:21:27.253685+0000 | compress | METRIC - error 10.33\n",
      "2025-12-23T12:21:27.254466+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:21:27.254855+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:21:27.255491+0000 | compress_modules | INFO - Quantizing model.layers.23.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:21:32.940919+0000 | compress | METRIC - time 5.68s\n",
      "2025-12-23T12:21:32.941892+0000 | compress | METRIC - error 0.24\n",
      "2025-12-23T12:21:32.942547+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:21:32.942919+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(24/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 162.65it/s]\n",
      "(25/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:21:45.854781+0000 | compress_modules | INFO - Quantizing model.layers.24.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:21:47.321678+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-23T12:21:47.322532+0000 | compress | METRIC - error 47.22\n",
      "2025-12-23T12:21:47.323427+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:21:47.323791+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:21:47.324370+0000 | compress_modules | INFO - Quantizing model.layers.24.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:21:48.767883+0000 | compress | METRIC - time 1.44s\n",
      "2025-12-23T12:21:48.768716+0000 | compress | METRIC - error 41.01\n",
      "2025-12-23T12:21:48.769349+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:21:48.769729+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:21:48.770394+0000 | compress_modules | INFO - Quantizing model.layers.24.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:21:50.225124+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-23T12:21:50.226001+0000 | compress | METRIC - error 3.04\n",
      "2025-12-23T12:21:50.227314+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:21:50.227720+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:21:50.228359+0000 | compress_modules | INFO - Quantizing model.layers.24.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:21:51.690298+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-23T12:21:51.691327+0000 | compress | METRIC - error 0.03\n",
      "2025-12-23T12:21:51.691952+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:21:51.692506+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:21:51.693079+0000 | compress_modules | INFO - Quantizing model.layers.24.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:21:53.243944+0000 | compress | METRIC - time 1.55s\n",
      "2025-12-23T12:21:53.244952+0000 | compress | METRIC - error 23.20\n",
      "2025-12-23T12:21:53.245811+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:21:53.246221+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:21:53.247345+0000 | compress_modules | INFO - Quantizing model.layers.24.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:21:54.791985+0000 | compress | METRIC - time 1.54s\n",
      "2025-12-23T12:21:54.793243+0000 | compress | METRIC - error 11.00\n",
      "2025-12-23T12:21:54.794088+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:21:54.794497+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:21:54.795218+0000 | compress_modules | INFO - Quantizing model.layers.24.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:22:00.274893+0000 | compress | METRIC - time 5.48s\n",
      "2025-12-23T12:22:00.276258+0000 | compress | METRIC - error 0.27\n",
      "2025-12-23T12:22:00.277040+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:22:00.277421+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(25/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 162.31it/s]\n",
      "(26/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:22:13.194549+0000 | compress_modules | INFO - Quantizing model.layers.25.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:22:14.673733+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:22:14.674621+0000 | compress | METRIC - error 47.38\n",
      "2025-12-23T12:22:14.675529+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:22:14.675903+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:22:14.676530+0000 | compress_modules | INFO - Quantizing model.layers.25.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:22:16.134825+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-23T12:22:16.135704+0000 | compress | METRIC - error 34.16\n",
      "2025-12-23T12:22:16.136578+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:22:16.136955+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:22:16.137947+0000 | compress_modules | INFO - Quantizing model.layers.25.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:22:17.610796+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-23T12:22:17.611572+0000 | compress | METRIC - error 3.28\n",
      "2025-12-23T12:22:17.612474+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:22:17.612863+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:22:17.613489+0000 | compress_modules | INFO - Quantizing model.layers.25.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:22:19.086816+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-23T12:22:19.087750+0000 | compress | METRIC - error 0.03\n",
      "2025-12-23T12:22:19.088746+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:22:19.089293+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:22:19.089929+0000 | compress_modules | INFO - Quantizing model.layers.25.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:22:20.645695+0000 | compress | METRIC - time 1.56s\n",
      "2025-12-23T12:22:20.646740+0000 | compress | METRIC - error 24.69\n",
      "2025-12-23T12:22:20.647449+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:22:20.647830+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:22:20.648456+0000 | compress_modules | INFO - Quantizing model.layers.25.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:22:22.204127+0000 | compress | METRIC - time 1.56s\n",
      "2025-12-23T12:22:22.205281+0000 | compress | METRIC - error 12.39\n",
      "2025-12-23T12:22:22.205962+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:22:22.206389+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:22:22.207054+0000 | compress_modules | INFO - Quantizing model.layers.25.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:22:27.701178+0000 | compress | METRIC - time 5.49s\n",
      "2025-12-23T12:22:27.703069+0000 | compress | METRIC - error 0.32\n",
      "2025-12-23T12:22:27.704092+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:22:27.704682+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(26/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 162.00it/s]\n",
      "(27/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:22:40.637544+0000 | compress_modules | INFO - Quantizing model.layers.26.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:22:42.158805+0000 | compress | METRIC - time 1.52s\n",
      "2025-12-23T12:22:42.159305+0000 | compress | METRIC - error 51.76\n",
      "2025-12-23T12:22:42.159918+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:22:42.160243+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:22:42.160787+0000 | compress_modules | INFO - Quantizing model.layers.26.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:22:43.656222+0000 | compress | METRIC - time 1.50s\n",
      "2025-12-23T12:22:43.656749+0000 | compress | METRIC - error 45.81\n",
      "2025-12-23T12:22:43.657384+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:22:43.657704+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:22:43.658266+0000 | compress_modules | INFO - Quantizing model.layers.26.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:22:45.151237+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:22:45.151845+0000 | compress | METRIC - error 2.35\n",
      "2025-12-23T12:22:45.152362+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:22:45.152686+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:22:45.153267+0000 | compress_modules | INFO - Quantizing model.layers.26.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:22:46.653512+0000 | compress | METRIC - time 1.50s\n",
      "2025-12-23T12:22:46.654299+0000 | compress | METRIC - error 0.08\n",
      "2025-12-23T12:22:46.654774+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:22:46.655118+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:22:46.655678+0000 | compress_modules | INFO - Quantizing model.layers.26.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:22:48.247327+0000 | compress | METRIC - time 1.59s\n",
      "2025-12-23T12:22:48.247954+0000 | compress | METRIC - error 27.28\n",
      "2025-12-23T12:22:48.248645+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:22:48.249020+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:22:48.249667+0000 | compress_modules | INFO - Quantizing model.layers.26.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:22:49.839281+0000 | compress | METRIC - time 1.59s\n",
      "2025-12-23T12:22:49.839884+0000 | compress | METRIC - error 13.94\n",
      "2025-12-23T12:22:49.840532+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:22:49.840836+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:22:49.841423+0000 | compress_modules | INFO - Quantizing model.layers.26.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:22:55.490025+0000 | compress | METRIC - time 5.65s\n",
      "2025-12-23T12:22:55.490892+0000 | compress | METRIC - error 0.38\n",
      "2025-12-23T12:22:55.491534+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:22:55.491978+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(27/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 163.23it/s]\n",
      "(28/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:23:08.477381+0000 | compress_modules | INFO - Quantizing model.layers.27.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:23:10.014353+0000 | compress | METRIC - time 1.54s\n",
      "2025-12-23T12:23:10.015149+0000 | compress | METRIC - error 50.06\n",
      "2025-12-23T12:23:10.015819+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:23:10.016227+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:23:10.016837+0000 | compress_modules | INFO - Quantizing model.layers.27.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:23:11.534898+0000 | compress | METRIC - time 1.52s\n",
      "2025-12-23T12:23:11.535786+0000 | compress | METRIC - error 43.38\n",
      "2025-12-23T12:23:11.536559+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:23:11.536950+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:23:11.537591+0000 | compress_modules | INFO - Quantizing model.layers.27.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:23:13.038823+0000 | compress | METRIC - time 1.50s\n",
      "2025-12-23T12:23:13.039660+0000 | compress | METRIC - error 5.48\n",
      "2025-12-23T12:23:13.040537+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:23:13.040925+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:23:13.041569+0000 | compress_modules | INFO - Quantizing model.layers.27.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:23:14.525035+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:23:14.526189+0000 | compress | METRIC - error 0.09\n",
      "2025-12-23T12:23:14.526793+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:23:14.527186+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:23:14.527818+0000 | compress_modules | INFO - Quantizing model.layers.27.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:23:16.094352+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-23T12:23:16.095336+0000 | compress | METRIC - error 30.77\n",
      "2025-12-23T12:23:16.095967+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:23:16.096348+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:23:16.096992+0000 | compress_modules | INFO - Quantizing model.layers.27.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:23:17.711249+0000 | compress | METRIC - time 1.61s\n",
      "2025-12-23T12:23:17.712318+0000 | compress | METRIC - error 16.73\n",
      "2025-12-23T12:23:17.712820+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:23:17.713200+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:23:17.713899+0000 | compress_modules | INFO - Quantizing model.layers.27.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:23:23.289182+0000 | compress | METRIC - time 5.57s\n",
      "2025-12-23T12:23:23.290259+0000 | compress | METRIC - error 0.49\n",
      "2025-12-23T12:23:23.290965+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:23:23.291357+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(28/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 166.73it/s]\n",
      "(29/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:23:36.245458+0000 | compress_modules | INFO - Quantizing model.layers.28.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:23:37.739136+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:23:37.740136+0000 | compress | METRIC - error 51.26\n",
      "2025-12-23T12:23:37.740703+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:23:37.741102+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:23:37.741817+0000 | compress_modules | INFO - Quantizing model.layers.28.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:23:39.212288+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-23T12:23:39.213107+0000 | compress | METRIC - error 38.42\n",
      "2025-12-23T12:23:39.213731+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:23:39.214137+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:23:39.214758+0000 | compress_modules | INFO - Quantizing model.layers.28.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:23:40.679219+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-23T12:23:40.680045+0000 | compress | METRIC - error 2.95\n",
      "2025-12-23T12:23:40.680722+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:23:40.681252+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:23:40.682238+0000 | compress_modules | INFO - Quantizing model.layers.28.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:23:42.172439+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:23:42.173316+0000 | compress | METRIC - error 0.12\n",
      "2025-12-23T12:23:42.173963+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:23:42.174371+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:23:42.174955+0000 | compress_modules | INFO - Quantizing model.layers.28.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:23:43.741031+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-23T12:23:43.742176+0000 | compress | METRIC - error 35.33\n",
      "2025-12-23T12:23:43.742785+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:23:43.743189+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:23:43.743791+0000 | compress_modules | INFO - Quantizing model.layers.28.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:23:45.323799+0000 | compress | METRIC - time 1.58s\n",
      "2025-12-23T12:23:45.324812+0000 | compress | METRIC - error 19.16\n",
      "2025-12-23T12:23:45.325610+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:23:45.326002+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:23:45.326614+0000 | compress_modules | INFO - Quantizing model.layers.28.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:23:50.896343+0000 | compress | METRIC - time 5.57s\n",
      "2025-12-23T12:23:50.897400+0000 | compress | METRIC - error 0.69\n",
      "2025-12-23T12:23:50.898138+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:23:50.898625+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(29/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 161.27it/s]\n",
      "(30/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:24:03.975068+0000 | compress_modules | INFO - Quantizing model.layers.29.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:24:05.473191+0000 | compress | METRIC - time 1.50s\n",
      "2025-12-23T12:24:05.474041+0000 | compress | METRIC - error 45.07\n",
      "2025-12-23T12:24:05.474739+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:24:05.475145+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:24:05.475806+0000 | compress_modules | INFO - Quantizing model.layers.29.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:24:06.958492+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:24:06.959368+0000 | compress | METRIC - error 32.96\n",
      "2025-12-23T12:24:06.960237+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:24:06.960610+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:24:06.961574+0000 | compress_modules | INFO - Quantizing model.layers.29.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:24:08.440409+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:24:08.441226+0000 | compress | METRIC - error 4.55\n",
      "2025-12-23T12:24:08.441931+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:24:08.442495+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:24:08.443119+0000 | compress_modules | INFO - Quantizing model.layers.29.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:24:09.927098+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:24:09.928113+0000 | compress | METRIC - error 0.17\n",
      "2025-12-23T12:24:09.928782+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:24:09.929212+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:24:09.929904+0000 | compress_modules | INFO - Quantizing model.layers.29.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:24:11.504436+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-23T12:24:11.506237+0000 | compress | METRIC - error 39.40\n",
      "2025-12-23T12:24:11.507168+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:24:11.507594+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:24:11.508296+0000 | compress_modules | INFO - Quantizing model.layers.29.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:24:13.091063+0000 | compress | METRIC - time 1.58s\n",
      "2025-12-23T12:24:13.092219+0000 | compress | METRIC - error 23.50\n",
      "2025-12-23T12:24:13.092844+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:24:13.093398+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:24:13.094492+0000 | compress_modules | INFO - Quantizing model.layers.29.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:24:18.661478+0000 | compress | METRIC - time 5.57s\n",
      "2025-12-23T12:24:18.662469+0000 | compress | METRIC - error 1.12\n",
      "2025-12-23T12:24:18.663163+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:24:18.663555+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(30/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 161.64it/s]\n",
      "(31/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:24:31.719591+0000 | compress_modules | INFO - Quantizing model.layers.30.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:24:33.209694+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:24:33.210546+0000 | compress | METRIC - error 61.92\n",
      "2025-12-23T12:24:33.211264+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:24:33.211637+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:24:33.212224+0000 | compress_modules | INFO - Quantizing model.layers.30.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:24:34.674231+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-23T12:24:34.674950+0000 | compress | METRIC - error 54.07\n",
      "2025-12-23T12:24:34.675576+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:24:34.675923+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:24:34.676508+0000 | compress_modules | INFO - Quantizing model.layers.30.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:24:36.147888+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-23T12:24:36.148682+0000 | compress | METRIC - error 7.66\n",
      "2025-12-23T12:24:36.191109+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:24:36.191941+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:24:36.192939+0000 | compress_modules | INFO - Quantizing model.layers.30.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:24:37.668521+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:24:37.669606+0000 | compress | METRIC - error 0.28\n",
      "2025-12-23T12:24:37.670477+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:24:37.671075+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:24:37.671782+0000 | compress_modules | INFO - Quantizing model.layers.30.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:24:39.237460+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-23T12:24:39.238504+0000 | compress | METRIC - error 46.82\n",
      "2025-12-23T12:24:39.239389+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:24:39.239790+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:24:39.240483+0000 | compress_modules | INFO - Quantizing model.layers.30.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:24:40.814818+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-23T12:24:40.815839+0000 | compress | METRIC - error 28.30\n",
      "2025-12-23T12:24:40.816559+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:24:40.816946+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:24:40.817611+0000 | compress_modules | INFO - Quantizing model.layers.30.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:24:46.361921+0000 | compress | METRIC - time 5.54s\n",
      "2025-12-23T12:24:46.363672+0000 | compress | METRIC - error 2.14\n",
      "2025-12-23T12:24:46.364550+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:24:46.365285+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(31/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 161.53it/s]\n",
      "(32/33): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:24:59.439930+0000 | compress_modules | INFO - Quantizing model.layers.31.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:25:00.931445+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-23T12:25:00.932292+0000 | compress | METRIC - error 40.40\n",
      "2025-12-23T12:25:00.933130+0000 | compress | METRIC - GPU 0 | usage: 43.19% | total memory: 48 GB\n",
      "2025-12-23T12:25:00.933485+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:25:00.934140+0000 | compress_modules | INFO - Quantizing model.layers.31.self_attn.k_proj using 512 samples\n",
      "2025-12-23T12:25:02.402691+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-23T12:25:02.403620+0000 | compress | METRIC - error 26.64\n",
      "2025-12-23T12:25:02.404280+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:25:02.404631+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:25:02.405304+0000 | compress_modules | INFO - Quantizing model.layers.31.self_attn.v_proj using 512 samples\n",
      "2025-12-23T12:25:03.868780+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-23T12:25:03.869645+0000 | compress | METRIC - error 5.97\n",
      "2025-12-23T12:25:03.870305+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:25:03.870675+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-23T12:25:03.871313+0000 | compress_modules | INFO - Quantizing model.layers.31.self_attn.o_proj using 512 samples\n",
      "2025-12-23T12:25:05.354296+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-23T12:25:05.355124+0000 | compress | METRIC - error 0.63\n",
      "2025-12-23T12:25:05.355815+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:25:05.356209+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-23T12:25:05.356857+0000 | compress_modules | INFO - Quantizing model.layers.31.mlp.gate_proj using 512 samples\n",
      "2025-12-23T12:25:06.926864+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-23T12:25:06.927892+0000 | compress | METRIC - error 42.73\n",
      "2025-12-23T12:25:06.928578+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:25:06.928978+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:25:06.930108+0000 | compress_modules | INFO - Quantizing model.layers.31.mlp.up_proj using 512 samples\n",
      "2025-12-23T12:25:08.503794+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-23T12:25:08.504794+0000 | compress | METRIC - error 56.83\n",
      "2025-12-23T12:25:08.505505+0000 | compress | METRIC - GPU 0 | usage: 43.20% | total memory: 48 GB\n",
      "2025-12-23T12:25:08.505885+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-23T12:25:08.506527+0000 | compress_modules | INFO - Quantizing model.layers.31.mlp.down_proj using 512 samples\n",
      "2025-12-23T12:25:14.072726+0000 | compress | METRIC - time 5.57s\n",
      "2025-12-23T12:25:14.073438+0000 | compress | METRIC - error 8.79\n",
      "2025-12-23T12:25:14.074189+0000 | compress | METRIC - GPU 0 | usage: 44.90% | total memory: 48 GB\n",
      "2025-12-23T12:25:14.074533+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(32/33): Propagating: 100%|██████████| 512/512 [00:03<00:00, 164.00it/s]\n",
      "(33/33): Calibrating: 100%|██████████| 512/512 [00:00<00:00, 917.57it/s]\n",
      "(33/33): Propagating: 100%|██████████| 512/512 [00:00<00:00, 1014.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23T12:25:18.443261+0000 | finalize | INFO - Compression lifecycle finalized for 2 modifiers\n",
      "2025-12-23T12:25:18.488560+0000 | get_model_compressor | INFO - skip_sparsity_compression_stats set to True. Skipping sparsity compression statistic calculations. No sparsity compressor will be applied.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compressing model: 224it [00:03, 57.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the quantization scheme\n",
    "scheme = \"W8A8\"  # W8A8 means 8-bit weights and 8-bit activations\n",
    "\n",
    "# Strength for SmoothQuant smoothing\n",
    "# This controls how much the activation values are smoothed to reduce outliers\n",
    "smoothing_strength = 0.8\n",
    "\n",
    "# Create SmoothQuant modifier\n",
    "# - smooths activations before quantization to improve stability and reduce degradation\n",
    "smooth_quant = SmoothQuantModifier(smoothing_strength=smoothing_strength)\n",
    "\n",
    "# Create GPTQ modifier\n",
    "# - targets=\"Linear\" quantizes only Linear layers (e.g., feedforward layers)\n",
    "# - scheme=scheme uses the W8A8 quantization scheme\n",
    "# - ignore=[\"lm_head\"] preserves the LM head to avoid generation quality loss\n",
    "quantizer = GPTQModifier(targets=\"Linear\", scheme=scheme, ignore=[\"lm_head\"])\n",
    "\n",
    "# Combine the modifiers into a recipe list\n",
    "# The order matters: first apply SmoothQuant, then GPTQ\n",
    "recipe = [smooth_quant, quantizer]\n",
    "\n",
    "# Perform quantization\n",
    "oneshot(\n",
    "    model=model_name,  # Model to quantize\n",
    "    dataset=tokenized_dataset,  # Calibration dataset, used for both SmoothQuant & GPTQ\n",
    "    recipe=recipe,  # List of quantization modifiers to apply\n",
    "    output_dir=compressed_model_path,  # Directory to save the quantized model\n",
    "    max_seq_length=2048,  # Maximum sequence length for calibration\n",
    "    num_calibration_samples=512,  # Number of samples used for calibration\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf956831",
   "metadata": {},
   "source": [
    "### Checking model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56836404-daab-4638-8abf-957b71f82507",
   "metadata": {
    "tags": [
     "parameters",
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (GB): 8.460090637207031\n"
     ]
    }
   ],
   "source": [
    "# Load quantized model\n",
    "model_quant = AutoModelForCausalLM.from_pretrained(compressed_model_path)\n",
    "model_quant.config.dtype = model.config.torch_dtype\n",
    "model_quant.save_pretrained(compressed_model_path)\n",
    "model_size = model_size_gb(model_quant)\n",
    "print(f\"Model size (GB): {model_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e882026b-2c4c-4e1f-b20f-75fdaf71b7f3",
   "metadata": {},
   "source": [
    "### Observation\n",
    "After quantizing the model, the size has clearly reduced from 14.9GB to 8GB. Now that we have reduced the model size, the next step is to evaluate this compressed model to make sure the accuracy has retained after compression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98bb261-81be-4324-aa28-241650c9634f",
   "metadata": {},
   "source": [
    "\n",
    "**ALTERNATIVELY**, llm-compressor also supports FP8 quantization. This conversion foes not require any calibration dataset. Uncomment the below cell to quantize the model to FP8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "849c84a3-83b0-4d28-9665-13e4f1ef5fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe = QuantizationModifier(\n",
    "#   targets=\"Linear\", scheme=\"FP8_DYNAMIC\", ignore=[\"lm_head\"])\n",
    "\n",
    "# oneshot(model=model_name, recipe=recipe, output_dir=compressed_model_path)\n",
    "\n",
    "# # Load quantized model\n",
    "# model_quant = AutoModelForCausalLM.from_pretrained(compressed_model_path)\n",
    "# model_quant.config.dtype = model.config.torch_dtype\n",
    "# model_quant.save_pretrained(compressed_model_path)\n",
    "# model_size = model_size_gb(model_quant)\n",
    "# print(f\"Model size (GB): {model_size}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
