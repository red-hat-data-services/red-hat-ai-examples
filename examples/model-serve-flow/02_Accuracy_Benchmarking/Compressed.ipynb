{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46dec15d-d789-4e22-b9ea-5eec04bf9230",
   "metadata": {},
   "source": [
    "## Evaluate Accuracy of the Compressed Model\n",
    "After compression, this step evaluates the compressed model on standard benchmarks to determine how compression affects its accuracy and generative quality relative to the base model.\n",
    "\n",
    "**Goal**: Establish the performance and accuracy of the compressed model and compare it later against the baseline to understand the impact of compression.\n",
    "\n",
    "**Key Actions**:\n",
    "\n",
    "- We will create a function called **evaluate** that uses `simple_evaluate` from LM Eval to test the compressed model.\n",
    "\n",
    "- Benchmark on multiple datasets:\n",
    "\n",
    "    - MMLU: General knowledge across subjects.\n",
    "\n",
    "    - IFeval: Instruction-following tasks.\n",
    "\n",
    "    - ARC: Logical and scientific reasoning.\n",
    "    \n",
    "    - HellaSwag: Commonsense completion.\n",
    "\n",
    "- Collect metrics like accuracy, accuracy_norm, and task-specific scores.\n",
    "\n",
    "- Save results as JSON for later comparison.\n",
    "\n",
    "**Outcome**:\n",
    "\n",
    "- Quantitative metrics for the compressed model.\n",
    "\n",
    "- Confidence that the model is good enough in terms of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f45e6-3f29-4922-b85f-2b77be643530",
   "metadata": {
    "tags": [
     "parameters",
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-12-10 13:22:55,324\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-10 13:22:55 [__init__.py:216] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from lm_eval.utils import make_table\n",
    "from utils import evaluate, load_pickle, save_pickle\n",
    "\n",
    "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e43e6d-4fbe-4bd4-91ae-156b6a1c3af5",
   "metadata": {
    "tags": [
     "parameters",
     "keep_output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bfb397-d989-4a4b-8636-511a25c12ed6",
   "metadata": {},
   "source": [
    "## Define evaluation benchmarking datasets\n",
    "The following benchmark datasets can be used for evaluating on multiple tasks:\n",
    "- MMLU: General knowledge across 57 subjects\n",
    "- IFeval: Instruction-following capability\n",
    "- ARC: Logical & scientific reasoning\n",
    "- HellaSwag: Commonsense completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383befc1-e7b7-4540-af75-a3d5ce28786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tasks you want to evaluate the model on\n",
    "tasks = [\"mmlu\", \"arc_easy\", \"hellaswag\", \"ifeval\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72ddc52-4acd-4230-9681-f84201f19e33",
   "metadata": {},
   "source": [
    "### Evaluating the Compressed Model\n",
    "\n",
    "**NOTE**: \n",
    "1. Running the evaluation on the entire list of tasks can take long. So for testing, you can use a single task instead.\n",
    "\n",
    "2. The results will be stored as a **results.pkl** files in the directories defined by **compressed_results_dir**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b759ca-440b-4491-abba-486fe2c1afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting directories\n",
    "compressed_model_path = \"Llama_3.1_8B_Instruct_int8_dynamic\"\n",
    "compressed_results_dir = \"results/compressed_accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c849dd-535e-442c-82e9-d1fbeed500d1",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# evaluate the compressed model and save results in pkl format\n",
    "comp_acc = evaluate(\n",
    "    compressed_model_path,\n",
    "    tasks,\n",
    "    limit=None,\n",
    "    batch_size=16,\n",
    "    apply_chat_template=True,\n",
    "    verbosity=None,\n",
    ")\n",
    "save_pickle(compressed_results_dir, comp_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20e51ac-f4c3-4276-b2fe-df595a963443",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_results = load_pickle(compressed_results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd79a881-9bcc-4860-a3a1-7b7da82d0138",
   "metadata": {
    "tags": [
     "parameters",
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                 Tasks                 |Version|Filter|n-shot|        Metric         |   |Value |   |Stderr|\n",
      "|---------------------------------------|------:|------|-----:|-----------------------|---|-----:|---|------|\n",
      "|arc_easy                               |      1|none  |     0|acc                    |↑  |0.8114|±  |0.0080|\n",
      "|                                       |       |none  |     0|acc_norm               |↑  |0.7584|±  |0.0088|\n",
      "|hellaswag                              |      1|none  |     0|acc                    |↑  |0.5756|±  |0.0049|\n",
      "|                                       |       |none  |     0|acc_norm               |↑  |0.7261|±  |0.0045|\n",
      "|ifeval                                 |      4|none  |     0|inst_level_loose_acc   |↑  |0.8609|±  |   N/A|\n",
      "|                                       |       |none  |     0|inst_level_strict_acc  |↑  |0.8225|±  |   N/A|\n",
      "|                                       |       |none  |     0|prompt_level_loose_acc |↑  |0.8004|±  |0.0172|\n",
      "|                                       |       |none  |     0|prompt_level_strict_acc|↑  |0.7468|±  |0.0187|\n",
      "|mmlu                                   |      2|none  |      |acc                    |↑  |0.6322|±  |0.0038|\n",
      "| - humanities                          |      2|none  |      |acc                    |↑  |0.5853|±  |0.0068|\n",
      "|  - formal_logic                       |      1|none  |     0|acc                    |↑  |0.4683|±  |0.0446|\n",
      "|  - high_school_european_history       |      1|none  |     0|acc                    |↑  |0.7455|±  |0.0340|\n",
      "|  - high_school_us_history             |      1|none  |     0|acc                    |↑  |0.7892|±  |0.0286|\n",
      "|  - high_school_world_history          |      1|none  |     0|acc                    |↑  |0.8101|±  |0.0255|\n",
      "|  - international_law                  |      1|none  |     0|acc                    |↑  |0.7686|±  |0.0385|\n",
      "|  - jurisprudence                      |      1|none  |     0|acc                    |↑  |0.7315|±  |0.0428|\n",
      "|  - logical_fallacies                  |      1|none  |     0|acc                    |↑  |0.7730|±  |0.0329|\n",
      "|  - moral_disputes                     |      1|none  |     0|acc                    |↑  |0.6792|±  |0.0251|\n",
      "|  - moral_scenarios                    |      1|none  |     0|acc                    |↑  |0.4145|±  |0.0165|\n",
      "|  - philosophy                         |      1|none  |     0|acc                    |↑  |0.6945|±  |0.0262|\n",
      "|  - prehistory                         |      1|none  |     0|acc                    |↑  |0.7130|±  |0.0252|\n",
      "|  - professional_law                   |      1|none  |     0|acc                    |↑  |0.4713|±  |0.0127|\n",
      "|  - world_religions                    |      1|none  |     0|acc                    |↑  |0.8480|±  |0.0275|\n",
      "| - other                               |      2|none  |      |acc                    |↑  |0.7181|±  |0.0078|\n",
      "|  - business_ethics                    |      1|none  |     0|acc                    |↑  |0.6600|±  |0.0476|\n",
      "|  - clinical_knowledge                 |      1|none  |     0|acc                    |↑  |0.7019|±  |0.0282|\n",
      "|  - college_medicine                   |      1|none  |     0|acc                    |↑  |0.6358|±  |0.0367|\n",
      "|  - global_facts                       |      1|none  |     0|acc                    |↑  |0.4200|±  |0.0496|\n",
      "|  - human_aging                        |      1|none  |     0|acc                    |↑  |0.6771|±  |0.0314|\n",
      "|  - management                         |      1|none  |     0|acc                    |↑  |0.7961|±  |0.0399|\n",
      "|  - marketing                          |      1|none  |     0|acc                    |↑  |0.8547|±  |0.0231|\n",
      "|  - medical_genetics                   |      1|none  |     0|acc                    |↑  |0.7800|±  |0.0416|\n",
      "|  - miscellaneous                      |      1|none  |     0|acc                    |↑  |0.8110|±  |0.0140|\n",
      "|  - nutrition                          |      1|none  |     0|acc                    |↑  |0.7614|±  |0.0244|\n",
      "|  - professional_accounting            |      1|none  |     0|acc                    |↑  |0.5284|±  |0.0298|\n",
      "|  - professional_medicine              |      1|none  |     0|acc                    |↑  |0.7463|±  |0.0264|\n",
      "|  - virology                           |      1|none  |     0|acc                    |↑  |0.5783|±  |0.0384|\n",
      "| - social sciences                     |      2|none  |      |acc                    |↑  |0.7452|±  |0.0077|\n",
      "|  - econometrics                       |      1|none  |     0|acc                    |↑  |0.4561|±  |0.0469|\n",
      "|  - high_school_geography              |      1|none  |     0|acc                    |↑  |0.7980|±  |0.0286|\n",
      "|  - high_school_government_and_politics|      1|none  |     0|acc                    |↑  |0.8549|±  |0.0254|\n",
      "|  - high_school_macroeconomics         |      1|none  |     0|acc                    |↑  |0.6538|±  |0.0241|\n",
      "|  - high_school_microeconomics         |      1|none  |     0|acc                    |↑  |0.7395|±  |0.0285|\n",
      "|  - high_school_psychology             |      1|none  |     0|acc                    |↑  |0.8569|±  |0.0150|\n",
      "|  - human_sexuality                    |      1|none  |     0|acc                    |↑  |0.7557|±  |0.0377|\n",
      "|  - professional_psychology            |      1|none  |     0|acc                    |↑  |0.6846|±  |0.0188|\n",
      "|  - public_relations                   |      1|none  |     0|acc                    |↑  |0.7000|±  |0.0439|\n",
      "|  - security_studies                   |      1|none  |     0|acc                    |↑  |0.6939|±  |0.0295|\n",
      "|  - sociology                          |      1|none  |     0|acc                    |↑  |0.8358|±  |0.0262|\n",
      "|  - us_foreign_policy                  |      1|none  |     0|acc                    |↑  |0.8700|±  |0.0338|\n",
      "| - stem                                |      2|none  |      |acc                    |↑  |0.5075|±  |0.0084|\n",
      "|  - abstract_algebra                   |      1|none  |     0|acc                    |↑  |0.2700|±  |0.0446|\n",
      "|  - anatomy                            |      1|none  |     0|acc                    |↑  |0.6222|±  |0.0419|\n",
      "|  - astronomy                          |      1|none  |     0|acc                    |↑  |0.6974|±  |0.0374|\n",
      "|  - college_biology                    |      1|none  |     0|acc                    |↑  |0.7639|±  |0.0355|\n",
      "|  - college_chemistry                  |      1|none  |     0|acc                    |↑  |0.4600|±  |0.0501|\n",
      "|  - college_computer_science           |      1|none  |     0|acc                    |↑  |0.4100|±  |0.0494|\n",
      "|  - college_mathematics                |      1|none  |     0|acc                    |↑  |0.2600|±  |0.0441|\n",
      "|  - college_physics                    |      1|none  |     0|acc                    |↑  |0.4118|±  |0.0490|\n",
      "|  - computer_security                  |      1|none  |     0|acc                    |↑  |0.7200|±  |0.0451|\n",
      "|  - conceptual_physics                 |      1|none  |     0|acc                    |↑  |0.6043|±  |0.0320|\n",
      "|  - electrical_engineering             |      1|none  |     0|acc                    |↑  |0.5793|±  |0.0411|\n",
      "|  - elementary_mathematics             |      1|none  |     0|acc                    |↑  |0.3968|±  |0.0252|\n",
      "|  - high_school_biology                |      1|none  |     0|acc                    |↑  |0.7645|±  |0.0241|\n",
      "|  - high_school_chemistry              |      1|none  |     0|acc                    |↑  |0.5074|±  |0.0352|\n",
      "|  - high_school_computer_science       |      1|none  |     0|acc                    |↑  |0.6200|±  |0.0488|\n",
      "|  - high_school_mathematics            |      1|none  |     0|acc                    |↑  |0.2519|±  |0.0265|\n",
      "|  - high_school_physics                |      1|none  |     0|acc                    |↑  |0.3841|±  |0.0397|\n",
      "|  - high_school_statistics             |      1|none  |     0|acc                    |↑  |0.4167|±  |0.0336|\n",
      "|  - machine_learning                   |      1|none  |     0|acc                    |↑  |0.4643|±  |0.0473|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print results for the compressed model\n",
    "print(make_table(comp_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
