{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46dec15d-d789-4e22-b9ea-5eec04bf9230",
   "metadata": {},
   "source": [
    "## Evaluate Accuracy of the Compressed Model\n",
    "After compression, it’s important to ensure the model maintains its generative capabilities. This step evaluates the compressed model on standard benchmarks.\n",
    "\n",
    "**Goal**: Verify that compression does not degrade model quality.\n",
    "\n",
    "**Key Actions**:\n",
    "\n",
    "- We will create a function called **evaluate** that uses simple_evaluate from LM Eval to test the compressed model.\n",
    "\n",
    "- Benchmark on multiple datasets:\n",
    "\n",
    "    - MMLU: General knowledge across subjects.\n",
    "\n",
    "    - IFeval: Instruction-following tasks.\n",
    "\n",
    "    - ARC: Logical and scientific reasoning.\n",
    "    \n",
    "    - HellaSwag: Commonsense completion.\n",
    "\n",
    "- Collect metrics like accuracy, accuracy_norm, and task-specific scores.\n",
    "\n",
    "- Save results as JSON for later comparison.\n",
    "\n",
    "**Outcome**:\n",
    "\n",
    "- Quantitative metrics for the compressed model.\n",
    "\n",
    "- Confidence that the model is ready for system-level performance benchmarking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a1f45e6-3f29-4922-b85f-2b77be643530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from lm_eval.utils import make_table\n",
    "import torch\n",
    "import json\n",
    "from typing import Union\n",
    "from utils import evaluate, save_pickle, load_pickle\n",
    "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e43e6d-4fbe-4bd4-91ae-156b6a1c3af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bfb397-d989-4a4b-8636-511a25c12ed6",
   "metadata": {},
   "source": [
    "## Define evaluation benchmarking datasets\n",
    "The following benchmark datasets can be used for evaluating on multiple tasks:\n",
    "- MMLU: General knowledge across 57 subjects\n",
    "- IFeval: Instruction-following capability\n",
    "- ARC: Logical & scientific reasoning\n",
    "- HellaSwag: Commonsense completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "383befc1-e7b7-4540-af75-a3d5ce28786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tasks you want to evaluate the model on\n",
    "tasks = [\n",
    "    \"mmlu\",\n",
    "    \"arc_easy\",\n",
    "    \"hellaswag\",\n",
    "    \"ifeval\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72ddc52-4acd-4230-9681-f84201f19e33",
   "metadata": {},
   "source": [
    "### Evaluating the Compressed Model with `simple_evaluate`\n",
    "\n",
    "`simple_evaluate` is the **main entry point** in LM Evaluation Harness to evaluate a model across one or multiple benchmark datasets. It handles:\n",
    "\n",
    "1. Wrapping your model (or creating an LM object) to provide a **standardized interface**.\n",
    "2. Preparing inputs and optionally applying **few-shot examples** or **chat/instruction templates**.\n",
    "3. Running the model on benchmark tasks and collecting outputs.\n",
    "4. Computing **evaluation metrics** (accuracy, accuracy_norm, etc.) for each task.\n",
    "5. Returning a **results dictionary** that includes task-level metrics and model configuration info.\n",
    "\n",
    "We have wrapped **simple_evaluate** in a helper function **evaluate** which can be found in [utils.py](utils.py).\n",
    "\n",
    "**Key concepts:**\n",
    "\n",
    "- **LM object**:  \n",
    "  LM Evaluation Harness wraps all models (Hugging Face, custom, or preloaded) in an `LM` object. This object provides a consistent interface (`loglikelihood`, `generate`, etc.) regardless of model backend.\n",
    "\n",
    "- **model_args**:  \n",
    "  Optional dictionary or string containing model-specific arguments (e.g., temperature, top-k, top-p). Ignored if passing a pre-wrapped LM object.\n",
    "\n",
    "- **apply_chat_template**:  \n",
    "  If your model is chat-based or instruction-following, this parameter allows you to prepend a prompt template to match the model's training format.  \n",
    "  \n",
    "**Parameters used here:**\n",
    "- `model`: Path or name of the model to evaluate (can be a string or an LM object).\n",
    "- `model_args`: Optional dictionary to provide model-specific arguments (e.g., batch size, device).\n",
    "- `tasks`: List of task names or objects to evaluate.\n",
    "- `num_fewshot`: Number of examples in the few-shot context (set to 0 for zero-shot).\n",
    "- `batch_size`: Number of samples to process per batch.\n",
    "- `device`: Device to run the model on (e.g., \"cuda\" or \"cpu\").\n",
    "- `apply_chat_template`: Whether to wrap inputs in a chat-style template; useful for chat or instruction-tuned models.\n",
    "- `verbosity`: Set logging level; use `\"DEBUG\"` to inspect inputs/outputs for debugging. Default is None.\n",
    "- `log_samples`: Whether to log per-sample outputs for inspection.\n",
    "\n",
    "\n",
    "**NOTE**: Running the evaluation on the entire list of tasks can take long. So for testing, you can use a single task instead.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6b759ca-440b-4491-abba-486fe2c1afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting directories\n",
    "compressed_model_path = \"./compressed_model\"\n",
    "compressed_results_dir = \"results/compressed_accuracy\"\n",
    "base_model_path = \"./base_model\"\n",
    "base_results_dir = \"results/base_accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28c849dd-535e-442c-82e9-d1fbeed500d1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.12/site-packages/transformers/quantizers/auto.py:231: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.However, loading attributes (e.g. ['run_compressed']) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.\n",
      "  warnings.warn(warning_msg)\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.40it/s]\n",
      "Overwriting default num_fewshot of hellaswag from None to 0\n",
      "Overwriting default num_fewshot of arc_easy from None to 0\n",
      "Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
      "Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
      "Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
      "Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
      "Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
      "Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
      "Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
      "Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
      "Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
      "Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
      "Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
      "Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
      "Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
      "Overwriting default num_fewshot of mmlu_management from None to 0\n",
      "Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
      "Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
      "Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
      "Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
      "Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
      "Overwriting default num_fewshot of mmlu_virology from None to 0\n",
      "Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
      "Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
      "Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
      "Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
      "Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
      "Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
      "Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
      "Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
      "Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
      "Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
      "Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
      "Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
      "Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
      "Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
      "Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
      "Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
      "Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
      "Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.\n",
      "100%|██████████| 541/541 [00:00<00:00, 12443.21it/s]\n",
      "100%|██████████| 10042/10042 [00:03<00:00, 2971.91it/s]\n",
      "100%|██████████| 2376/2376 [00:01<00:00, 1390.63it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 817.37it/s]\n",
      "100%|██████████| 135/135 [00:00<00:00, 816.20it/s]\n",
      "100%|██████████| 152/152 [00:00<00:00, 827.46it/s]\n",
      "100%|██████████| 144/144 [00:00<00:00, 831.21it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 828.54it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 818.43it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 808.04it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 820.84it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 812.33it/s]\n",
      "100%|██████████| 235/235 [00:00<00:00, 270.68it/s]\n",
      "100%|██████████| 145/145 [00:00<00:00, 823.98it/s]\n",
      "100%|██████████| 378/378 [00:00<00:00, 822.53it/s]\n",
      "100%|██████████| 310/310 [00:00<00:00, 827.95it/s]\n",
      "100%|██████████| 203/203 [00:00<00:00, 826.42it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 798.25it/s]\n",
      "100%|██████████| 270/270 [00:00<00:00, 825.71it/s]\n",
      "100%|██████████| 151/151 [00:00<00:00, 827.05it/s]\n",
      "100%|██████████| 216/216 [00:00<00:00, 826.38it/s]\n",
      "100%|██████████| 112/112 [00:00<00:00, 821.68it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 819.86it/s]\n",
      "100%|██████████| 265/265 [00:00<00:00, 821.21it/s]\n",
      "100%|██████████| 173/173 [00:00<00:00, 823.82it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 789.60it/s]\n",
      "100%|██████████| 223/223 [00:00<00:00, 827.90it/s]\n",
      "100%|██████████| 103/103 [00:00<00:00, 824.61it/s]\n",
      "100%|██████████| 234/234 [00:00<00:00, 827.25it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 821.27it/s]\n",
      "100%|██████████| 783/783 [00:00<00:00, 829.12it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 828.85it/s]\n",
      "100%|██████████| 282/282 [00:00<00:00, 820.68it/s]\n",
      "100%|██████████| 272/272 [00:00<00:00, 819.57it/s]\n",
      "100%|██████████| 166/166 [00:00<00:00, 820.41it/s]\n",
      "100%|██████████| 114/114 [00:00<00:00, 822.17it/s]\n",
      "100%|██████████| 198/198 [00:00<00:00, 814.66it/s]\n",
      "100%|██████████| 193/193 [00:00<00:00, 817.59it/s]\n",
      "100%|██████████| 390/390 [00:00<00:00, 825.22it/s]\n",
      "100%|██████████| 238/238 [00:00<00:00, 826.41it/s]\n",
      "100%|██████████| 545/545 [00:00<00:00, 824.48it/s]\n",
      "100%|██████████| 131/131 [00:00<00:00, 826.77it/s]\n",
      "100%|██████████| 612/612 [00:00<00:00, 823.27it/s]\n",
      "100%|██████████| 110/110 [00:00<00:00, 822.25it/s]\n",
      "100%|██████████| 245/245 [00:00<00:00, 824.97it/s]\n",
      "100%|██████████| 201/201 [00:00<00:00, 827.03it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 809.94it/s]\n",
      "100%|██████████| 126/126 [00:00<00:00, 818.51it/s]\n",
      "100%|██████████| 165/165 [00:00<00:00, 821.97it/s]\n",
      "100%|██████████| 204/204 [00:00<00:00, 822.15it/s]\n",
      "100%|██████████| 237/237 [00:00<00:00, 816.17it/s]\n",
      "100%|██████████| 121/121 [00:00<00:00, 829.47it/s]\n",
      "100%|██████████| 108/108 [00:00<00:00, 821.83it/s]\n",
      "100%|██████████| 163/163 [00:00<00:00, 824.46it/s]\n",
      "100%|██████████| 346/346 [00:00<00:00, 822.23it/s]\n",
      "100%|██████████| 895/895 [00:01<00:00, 816.03it/s]\n",
      "100%|██████████| 311/311 [00:00<00:00, 824.87it/s]\n",
      "100%|██████████| 324/324 [00:00<00:00, 826.23it/s]\n",
      "100%|██████████| 1534/1534 [00:01<00:00, 824.38it/s]\n",
      "100%|██████████| 171/171 [00:00<00:00, 825.65it/s]\n",
      "Running generate_until requests:   0%|          | 0/541 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:   0%|          | 1/541 [07:33<68:02:05, 453.57s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:   3%|▎         | 17/541 [11:00<4:34:01, 31.38s/it] The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:   6%|▌         | 33/541 [18:20<4:06:44, 29.14s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:   9%|▉         | 49/541 [23:36<3:24:08, 24.90s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  12%|█▏        | 65/541 [27:52<2:49:54, 21.42s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  15%|█▍        | 81/541 [34:40<2:55:26, 22.88s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  18%|█▊        | 97/541 [41:59<3:00:45, 24.43s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  21%|██        | 113/541 [46:35<2:37:30, 22.08s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  24%|██▍       | 129/541 [50:58<2:19:18, 20.29s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  27%|██▋       | 145/541 [55:23<2:06:12, 19.12s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  33%|███▎      | 177/541 [1:08:28<2:14:40, 22.20s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  36%|███▌      | 193/541 [1:12:14<1:54:34, 19.75s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  39%|███▊      | 209/541 [1:17:10<1:47:08, 19.36s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  42%|████▏     | 225/541 [1:21:09<1:34:58, 18.03s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  45%|████▍     | 241/541 [1:25:25<1:27:06, 17.42s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  48%|████▊     | 257/541 [1:32:44<1:36:45, 20.44s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  50%|█████     | 273/541 [1:37:12<1:26:20, 19.33s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  53%|█████▎    | 289/541 [1:44:32<1:31:26, 21.77s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  56%|█████▋    | 305/541 [1:47:54<1:14:50, 19.03s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  59%|█████▉    | 321/541 [1:55:11<1:18:53, 21.51s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  62%|██████▏   | 337/541 [2:01:42<1:16:10, 22.40s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  65%|██████▌   | 353/541 [2:09:01<1:14:53, 23.90s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  68%|██████▊   | 369/541 [2:16:19<1:11:32, 24.95s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  71%|███████   | 385/541 [2:22:58<1:04:50, 24.94s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  74%|███████▍  | 401/541 [2:30:16<59:55, 25.68s/it]  The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  77%|███████▋  | 417/541 [2:34:06<46:03, 22.28s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  80%|████████  | 433/541 [2:41:24<42:51, 23.81s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  83%|████████▎ | 449/541 [2:48:42<38:09, 24.89s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  86%|████████▌ | 465/541 [2:52:23<27:18, 21.56s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  89%|████████▉ | 481/541 [2:59:41<23:18, 23.31s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  92%|█████████▏| 497/541 [3:04:10<15:39, 21.35s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:  95%|█████████▍| 513/541 [3:11:27<10:48, 23.15s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests: 100%|██████████| 541/541 [3:14:26<00:00, 21.56s/it]\n",
      "Running loglikelihood requests: 100%|██████████| 105837/105837 [32:47<00:00, 53.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# evaluate the compressed model and save results in pkl format\n",
    "comp_acc = evaluate(compressed_model_path, tasks, limit=None, batch_size=16, apply_chat_template=True, verbosity=None)\n",
    "save_pickle(compressed_results_dir, comp_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daff8288-c452-4d04-89cc-ddf57339469b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.82it/s]\n",
      "Overwriting default num_fewshot of hellaswag from None to 0\n",
      "Overwriting default num_fewshot of arc_easy from None to 0\n",
      "Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
      "Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
      "Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
      "Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
      "Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
      "Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
      "Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
      "Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
      "Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
      "Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
      "Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
      "Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
      "Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
      "Overwriting default num_fewshot of mmlu_management from None to 0\n",
      "Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
      "Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
      "Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
      "Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
      "Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
      "Overwriting default num_fewshot of mmlu_virology from None to 0\n",
      "Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
      "Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
      "Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
      "Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
      "Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
      "Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
      "Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
      "Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
      "Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
      "Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
      "Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
      "Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
      "Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
      "Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
      "Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
      "Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
      "Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
      "Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
      "Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.\n",
      "100%|██████████| 541/541 [00:00<00:00, 12945.38it/s]\n",
      "100%|██████████| 10042/10042 [00:03<00:00, 2590.55it/s]\n",
      "100%|██████████| 2376/2376 [00:01<00:00, 1399.80it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 811.92it/s]\n",
      "100%|██████████| 135/135 [00:00<00:00, 827.36it/s]\n",
      "100%|██████████| 152/152 [00:00<00:00, 831.36it/s]\n",
      "100%|██████████| 144/144 [00:00<00:00, 830.78it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 828.51it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 827.13it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 825.63it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 821.03it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 825.57it/s]\n",
      "100%|██████████| 235/235 [00:00<00:00, 825.43it/s]\n",
      "100%|██████████| 145/145 [00:00<00:00, 833.96it/s]\n",
      "100%|██████████| 378/378 [00:00<00:00, 828.07it/s]\n",
      "100%|██████████| 310/310 [00:00<00:00, 827.59it/s]\n",
      "100%|██████████| 203/203 [00:00<00:00, 826.35it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 825.08it/s]\n",
      "100%|██████████| 270/270 [00:00<00:00, 825.37it/s]\n",
      "100%|██████████| 151/151 [00:00<00:00, 833.01it/s]\n",
      "100%|██████████| 216/216 [00:00<00:00, 828.60it/s]\n",
      "100%|██████████| 112/112 [00:00<00:00, 829.83it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 817.94it/s]\n",
      "100%|██████████| 265/265 [00:00<00:00, 827.49it/s]\n",
      "100%|██████████| 173/173 [00:00<00:00, 830.32it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 827.76it/s]\n",
      "100%|██████████| 223/223 [00:00<00:00, 829.34it/s]\n",
      "100%|██████████| 103/103 [00:00<00:00, 824.26it/s]\n",
      "100%|██████████| 234/234 [00:00<00:00, 834.47it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 818.09it/s]\n",
      "100%|██████████| 783/783 [00:00<00:00, 829.34it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 831.82it/s]\n",
      "100%|██████████| 282/282 [00:00<00:00, 826.27it/s]\n",
      "100%|██████████| 272/272 [00:00<00:00, 825.15it/s]\n",
      "100%|██████████| 166/166 [00:00<00:00, 833.14it/s]\n",
      "100%|██████████| 114/114 [00:00<00:00, 821.92it/s]\n",
      "100%|██████████| 198/198 [00:00<00:00, 827.37it/s]\n",
      "100%|██████████| 193/193 [00:00<00:00, 830.08it/s]\n",
      "100%|██████████| 390/390 [00:00<00:00, 833.23it/s]\n",
      "100%|██████████| 238/238 [00:00<00:00, 832.24it/s]\n",
      "100%|██████████| 545/545 [00:00<00:00, 830.70it/s]\n",
      "100%|██████████| 131/131 [00:00<00:00, 817.85it/s]\n",
      "100%|██████████| 612/612 [00:00<00:00, 827.32it/s]\n",
      "100%|██████████| 110/110 [00:00<00:00, 829.38it/s]\n",
      "100%|██████████| 245/245 [00:00<00:00, 829.37it/s]\n",
      "100%|██████████| 201/201 [00:00<00:00, 833.61it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 829.46it/s]\n",
      "100%|██████████| 126/126 [00:00<00:00, 826.23it/s]\n",
      "100%|██████████| 165/165 [00:00<00:00, 825.79it/s]\n",
      "100%|██████████| 204/204 [00:00<00:00, 816.76it/s]\n",
      "100%|██████████| 237/237 [00:00<00:00, 829.17it/s]\n",
      "100%|██████████| 121/121 [00:00<00:00, 827.07it/s]\n",
      "100%|██████████| 108/108 [00:00<00:00, 826.84it/s]\n",
      "100%|██████████| 163/163 [00:00<00:00, 830.65it/s]\n",
      "100%|██████████| 346/346 [00:00<00:00, 830.82it/s]\n",
      "100%|██████████| 895/895 [00:01<00:00, 834.89it/s]\n",
      "100%|██████████| 311/311 [00:00<00:00, 834.58it/s]\n",
      "100%|██████████| 324/324 [00:00<00:00, 826.67it/s]\n",
      "100%|██████████| 1534/1534 [00:01<00:00, 827.12it/s]\n",
      "100%|██████████| 171/171 [00:00<00:00, 825.76it/s]\n",
      "Running generate_until requests:   0%|          | 0/541 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed argument batch_size = auto. Detecting largest batch size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determined Largest batch size: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running generate_until requests:   0%|          | 1/541 [00:22<3:20:11, 22.24s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:   0%|          | 2/541 [00:25<1:41:14, 11.27s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:   1%|          | 3/541 [00:29<1:11:45,  8.00s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:   1%|          | 4/541 [00:55<2:12:20, 14.79s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:   1%|          | 5/541 [01:16<2:32:19, 17.05s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:   1%|          | 6/541 [01:22<1:58:20, 13.27s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:   1%|▏         | 7/541 [01:26<1:30:55, 10.22s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:   1%|▏         | 8/541 [01:36<1:31:09, 10.26s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:   2%|▏         | 9/541 [01:43<1:21:23,  9.18s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Running generate_until requests:   2%|▏         | 10/541 [01:45<1:02:02,  7.01s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "# evaluate the base model and save results in pkl format\n",
    "base_acc = evaluate(base_model_path, tasks, limit=None, batch_size=\"auto\", apply_chat_template=True, verbosity=None)\n",
    "save_pickle(base_results_dir, base_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c20e51ac-f4c3-4276-b2fe-df595a963443",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_results = load_pickle(base_results_dir)\n",
    "comp_results = load_pickle(compressed_results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36511cfb-fac8-4f8c-be17-c2d98ffb8560",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                 Tasks                  |Version|Filter|n-shot|        Metric         |   |Value |   |Stderr|\n",
      "|----------------------------------------|------:|------|-----:|-----------------------|---|-----:|---|------|\n",
      "|arc_easy                                |      1|none  |     0|acc                    |↑  |0.8127|±  |0.0080|\n",
      "|                                        |       |none  |     0|acc_norm               |↑  |0.7588|±  |0.0088|\n",
      "|hellaswag                               |      1|none  |     0|acc                    |↑  |0.5742|±  |0.0049|\n",
      "|                                        |       |none  |     0|acc_norm               |↑  |0.7254|±  |0.0045|\n",
      "|ifeval                                  |      4|none  |     0|inst_level_loose_acc   |↑  |0.8513|±  |   N/A|\n",
      "|                                        |       |none  |     0|inst_level_strict_acc  |↑  |0.8189|±  |   N/A|\n",
      "|                                        |       |none  |     0|prompt_level_loose_acc |↑  |0.7874|±  |0.0176|\n",
      "|                                        |       |none  |     0|prompt_level_strict_acc|↑  |0.7449|±  |0.0188|\n",
      "|mmlu                                    |      2|none  |      |acc                    |↑  |0.6321|±  |0.0038|\n",
      "|mmlu_humanities                         |      2|none  |      |acc                    |↑  |0.5868|±  |0.0068|\n",
      "|mmlu_formal_logic                       |      1|none  |     0|acc                    |↑  |0.5000|±  |0.0447|\n",
      "|mmlu_high_school_european_history       |      1|none  |     0|acc                    |↑  |0.7455|±  |0.0340|\n",
      "|mmlu_high_school_us_history             |      1|none  |     0|acc                    |↑  |0.7892|±  |0.0286|\n",
      "|mmlu_high_school_world_history          |      1|none  |     0|acc                    |↑  |0.8186|±  |0.0251|\n",
      "|mmlu_international_law                  |      1|none  |     0|acc                    |↑  |0.7686|±  |0.0385|\n",
      "|mmlu_jurisprudence                      |      1|none  |     0|acc                    |↑  |0.7315|±  |0.0428|\n",
      "|mmlu_logical_fallacies                  |      1|none  |     0|acc                    |↑  |0.7730|±  |0.0329|\n",
      "|mmlu_moral_disputes                     |      1|none  |     0|acc                    |↑  |0.6792|±  |0.0251|\n",
      "|mmlu_moral_scenarios                    |      1|none  |     0|acc                    |↑  |0.4190|±  |0.0165|\n",
      "|mmlu_philosophy                         |      1|none  |     0|acc                    |↑  |0.6977|±  |0.0261|\n",
      "|mmlu_prehistory                         |      1|none  |     0|acc                    |↑  |0.7130|±  |0.0252|\n",
      "|mmlu_professional_law                   |      1|none  |     0|acc                    |↑  |0.4687|±  |0.0127|\n",
      "|mmlu_world_religions                    |      1|none  |     0|acc                    |↑  |0.8480|±  |0.0275|\n",
      "|mmlu_other                              |      2|none  |      |acc                    |↑  |0.7177|±  |0.0078|\n",
      "|mmlu_business_ethics                    |      1|none  |     0|acc                    |↑  |0.6500|±  |0.0479|\n",
      "|mmlu_clinical_knowledge                 |      1|none  |     0|acc                    |↑  |0.7094|±  |0.0279|\n",
      "|mmlu_college_medicine                   |      1|none  |     0|acc                    |↑  |0.6416|±  |0.0366|\n",
      "|mmlu_global_facts                       |      1|none  |     0|acc                    |↑  |0.4200|±  |0.0496|\n",
      "|mmlu_human_aging                        |      1|none  |     0|acc                    |↑  |0.6771|±  |0.0314|\n",
      "|mmlu_management                         |      1|none  |     0|acc                    |↑  |0.8058|±  |0.0392|\n",
      "|mmlu_marketing                          |      1|none  |     0|acc                    |↑  |0.8547|±  |0.0231|\n",
      "|mmlu_medical_genetics                   |      1|none  |     0|acc                    |↑  |0.8000|±  |0.0402|\n",
      "|mmlu_miscellaneous                      |      1|none  |     0|acc                    |↑  |0.8084|±  |0.0141|\n",
      "|mmlu_nutrition                          |      1|none  |     0|acc                    |↑  |0.7516|±  |0.0247|\n",
      "|mmlu_professional_accounting            |      1|none  |     0|acc                    |↑  |0.5177|±  |0.0298|\n",
      "|mmlu_professional_medicine              |      1|none  |     0|acc                    |↑  |0.7610|±  |0.0259|\n",
      "|mmlu_virology                           |      1|none  |     0|acc                    |↑  |0.5663|±  |0.0386|\n",
      "|mmlu_social_sciences                    |      2|none  |      |acc                    |↑  |0.7442|±  |0.0077|\n",
      "|mmlu_econometrics                       |      1|none  |     0|acc                    |↑  |0.4386|±  |0.0467|\n",
      "|mmlu_high_school_geography              |      1|none  |     0|acc                    |↑  |0.7929|±  |0.0289|\n",
      "|mmlu_high_school_government_and_politics|      1|none  |     0|acc                    |↑  |0.8497|±  |0.0258|\n",
      "|mmlu_high_school_macroeconomics         |      1|none  |     0|acc                    |↑  |0.6564|±  |0.0241|\n",
      "|mmlu_high_school_microeconomics         |      1|none  |     0|acc                    |↑  |0.7479|±  |0.0282|\n",
      "|mmlu_high_school_psychology             |      1|none  |     0|acc                    |↑  |0.8642|±  |0.0147|\n",
      "|mmlu_human_sexuality                    |      1|none  |     0|acc                    |↑  |0.7634|±  |0.0373|\n",
      "|mmlu_professional_psychology            |      1|none  |     0|acc                    |↑  |0.6797|±  |0.0189|\n",
      "|mmlu_public_relations                   |      1|none  |     0|acc                    |↑  |0.6909|±  |0.0443|\n",
      "|mmlu_security_studies                   |      1|none  |     0|acc                    |↑  |0.6898|±  |0.0296|\n",
      "|mmlu_sociology                          |      1|none  |     0|acc                    |↑  |0.8308|±  |0.0265|\n",
      "|mmlu_us_foreign_policy                  |      1|none  |     0|acc                    |↑  |0.8600|±  |0.0349|\n",
      "|mmlu_stem                               |      2|none  |      |acc                    |↑  |0.5059|±  |0.0084|\n",
      "|mmlu_abstract_algebra                   |      1|none  |     0|acc                    |↑  |0.2700|±  |0.0446|\n",
      "|mmlu_anatomy                            |      1|none  |     0|acc                    |↑  |0.6222|±  |0.0419|\n",
      "|mmlu_astronomy                          |      1|none  |     0|acc                    |↑  |0.7039|±  |0.0372|\n",
      "|mmlu_college_biology                    |      1|none  |     0|acc                    |↑  |0.7639|±  |0.0355|\n",
      "|mmlu_college_chemistry                  |      1|none  |     0|acc                    |↑  |0.4700|±  |0.0502|\n",
      "|mmlu_college_computer_science           |      1|none  |     0|acc                    |↑  |0.4100|±  |0.0494|\n",
      "|mmlu_college_mathematics                |      1|none  |     0|acc                    |↑  |0.2800|±  |0.0451|\n",
      "|mmlu_college_physics                    |      1|none  |     0|acc                    |↑  |0.3824|±  |0.0484|\n",
      "|mmlu_computer_security                  |      1|none  |     0|acc                    |↑  |0.7200|±  |0.0451|\n",
      "|mmlu_conceptual_physics                 |      1|none  |     0|acc                    |↑  |0.5915|±  |0.0321|\n",
      "|mmlu_electrical_engineering             |      1|none  |     0|acc                    |↑  |0.5724|±  |0.0412|\n",
      "|mmlu_elementary_mathematics             |      1|none  |     0|acc                    |↑  |0.3942|±  |0.0252|\n",
      "|mmlu_high_school_biology                |      1|none  |     0|acc                    |↑  |0.7581|±  |0.0244|\n",
      "|mmlu_high_school_chemistry              |      1|none  |     0|acc                    |↑  |0.5123|±  |0.0352|\n",
      "|mmlu_high_school_computer_science       |      1|none  |     0|acc                    |↑  |0.6100|±  |0.0490|\n",
      "|mmlu_high_school_mathematics            |      1|none  |     0|acc                    |↑  |0.2481|±  |0.0263|\n",
      "|mmlu_high_school_physics                |      1|none  |     0|acc                    |↑  |0.3709|±  |0.0394|\n",
      "|mmlu_high_school_statistics             |      1|none  |     0|acc                    |↑  |0.4213|±  |0.0337|\n",
      "|mmlu_machine_learning                   |      1|none  |     0|acc                    |↑  |0.4911|±  |0.0475|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the results\n",
    "print(make_table(base_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd79a881-9bcc-4860-a3a1-7b7da82d0138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                 Tasks                  |Version|Filter|n-shot|        Metric         |   |Value |   |Stderr|\n",
      "|----------------------------------------|------:|------|-----:|-----------------------|---|-----:|---|------|\n",
      "|arc_easy                                |      1|none  |     0|acc                    |↑  |0.8106|±  |0.0080|\n",
      "|                                        |       |none  |     0|acc_norm               |↑  |0.7572|±  |0.0088|\n",
      "|hellaswag                               |      1|none  |     0|acc                    |↑  |0.5750|±  |0.0049|\n",
      "|                                        |       |none  |     0|acc_norm               |↑  |0.7249|±  |0.0045|\n",
      "|ifeval                                  |      4|none  |     0|inst_level_loose_acc   |↑  |0.8621|±  |   N/A|\n",
      "|                                        |       |none  |     0|inst_level_strict_acc  |↑  |0.8309|±  |   N/A|\n",
      "|                                        |       |none  |     0|prompt_level_loose_acc |↑  |0.7967|±  |0.0173|\n",
      "|                                        |       |none  |     0|prompt_level_strict_acc|↑  |0.7542|±  |0.0185|\n",
      "|mmlu                                    |      2|none  |      |acc                    |↑  |0.6315|±  |0.0038|\n",
      "|mmlu_humanities                         |      2|none  |      |acc                    |↑  |0.5847|±  |0.0068|\n",
      "|mmlu_formal_logic                       |      1|none  |     0|acc                    |↑  |0.4841|±  |0.0447|\n",
      "|mmlu_high_school_european_history       |      1|none  |     0|acc                    |↑  |0.7455|±  |0.0340|\n",
      "|mmlu_high_school_us_history             |      1|none  |     0|acc                    |↑  |0.7941|±  |0.0284|\n",
      "|mmlu_high_school_world_history          |      1|none  |     0|acc                    |↑  |0.8186|±  |0.0251|\n",
      "|mmlu_international_law                  |      1|none  |     0|acc                    |↑  |0.7686|±  |0.0385|\n",
      "|mmlu_jurisprudence                      |      1|none  |     0|acc                    |↑  |0.7407|±  |0.0424|\n",
      "|mmlu_logical_fallacies                  |      1|none  |     0|acc                    |↑  |0.7607|±  |0.0335|\n",
      "|mmlu_moral_disputes                     |      1|none  |     0|acc                    |↑  |0.6734|±  |0.0252|\n",
      "|mmlu_moral_scenarios                    |      1|none  |     0|acc                    |↑  |0.4078|±  |0.0164|\n",
      "|mmlu_philosophy                         |      1|none  |     0|acc                    |↑  |0.6945|±  |0.0262|\n",
      "|mmlu_prehistory                         |      1|none  |     0|acc                    |↑  |0.7099|±  |0.0253|\n",
      "|mmlu_professional_law                   |      1|none  |     0|acc                    |↑  |0.4726|±  |0.0128|\n",
      "|mmlu_world_religions                    |      1|none  |     0|acc                    |↑  |0.8480|±  |0.0275|\n",
      "|mmlu_other                              |      2|none  |      |acc                    |↑  |0.7190|±  |0.0078|\n",
      "|mmlu_business_ethics                    |      1|none  |     0|acc                    |↑  |0.6700|±  |0.0473|\n",
      "|mmlu_clinical_knowledge                 |      1|none  |     0|acc                    |↑  |0.7132|±  |0.0278|\n",
      "|mmlu_college_medicine                   |      1|none  |     0|acc                    |↑  |0.6358|±  |0.0367|\n",
      "|mmlu_global_facts                       |      1|none  |     0|acc                    |↑  |0.4200|±  |0.0496|\n",
      "|mmlu_human_aging                        |      1|none  |     0|acc                    |↑  |0.6816|±  |0.0313|\n",
      "|mmlu_management                         |      1|none  |     0|acc                    |↑  |0.7961|±  |0.0399|\n",
      "|mmlu_marketing                          |      1|none  |     0|acc                    |↑  |0.8590|±  |0.0228|\n",
      "|mmlu_medical_genetics                   |      1|none  |     0|acc                    |↑  |0.7800|±  |0.0416|\n",
      "|mmlu_miscellaneous                      |      1|none  |     0|acc                    |↑  |0.8135|±  |0.0139|\n",
      "|mmlu_nutrition                          |      1|none  |     0|acc                    |↑  |0.7549|±  |0.0246|\n",
      "|mmlu_professional_accounting            |      1|none  |     0|acc                    |↑  |0.5177|±  |0.0298|\n",
      "|mmlu_professional_medicine              |      1|none  |     0|acc                    |↑  |0.7537|±  |0.0262|\n",
      "|mmlu_virology                           |      1|none  |     0|acc                    |↑  |0.5663|±  |0.0386|\n",
      "|mmlu_social_sciences                    |      2|none  |      |acc                    |↑  |0.7452|±  |0.0077|\n",
      "|mmlu_econometrics                       |      1|none  |     0|acc                    |↑  |0.4386|±  |0.0467|\n",
      "|mmlu_high_school_geography              |      1|none  |     0|acc                    |↑  |0.7828|±  |0.0294|\n",
      "|mmlu_high_school_government_and_politics|      1|none  |     0|acc                    |↑  |0.8497|±  |0.0258|\n",
      "|mmlu_high_school_macroeconomics         |      1|none  |     0|acc                    |↑  |0.6615|±  |0.0240|\n",
      "|mmlu_high_school_microeconomics         |      1|none  |     0|acc                    |↑  |0.7521|±  |0.0280|\n",
      "|mmlu_high_school_psychology             |      1|none  |     0|acc                    |↑  |0.8606|±  |0.0149|\n",
      "|mmlu_human_sexuality                    |      1|none  |     0|acc                    |↑  |0.7634|±  |0.0373|\n",
      "|mmlu_professional_psychology            |      1|none  |     0|acc                    |↑  |0.6863|±  |0.0188|\n",
      "|mmlu_public_relations                   |      1|none  |     0|acc                    |↑  |0.7000|±  |0.0439|\n",
      "|mmlu_security_studies                   |      1|none  |     0|acc                    |↑  |0.6857|±  |0.0297|\n",
      "|mmlu_sociology                          |      1|none  |     0|acc                    |↑  |0.8259|±  |0.0268|\n",
      "|mmlu_us_foreign_policy                  |      1|none  |     0|acc                    |↑  |0.8700|±  |0.0338|\n",
      "|mmlu_stem                               |      2|none  |      |acc                    |↑  |0.5043|±  |0.0084|\n",
      "|mmlu_abstract_algebra                   |      1|none  |     0|acc                    |↑  |0.2600|±  |0.0441|\n",
      "|mmlu_anatomy                            |      1|none  |     0|acc                    |↑  |0.6296|±  |0.0417|\n",
      "|mmlu_astronomy                          |      1|none  |     0|acc                    |↑  |0.6842|±  |0.0378|\n",
      "|mmlu_college_biology                    |      1|none  |     0|acc                    |↑  |0.7569|±  |0.0359|\n",
      "|mmlu_college_chemistry                  |      1|none  |     0|acc                    |↑  |0.4700|±  |0.0502|\n",
      "|mmlu_college_computer_science           |      1|none  |     0|acc                    |↑  |0.4200|±  |0.0496|\n",
      "|mmlu_college_mathematics                |      1|none  |     0|acc                    |↑  |0.2700|±  |0.0446|\n",
      "|mmlu_college_physics                    |      1|none  |     0|acc                    |↑  |0.4118|±  |0.0490|\n",
      "|mmlu_computer_security                  |      1|none  |     0|acc                    |↑  |0.7200|±  |0.0451|\n",
      "|mmlu_conceptual_physics                 |      1|none  |     0|acc                    |↑  |0.5915|±  |0.0321|\n",
      "|mmlu_electrical_engineering             |      1|none  |     0|acc                    |↑  |0.5862|±  |0.0410|\n",
      "|mmlu_elementary_mathematics             |      1|none  |     0|acc                    |↑  |0.4021|±  |0.0253|\n",
      "|mmlu_high_school_biology                |      1|none  |     0|acc                    |↑  |0.7548|±  |0.0245|\n",
      "|mmlu_high_school_chemistry              |      1|none  |     0|acc                    |↑  |0.5074|±  |0.0352|\n",
      "|mmlu_high_school_computer_science       |      1|none  |     0|acc                    |↑  |0.6000|±  |0.0492|\n",
      "|mmlu_high_school_mathematics            |      1|none  |     0|acc                    |↑  |0.2519|±  |0.0265|\n",
      "|mmlu_high_school_physics                |      1|none  |     0|acc                    |↑  |0.3642|±  |0.0393|\n",
      "|mmlu_high_school_statistics             |      1|none  |     0|acc                    |↑  |0.4074|±  |0.0335|\n",
      "|mmlu_machine_learning                   |      1|none  |     0|acc                    |↑  |0.4643|±  |0.0473|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(make_table(comp_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b54815-5261-4ef8-b970-f52e95f2bdb9",
   "metadata": {},
   "source": [
    "## Observation\n",
    "Comparing the accuracies of the base and compressed models shows that the compressed model performs very similarly to the base model across most tasks. While there are small variations in some task-level metrics, the overall accuracy drop is minimal, demonstrating that compression (e.g., quantization to 8-bit) maintains the model’s capabilities effectively.\n",
    "\n",
    "This indicates that the compressed model is suitable for deployment scenarios where reduced memory footprint and faster inference are required, without significantly sacrificing performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
