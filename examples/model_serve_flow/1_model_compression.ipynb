{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7375209-d552-4543-9e7f-1c9a03117314",
   "metadata": {},
   "source": [
    "## Compress the Base LLM using LLM Compressor:\n",
    "In this step, the base large language model is compressed to reduce its memory footprint and improve inference efficiency without significantly impacting accuracy.\n",
    "\n",
    "**Goal**: Reduce model size (e.g., FP16 → INT8/INT4) while retaining performance.\n",
    "\n",
    "**Key Actions**:\n",
    "\n",
    "- Load the base model.\n",
    "\n",
    "- Measure its size and memory usage.\n",
    "\n",
    "- Apply a quantization recipe (e.g., SmoothQuant + GPTQ modifier).\n",
    "\n",
    "- Use a calibration dataset (e.g., WikiText, UltraChat) to collect activation statistics.\n",
    "\n",
    "- Save the compressed model and verify size reduction.\n",
    "\n",
    "**Outcome**:\n",
    "\n",
    "- Compressed model saved on disk.\n",
    "\n",
    "- Model size reduced, typically by 50% (depending on quantization scheme)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7d76ec6-9bab-4a4b-bda8-0e5663510937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "from llmcompressor.modifiers.quantization import QuantizationModifier, GPTQModifier\n",
    "from llmcompressor.modifiers.smoothquant import SmoothQuantModifier\n",
    "from llmcompressor import oneshot\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import os\n",
    "from utils import model_size_gb, tokenize_for_calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0bb9620-ca7b-44e4-bc75-b2de8bd992c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check available device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6585cb-614e-403b-beb1-36a9c03f66b8",
   "metadata": {},
   "source": [
    "## Loading Base Model\n",
    "You can use the model of your choice by modifying the \"model_name\" variable.\n",
    "While loading the model using **from_pretrained** using transformers' **AutoModelForCausalLM** class, we specify the data type using the **torch_dtype** parameter and set it to **auto** so the model is loaded in the data type specified in its config.\n",
    "Otherwise, PyTorch loads the weights in **full precision (fp32)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "799031ae-0932-4924-86e6-68d7917c482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up variables\n",
    "# model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "# model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "# model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "model_name = \"RedHatAI/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "base_model_path = \"./base_model\"\n",
    "compressed_model_path = \"./compressed_model\"\n",
    "\n",
    "# base_model_path = \"./base_model_lama\"\n",
    "# compressed_model_path = \"./compressed_model_lama\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb655abf-5d22-49e4-b278-eb5d92fa26d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model saved at: ./base_model\n"
     ]
    }
   ],
   "source": [
    "# loading model and tokenizer from huggingfaceabs\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             torch_dtype=\"auto\",\n",
    "                                             device_map=\"auto\")\n",
    "\n",
    "# saving model and tokenizer\n",
    "model.save_pretrained(base_model_path)\n",
    "tokenizer.save_pretrained(base_model_path)\n",
    "\n",
    "print(\"Base model saved at:\", base_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5725441f-ed72-44fd-8f6d-8db56b637049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the base model is: 14.9575GB\n"
     ]
    }
   ],
   "source": [
    "# check model size   \n",
    "# !du -sh {base_model_path}\n",
    "model_size = model_size_gb(model)\n",
    "print(f\"The size of the base model is: {model_size:.4f}GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20f28eb-1122-416d-bb31-40ee900b1ddc",
   "metadata": {},
   "source": [
    "## Data Aware Weight+Activation Quantization\n",
    "\n",
    "- Use a calibration dataset to avoid data distribution drift after quantization\n",
    "- Scheme for quantization is \"W8A8\"; convert both weights and activations to INT8 (can be W4A4 as well)\n",
    "- Activations are quantized on the fly during inference)\n",
    "\n",
    "### Things to keep in mind for data aware quantization\n",
    "1. **Choice of Calibration Dataset:** GPTQ quantization estimates activation ranges from calibration data. If the calibration data is very different from what the model will see in production, these ranges may be inaccurate, leading to higher quantization errors and degraded model outputs.\n",
    "\n",
    "   For production, use a dataset that closely resembles the expected domain(e.g finance, medicine etc), task(Q/A,    summarization etc), and style of your inputs to ensure quantization preserves quality.\n",
    "\n",
    "    For the sake of this demo, we can use a small, general-purpose dataset for faster processing. Specifically, we use the `wikitext-2-raw-v1` version of the WikiText dataset which is the smaller version.\n",
    "\n",
    "2. **Number of Calibration Samples Used for Quantization**\n",
    "\n",
    "     More samples give better and stable statistics on the range and distribution of activations, which reduces quantization noise. Small calibration sets, on the other hand, are quicker but noisier.\n",
    "    \n",
    "    For the sake of this demo, we use a small number of samples (e.g., 16–512) is enough to show the process.\n",
    "    \n",
    "    For production, use a larger\n",
    "\n",
    "   sample set (hundreds to thousands) to stabilize ranges and minimize error.\n",
    "\n",
    "4. **Sequence Length**\n",
    "\n",
    "    Longer input sequences generate larger activations because each token’s representation depends on all previous tokens and layers. These bigger values can exceed the quantization range (e.g., -128 to 127 for 8-bit quantization), causing rounding errors or clipping, which reduces accuracy.\n",
    "    \n",
    "    For this demo, shorter sequences are sufficient to illustrate quantization.\n",
    "    \n",
    "    For production, use sequences that reflect maximum expected lengths in your application to prevent errors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701b8093-b984-4d58-a552-65692dc7944c",
   "metadata": {},
   "source": [
    "### Preparing Calibration Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de6dd2e2-58d1-47e8-b17b-2a0d78627e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset to use for calibration\n",
    "dataset_id = \"wikitext\"  \n",
    "\n",
    "# Specify the configuration / version of the dataset\n",
    "config = \"wikitext-2-raw-v1\"  # Small version (~2M tokens), raw text format\n",
    "\n",
    "# Set the number of calibration samples based on available device\n",
    "# - On GPU: use more samples to get more accurate activation statistics\n",
    "# - On CPU: reduce samples to prevent memory issues and keep demo fast\n",
    "num_calibration_samples = 512 if device == \"cuda\" else 16  \n",
    "\n",
    "# Set the maximum sequence length for calibration\n",
    "max_sequence_length = 1024 if device == \"cuda\" else 16  \n",
    "\n",
    "# Load the dataset using Hugging Face Datasets API\n",
    "# This downloads train split of the dataset\n",
    "ds = load_dataset(dataset_id, config, split=\"train\")  \n",
    "# Shuffle and grab only the number of samples we need\n",
    "ds = ds.shuffle(seed=42).select(range(num_calibration_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a43b24ce-6980-4aff-937c-e0276eb58a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns in the wikitext: ['text']\n",
      "\n",
      "{'text': ' Continuous , short @-@ arc , high pressure xenon arc lamps have a color temperature closely approximating noon sunlight and are used in solar simulators . That is , the chromaticity of these lamps closely approximates a heated black body radiator that has a temperature close to that observed from the Sun . After they were first introduced during the 1940s , these lamps began replacing the shorter @-@ lived carbon arc lamps in movie projectors . They are employed in typical 35mm , IMAX and the new digital projectors film projection systems , automotive HID headlights , high @-@ end \" tactical \" flashlights and other specialized uses . These arc lamps are an excellent source of short wavelength ultraviolet radiation and they have intense emissions in the near infrared , which is used in some night vision systems . \\n'}\n"
     ]
    }
   ],
   "source": [
    "# inspect the dataset\n",
    "print(f\"columns in the {dataset_id}: {ds.column_names}\\n\")\n",
    "print(ds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7e60f8-6420-41aa-91da-266b2ce828c1",
   "metadata": {},
   "source": [
    "**Datset inspection shows the we need to extract column ```text``` and pass it as input to the model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf853df6-2fbd-4a95-ae92-52c7b11577a4",
   "metadata": {},
   "source": [
    "### When to Use a Custom Template for Calibration\n",
    "\n",
    "Use a **custom template** when you want the calibration text to closely mimic the input format your model will see in production.  \n",
    "\n",
    "For example, if your model is **instruction-following** or **chat-based**, providing the template the model was originally trained on or the template that will be used during inference ensures that the activation statistics collected during calibration reflect realistic usage patterns. \n",
    "\n",
    "This can improve the accuracy of quantization and compression.\n",
    "\n",
    "If your model can handle raw text and doesn’t require a specific format, you can rely on the default template instead.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54934efc-9564-446c-a37b-daf58dcb5ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get activations for the calibration dataset, we need to:\n",
    "# 1. extract the samples from the dataset \n",
    "# 2. tokenize samples in the dataset\n",
    "input_column = \"text\"\n",
    "\n",
    "# Call tokenize_for_calibration using dataset.map\n",
    "tokenized_dataset = ds.map(\n",
    "    lambda batch: tokenize_for_calibration(\n",
    "        examples=batch,                   # batch from Hugging Face dataset\n",
    "        input_column=input_column,        # the column containing text to calibrate\n",
    "        tokenizer=tokenizer,              # your Hugging Face tokenizer\n",
    "        max_length=max_sequence_length,   # maximum sequence length\n",
    "        model_type=\"chat\",         # use chat template if no custom template\n",
    "        custom_template=None              # optional, provide a dict if you want a custom template\n",
    "    ),\n",
    "    batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40ea72af-71a5-4cc8-91fc-69bf7b642b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 512\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5357d71-6eed-40fa-972b-d7e428422414",
   "metadata": {},
   "source": [
    "### Quantizing/Compressing Base Model\n",
    "\n",
    "**SmoothQuant** SmoothQuant operates on the activations (outputs of intermediate layers that become inputs to the next layer) produced by the base model. These activations can sometimes have extreme values (outliers). SmoothQuant scales the activations to reduce these outliers so that most values fall within a reasonable range, e.g., [-4, 4].\n",
    "\n",
    "To ensure that the overall layer output remains unchanged (Y = W * A), SmoothQuant also scales the corresponding weights by multiplying them with the same factor.\n",
    "\n",
    "Activations are scaled as:\n",
    "$A^*=A/s$\n",
    "\n",
    "Weights are scaled as:\n",
    "$W^*=W∗s$\n",
    "\n",
    "This way, the layer output remains approximately the same, but the activations are now suitable for stable low-bit quantization.\n",
    "\n",
    "**GPTQModifier** GPTQ takes the smoothed activations and weights produced by SmoothQuant and computes a quantization scale for each weight matrix. This scale determines how weights will be mapped into low-bit integers (e.g., int8).\n",
    "\n",
    "GPTQ then:\n",
    "\n",
    "1. Quantizes the weights using these scales\n",
    "\n",
    "    $Wquant=round(W/s)$\n",
    "\n",
    "2. Computes the model outputs using:\n",
    "\n",
    "    full-precision weights → Y\n",
    "\n",
    "   \n",
    "    quantized weights → Yquant\n",
    "\n",
    "3. Adjusts the quantization error so that\n",
    "\n",
    "    $Yquant≈Y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d30b5686-60b4-42f1-991a-21260466797c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 133.25it/s]\n",
      "Tokenizing: 100%|██████████| 512/512 [00:00<00:00, 1198.02 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:05:14.988641+0000 | reset | INFO - Compression lifecycle reset\n",
      "2025-12-02T19:05:14.994995+0000 | _create_default_logger | INFO - Logging all LLM Compressor modifier-level logs to sparse_logs/02-12-2025_19.05.14.log\n",
      "2025-12-02T19:05:14.996270+0000 | from_modifiers | INFO - Creating recipe from modifiers\n",
      "2025-12-02T19:05:14.996782+0000 | _infer_mappings_from_model | INFO - No SmoothQuantModifier.mappings provided, inferring from model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:05:15.754047+0000 | initialize | INFO - Compression lifecycle initialized for 2 modifiers\n",
      "2025-12-02T19:05:15.754919+0000 | IndependentPipeline | INFO - Inferred `SequentialPipeline` for `SmoothQuantModifier`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing cache: 100%|██████████| 512/512 [00:00<00:00, 515.82it/s]\n",
      "(1/33): Calibrating: 100%|██████████| 512/512 [00:04<00:00, 112.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:05:21.517078+0000 | _apply_smoothing | INFO - Smoothing with model.layers.0.input_layernorm\n",
      "2025-12-02T19:05:21.524558+0000 | _apply_smoothing | INFO - Smoothing with model.layers.0.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(1/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 86.27it/s]\n",
      "(2/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 133.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:05:31.542007+0000 | _apply_smoothing | INFO - Smoothing with model.layers.1.input_layernorm\n",
      "2025-12-02T19:05:31.545517+0000 | _apply_smoothing | INFO - Smoothing with model.layers.1.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(2/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 94.60it/s]\n",
      "(3/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 130.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:05:40.966659+0000 | _apply_smoothing | INFO - Smoothing with model.layers.2.input_layernorm\n",
      "2025-12-02T19:05:40.970325+0000 | _apply_smoothing | INFO - Smoothing with model.layers.2.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(3/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 93.92it/s]\n",
      "(4/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 132.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:05:50.371979+0000 | _apply_smoothing | INFO - Smoothing with model.layers.3.input_layernorm\n",
      "2025-12-02T19:05:50.375749+0000 | _apply_smoothing | INFO - Smoothing with model.layers.3.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(4/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 93.11it/s]\n",
      "(5/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 131.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:05:59.828261+0000 | _apply_smoothing | INFO - Smoothing with model.layers.4.input_layernorm\n",
      "2025-12-02T19:05:59.831647+0000 | _apply_smoothing | INFO - Smoothing with model.layers.4.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(5/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 92.71it/s]\n",
      "(6/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 132.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:06:09.306007+0000 | _apply_smoothing | INFO - Smoothing with model.layers.5.input_layernorm\n",
      "2025-12-02T19:06:09.308910+0000 | _apply_smoothing | INFO - Smoothing with model.layers.5.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(6/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 93.95it/s]\n",
      "(7/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 130.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:06:18.750799+0000 | _apply_smoothing | INFO - Smoothing with model.layers.6.input_layernorm\n",
      "2025-12-02T19:06:18.754314+0000 | _apply_smoothing | INFO - Smoothing with model.layers.6.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(7/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 93.50it/s]\n",
      "(8/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 131.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:06:28.199375+0000 | _apply_smoothing | INFO - Smoothing with model.layers.7.input_layernorm\n",
      "2025-12-02T19:06:28.203321+0000 | _apply_smoothing | INFO - Smoothing with model.layers.7.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(8/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 92.75it/s]\n",
      "(9/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 131.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:06:37.697081+0000 | _apply_smoothing | INFO - Smoothing with model.layers.8.input_layernorm\n",
      "2025-12-02T19:06:37.700496+0000 | _apply_smoothing | INFO - Smoothing with model.layers.8.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(9/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 93.80it/s]\n",
      "(10/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 129.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:06:47.400115+0000 | _apply_smoothing | INFO - Smoothing with model.layers.9.input_layernorm\n",
      "2025-12-02T19:06:47.403538+0000 | _apply_smoothing | INFO - Smoothing with model.layers.9.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(10/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 93.22it/s]\n",
      "(11/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 130.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:06:56.985208+0000 | _apply_smoothing | INFO - Smoothing with model.layers.10.input_layernorm\n",
      "2025-12-02T19:06:56.988295+0000 | _apply_smoothing | INFO - Smoothing with model.layers.10.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(11/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 92.59it/s]\n",
      "(12/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 129.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:07:06.620902+0000 | _apply_smoothing | INFO - Smoothing with model.layers.11.input_layernorm\n",
      "2025-12-02T19:07:06.624375+0000 | _apply_smoothing | INFO - Smoothing with model.layers.11.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(12/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 93.34it/s]\n",
      "(13/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 130.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:07:16.181926+0000 | _apply_smoothing | INFO - Smoothing with model.layers.12.input_layernorm\n",
      "2025-12-02T19:07:16.185636+0000 | _apply_smoothing | INFO - Smoothing with model.layers.12.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(13/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 93.13it/s]\n",
      "(14/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 130.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:07:25.765541+0000 | _apply_smoothing | INFO - Smoothing with model.layers.13.input_layernorm\n",
      "2025-12-02T19:07:25.769252+0000 | _apply_smoothing | INFO - Smoothing with model.layers.13.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(14/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 93.15it/s]\n",
      "(21/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 93.17it/s]]\n",
      "(22/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 130.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:08:43.125297+0000 | _apply_smoothing | INFO - Smoothing with model.layers.21.input_layernorm\n",
      "2025-12-02T19:08:43.128792+0000 | _apply_smoothing | INFO - Smoothing with model.layers.21.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(22/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 93.21it/s]\n",
      "(23/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 132.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:08:52.671262+0000 | _apply_smoothing | INFO - Smoothing with model.layers.22.input_layernorm\n",
      "2025-12-02T19:08:52.674075+0000 | _apply_smoothing | INFO - Smoothing with model.layers.22.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(23/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 93.76it/s]\n",
      "(24/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 131.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:09:02.214676+0000 | _apply_smoothing | INFO - Smoothing with model.layers.23.input_layernorm\n",
      "2025-12-02T19:09:02.218081+0000 | _apply_smoothing | INFO - Smoothing with model.layers.23.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(24/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 93.81it/s]\n",
      "(25/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 132.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:09:11.706153+0000 | _apply_smoothing | INFO - Smoothing with model.layers.24.input_layernorm\n",
      "2025-12-02T19:09:11.709900+0000 | _apply_smoothing | INFO - Smoothing with model.layers.24.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(25/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 92.71it/s]\n",
      "(26/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 132.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:09:21.259960+0000 | _apply_smoothing | INFO - Smoothing with model.layers.25.input_layernorm\n",
      "2025-12-02T19:09:21.263553+0000 | _apply_smoothing | INFO - Smoothing with model.layers.25.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(26/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 93.79it/s]\n",
      "(27/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 132.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:09:30.750869+0000 | _apply_smoothing | INFO - Smoothing with model.layers.26.input_layernorm\n",
      "2025-12-02T19:09:30.754315+0000 | _apply_smoothing | INFO - Smoothing with model.layers.26.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(27/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 93.25it/s]\n",
      "(28/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 133.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:09:40.255899+0000 | _apply_smoothing | INFO - Smoothing with model.layers.27.input_layernorm\n",
      "2025-12-02T19:09:40.259744+0000 | _apply_smoothing | INFO - Smoothing with model.layers.27.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(28/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 93.98it/s]\n",
      "(29/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 131.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:09:49.780858+0000 | _apply_smoothing | INFO - Smoothing with model.layers.28.input_layernorm\n",
      "2025-12-02T19:09:49.784471+0000 | _apply_smoothing | INFO - Smoothing with model.layers.28.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(29/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 93.92it/s]\n",
      "(30/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 133.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:09:59.248171+0000 | _apply_smoothing | INFO - Smoothing with model.layers.29.input_layernorm\n",
      "2025-12-02T19:09:59.252090+0000 | _apply_smoothing | INFO - Smoothing with model.layers.29.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(30/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 93.80it/s]\n",
      "(31/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 132.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:10:08.757849+0000 | _apply_smoothing | INFO - Smoothing with model.layers.30.input_layernorm\n",
      "2025-12-02T19:10:08.760917+0000 | _apply_smoothing | INFO - Smoothing with model.layers.30.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(31/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 93.97it/s]\n",
      "(32/33): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 133.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:10:18.231974+0000 | _apply_smoothing | INFO - Smoothing with model.layers.31.input_layernorm\n",
      "2025-12-02T19:10:18.235404+0000 | _apply_smoothing | INFO - Smoothing with model.layers.31.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(32/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 91.81it/s]\n",
      "(33/33): Calibrating: 100%|██████████| 512/512 [00:05<00:00, 88.14it/s]\n",
      "(33/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 88.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:10:35.934655+0000 | IndependentPipeline | INFO - Inferred `SequentialPipeline` for `GPTQModifier`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing cache: 100%|██████████| 512/512 [00:00<00:00, 532.42it/s]\n",
      "(1/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 34.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:10:51.936018+0000 | compress_modules | INFO - Quantizing model.layers.0.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:10:53.520624+0000 | compress | METRIC - time 1.58s\n",
      "2025-12-02T19:10:53.522181+0000 | compress | METRIC - error 5.95\n",
      "2025-12-02T19:10:53.523363+0000 | compress | METRIC - GPU 0 | usage: 89.45% | total memory: 48 GB\n",
      "2025-12-02T19:10:53.524121+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:10:53.524806+0000 | compress_modules | INFO - Quantizing model.layers.0.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:10:54.963163+0000 | compress | METRIC - time 1.44s\n",
      "2025-12-02T19:10:54.964139+0000 | compress | METRIC - error 4.26\n",
      "2025-12-02T19:10:54.964800+0000 | compress | METRIC - GPU 0 | usage: 89.45% | total memory: 48 GB\n",
      "2025-12-02T19:10:54.965313+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:10:54.965907+0000 | compress_modules | INFO - Quantizing model.layers.0.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:10:56.432256+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-02T19:10:56.433309+0000 | compress | METRIC - error 0.01\n",
      "2025-12-02T19:10:56.434083+0000 | compress | METRIC - GPU 0 | usage: 89.45% | total memory: 48 GB\n",
      "2025-12-02T19:10:56.434623+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:10:56.435287+0000 | compress_modules | INFO - Quantizing model.layers.0.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:10:57.906156+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-02T19:10:57.907877+0000 | compress | METRIC - error 0.00\n",
      "2025-12-02T19:10:57.908569+0000 | compress | METRIC - GPU 0 | usage: 89.45% | total memory: 48 GB\n",
      "2025-12-02T19:10:57.909124+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:10:57.909755+0000 | compress_modules | INFO - Quantizing model.layers.0.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:10:59.479095+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-02T19:10:59.480319+0000 | compress | METRIC - error 1.02\n",
      "2025-12-02T19:10:59.481031+0000 | compress | METRIC - GPU 0 | usage: 89.45% | total memory: 48 GB\n",
      "2025-12-02T19:10:59.481563+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:10:59.482189+0000 | compress_modules | INFO - Quantizing model.layers.0.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:11:01.051894+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-02T19:11:01.052934+0000 | compress | METRIC - error 0.70\n",
      "2025-12-02T19:11:01.053578+0000 | compress | METRIC - GPU 0 | usage: 89.45% | total memory: 48 GB\n",
      "2025-12-02T19:11:01.054119+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:11:01.054733+0000 | compress_modules | INFO - Quantizing model.layers.0.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:11:06.515479+0000 | compress | METRIC - time 5.46s\n",
      "2025-12-02T19:11:06.516946+0000 | compress | METRIC - error 0.00\n",
      "2025-12-02T19:11:06.517737+0000 | compress | METRIC - GPU 0 | usage: 92.86% | total memory: 48 GB\n",
      "2025-12-02T19:11:06.518268+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(1/33): Propagating: 100%|██████████| 512/512 [00:06<00:00, 75.92it/s]\n",
      "(2/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 35.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:11:28.086431+0000 | compress_modules | INFO - Quantizing model.layers.1.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:11:29.583190+0000 | compress | METRIC - time 1.50s\n",
      "2025-12-02T19:11:29.583979+0000 | compress | METRIC - error 8.16\n",
      "2025-12-02T19:11:29.584753+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:11:29.585285+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:11:29.585883+0000 | compress_modules | INFO - Quantizing model.layers.1.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:11:31.045978+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-02T19:11:31.047157+0000 | compress | METRIC - error 4.67\n",
      "2025-12-02T19:11:31.047843+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:11:31.048353+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:11:31.048926+0000 | compress_modules | INFO - Quantizing model.layers.1.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:11:32.527445+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-02T19:11:32.528361+0000 | compress | METRIC - error 0.05\n",
      "2025-12-02T19:11:32.529279+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:11:32.529691+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:11:32.530366+0000 | compress_modules | INFO - Quantizing model.layers.1.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:11:34.008961+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-02T19:11:34.010188+0000 | compress | METRIC - error 0.00\n",
      "2025-12-02T19:11:34.010862+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:11:34.011374+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:11:34.011962+0000 | compress_modules | INFO - Quantizing model.layers.1.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:11:35.577628+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-02T19:11:35.578912+0000 | compress | METRIC - error 1.41\n",
      "2025-12-02T19:11:35.579732+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:11:35.580329+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:11:35.581354+0000 | compress_modules | INFO - Quantizing model.layers.1.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:11:37.115757+0000 | compress | METRIC - time 1.53s\n",
      "2025-12-02T19:11:37.116985+0000 | compress | METRIC - error 1.16\n",
      "2025-12-02T19:11:37.117704+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:11:37.118265+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:11:37.118853+0000 | compress_modules | INFO - Quantizing model.layers.1.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:11:42.566618+0000 | compress | METRIC - time 5.45s\n",
      "2025-12-02T19:11:42.567797+0000 | compress | METRIC - error 0.59\n",
      "2025-12-02T19:11:42.568693+0000 | compress | METRIC - GPU 0 | usage: 90.69% | total memory: 48 GB\n",
      "2025-12-02T19:11:42.569247+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(2/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 87.93it/s]\n",
      "(3/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 35.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:12:02.945815+0000 | compress_modules | INFO - Quantizing model.layers.2.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:12:04.451899+0000 | compress | METRIC - time 1.51s\n",
      "2025-12-02T19:12:04.452984+0000 | compress | METRIC - error 19.88\n",
      "2025-12-02T19:12:04.453796+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:12:04.454324+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:12:04.454903+0000 | compress_modules | INFO - Quantizing model.layers.2.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:12:05.910121+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-02T19:12:05.911107+0000 | compress | METRIC - error 13.86\n",
      "2025-12-02T19:12:05.911770+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:12:05.912270+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:12:05.912845+0000 | compress_modules | INFO - Quantizing model.layers.2.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:12:07.372309+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-02T19:12:07.373372+0000 | compress | METRIC - error 0.20\n",
      "2025-12-02T19:12:07.374382+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:12:07.374926+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:12:07.375478+0000 | compress_modules | INFO - Quantizing model.layers.2.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:12:08.850050+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-02T19:12:08.851289+0000 | compress | METRIC - error 0.00\n",
      "2025-12-02T19:12:08.851959+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:12:08.852757+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:12:08.853336+0000 | compress_modules | INFO - Quantizing model.layers.2.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:12:10.423535+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-02T19:12:10.424649+0000 | compress | METRIC - error 2.80\n",
      "2025-12-02T19:12:10.425989+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:12:10.426463+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:12:10.427098+0000 | compress_modules | INFO - Quantizing model.layers.2.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:12:12.012255+0000 | compress | METRIC - time 1.58s\n",
      "2025-12-02T19:12:12.013303+0000 | compress | METRIC - error 1.85\n",
      "2025-12-02T19:12:12.014057+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:12:12.014520+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:12:12.015275+0000 | compress_modules | INFO - Quantizing model.layers.2.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:12:17.622243+0000 | compress | METRIC - time 5.61s\n",
      "2025-12-02T19:12:17.623543+0000 | compress | METRIC - error 0.01\n",
      "2025-12-02T19:12:17.624236+0000 | compress | METRIC - GPU 0 | usage: 90.69% | total memory: 48 GB\n",
      "2025-12-02T19:12:17.624805+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(3/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 87.84it/s]\n",
      "(4/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 34.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:12:38.228969+0000 | compress_modules | INFO - Quantizing model.layers.3.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:12:39.691670+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-02T19:12:39.692651+0000 | compress | METRIC - error 13.12\n",
      "2025-12-02T19:12:39.693414+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:12:39.693972+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:12:39.694548+0000 | compress_modules | INFO - Quantizing model.layers.3.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:12:41.153297+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-02T19:12:41.154329+0000 | compress | METRIC - error 8.28\n",
      "2025-12-02T19:12:41.155047+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:12:41.155464+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:12:41.156128+0000 | compress_modules | INFO - Quantizing model.layers.3.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:12:42.606858+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-02T19:12:42.607784+0000 | compress | METRIC - error 0.32\n",
      "2025-12-02T19:12:42.608446+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:12:42.609001+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:12:42.609580+0000 | compress_modules | INFO - Quantizing model.layers.3.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:12:44.075973+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-02T19:12:44.077000+0000 | compress | METRIC - error 0.01\n",
      "2025-12-02T19:12:44.077924+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:12:44.078329+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:12:44.078990+0000 | compress_modules | INFO - Quantizing model.layers.3.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:12:45.627987+0000 | compress | METRIC - time 1.55s\n",
      "2025-12-02T19:12:45.629203+0000 | compress | METRIC - error 5.32\n",
      "2025-12-02T19:12:45.630138+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:12:45.630684+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:12:45.631365+0000 | compress_modules | INFO - Quantizing model.layers.3.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:12:47.174791+0000 | compress | METRIC - time 1.54s\n",
      "2025-12-02T19:12:47.176481+0000 | compress | METRIC - error 2.89\n",
      "2025-12-02T19:12:47.177264+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:12:47.177683+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:12:47.178388+0000 | compress_modules | INFO - Quantizing model.layers.3.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:12:52.563338+0000 | compress | METRIC - time 5.38s\n",
      "2025-12-02T19:12:52.564455+0000 | compress | METRIC - error 0.02\n",
      "2025-12-02T19:12:52.565358+0000 | compress | METRIC - GPU 0 | usage: 90.69% | total memory: 48 GB\n",
      "2025-12-02T19:12:52.565902+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(4/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 87.22it/s]\n",
      "(5/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 34.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:13:13.235365+0000 | compress_modules | INFO - Quantizing model.layers.4.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:13:14.719898+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-02T19:13:14.720931+0000 | compress | METRIC - error 15.91\n",
      "2025-12-02T19:13:14.721900+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:13:14.722462+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:13:14.723054+0000 | compress_modules | INFO - Quantizing model.layers.4.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:13:16.171285+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-02T19:13:16.172574+0000 | compress | METRIC - error 10.69\n",
      "2025-12-02T19:13:16.173219+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:13:16.173851+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:13:16.174824+0000 | compress_modules | INFO - Quantizing model.layers.4.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:13:17.649081+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-02T19:13:17.650060+0000 | compress | METRIC - error 0.32\n",
      "2025-12-02T19:13:17.650995+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:13:17.651405+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:13:17.652050+0000 | compress_modules | INFO - Quantizing model.layers.4.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:13:19.124149+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-02T19:13:19.125371+0000 | compress | METRIC - error 0.01\n",
      "2025-12-02T19:13:19.126674+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:13:19.127333+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:13:19.128082+0000 | compress_modules | INFO - Quantizing model.layers.4.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:13:20.695566+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-02T19:13:20.696792+0000 | compress | METRIC - error 9.59\n",
      "2025-12-02T19:13:20.697505+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:13:20.698026+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:13:20.698585+0000 | compress_modules | INFO - Quantizing model.layers.4.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:13:22.256621+0000 | compress | METRIC - time 1.56s\n",
      "2025-12-02T19:13:22.257829+0000 | compress | METRIC - error 4.62\n",
      "2025-12-02T19:13:22.258550+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:13:22.259102+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:13:22.259674+0000 | compress_modules | INFO - Quantizing model.layers.4.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:13:27.844185+0000 | compress | METRIC - time 5.58s\n",
      "2025-12-02T19:13:27.845315+0000 | compress | METRIC - error 0.05\n",
      "2025-12-02T19:13:27.846425+0000 | compress | METRIC - GPU 0 | usage: 88.99% | total memory: 48 GB\n",
      "2025-12-02T19:13:27.847049+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(5/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 87.21it/s]\n",
      "(6/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 35.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:13:48.349366+0000 | compress_modules | INFO - Quantizing model.layers.5.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:13:49.874948+0000 | compress | METRIC - time 1.52s\n",
      "2025-12-02T19:13:49.876074+0000 | compress | METRIC - error 26.91\n",
      "2025-12-02T19:13:49.876914+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:13:49.877352+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:13:49.878005+0000 | compress_modules | INFO - Quantizing model.layers.5.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:13:51.317370+0000 | compress | METRIC - time 1.44s\n",
      "2025-12-02T19:13:51.318406+0000 | compress | METRIC - error 17.99\n",
      "2025-12-02T19:13:51.319067+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:13:51.319528+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:13:51.320544+0000 | compress_modules | INFO - Quantizing model.layers.5.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:13:52.780604+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-02T19:13:52.781693+0000 | compress | METRIC - error 0.42\n",
      "2025-12-02T19:13:52.782328+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:13:52.782763+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:13:52.783450+0000 | compress_modules | INFO - Quantizing model.layers.5.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:13:54.273806+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-02T19:13:54.274785+0000 | compress | METRIC - error 0.02\n",
      "2025-12-02T19:13:54.275399+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:13:54.275922+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:13:54.276507+0000 | compress_modules | INFO - Quantizing model.layers.5.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:13:55.863358+0000 | compress | METRIC - time 1.59s\n",
      "2025-12-02T19:13:55.864583+0000 | compress | METRIC - error 12.15\n",
      "2025-12-02T19:13:55.865247+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:13:55.865660+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:13:55.866309+0000 | compress_modules | INFO - Quantizing model.layers.5.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:13:57.413076+0000 | compress | METRIC - time 1.55s\n",
      "2025-12-02T19:13:57.414299+0000 | compress | METRIC - error 5.78\n",
      "2025-12-02T19:13:57.415127+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:13:57.415548+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:13:57.416194+0000 | compress_modules | INFO - Quantizing model.layers.5.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:14:02.971609+0000 | compress | METRIC - time 5.56s\n",
      "2025-12-02T19:14:02.972878+0000 | compress | METRIC - error 0.07\n",
      "2025-12-02T19:14:02.973619+0000 | compress | METRIC - GPU 0 | usage: 88.99% | total memory: 48 GB\n",
      "2025-12-02T19:14:02.974164+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(6/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 87.76it/s]\n",
      "(7/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 34.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:14:23.673085+0000 | compress_modules | INFO - Quantizing model.layers.6.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:14:25.181129+0000 | compress | METRIC - time 1.51s\n",
      "2025-12-02T19:14:25.182203+0000 | compress | METRIC - error 24.99\n",
      "2025-12-02T19:14:25.182936+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:14:25.183364+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:14:25.184033+0000 | compress_modules | INFO - Quantizing model.layers.6.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:14:26.662682+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-02T19:14:26.663805+0000 | compress | METRIC - error 17.95\n",
      "2025-12-02T19:14:26.664398+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:14:26.664924+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:14:26.665515+0000 | compress_modules | INFO - Quantizing model.layers.6.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:14:28.156559+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-02T19:14:28.157537+0000 | compress | METRIC - error 0.36\n",
      "2025-12-02T19:14:28.158266+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:14:28.158723+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:14:28.159358+0000 | compress_modules | INFO - Quantizing model.layers.6.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:14:29.639147+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-02T19:14:29.640385+0000 | compress | METRIC - error 0.03\n",
      "2025-12-02T19:14:29.641097+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:14:29.641526+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:14:29.642202+0000 | compress_modules | INFO - Quantizing model.layers.6.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:14:31.198060+0000 | compress | METRIC - time 1.56s\n",
      "2025-12-02T19:14:31.199368+0000 | compress | METRIC - error 17.92\n",
      "2025-12-02T19:14:31.200187+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:14:31.200667+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:14:31.201818+0000 | compress_modules | INFO - Quantizing model.layers.6.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:14:32.779140+0000 | compress | METRIC - time 1.58s\n",
      "2025-12-02T19:14:32.781044+0000 | compress | METRIC - error 7.07\n",
      "2025-12-02T19:14:32.781829+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:14:32.782388+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:14:32.783010+0000 | compress_modules | INFO - Quantizing model.layers.6.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:14:39.032380+0000 | compress | METRIC - time 6.25s\n",
      "2025-12-02T19:14:39.033612+0000 | compress | METRIC - error 0.09\n",
      "2025-12-02T19:14:39.034381+0000 | compress | METRIC - GPU 0 | usage: 90.69% | total memory: 48 GB\n",
      "2025-12-02T19:14:39.034983+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(7/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 88.59it/s]\n",
      "(8/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 35.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:14:59.257358+0000 | compress_modules | INFO - Quantizing model.layers.7.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:15:00.741439+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-02T19:15:00.742454+0000 | compress | METRIC - error 24.43\n",
      "2025-12-02T19:15:00.743229+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:15:00.743757+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:15:00.744346+0000 | compress_modules | INFO - Quantizing model.layers.7.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:15:02.185425+0000 | compress | METRIC - time 1.44s\n",
      "2025-12-02T19:15:02.186464+0000 | compress | METRIC - error 16.81\n",
      "2025-12-02T19:15:02.187151+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:15:02.187655+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:15:02.188237+0000 | compress_modules | INFO - Quantizing model.layers.7.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:15:03.637995+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-02T19:15:03.639077+0000 | compress | METRIC - error 0.50\n",
      "2025-12-02T19:15:03.639958+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:15:03.640834+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:15:03.641411+0000 | compress_modules | INFO - Quantizing model.layers.7.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:15:05.120512+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-02T19:15:05.121630+0000 | compress | METRIC - error 0.05\n",
      "2025-12-02T19:15:05.122295+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:15:05.122699+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:15:05.123356+0000 | compress_modules | INFO - Quantizing model.layers.7.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:15:06.688832+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-02T19:15:06.689864+0000 | compress | METRIC - error 19.72\n",
      "2025-12-02T19:15:06.690579+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:15:06.691017+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:15:06.691693+0000 | compress_modules | INFO - Quantizing model.layers.7.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:15:08.261091+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-02T19:15:08.262391+0000 | compress | METRIC - error 8.67\n",
      "2025-12-02T19:15:08.263165+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:15:08.263576+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:15:08.264266+0000 | compress_modules | INFO - Quantizing model.layers.7.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:15:13.869294+0000 | compress | METRIC - time 5.60s\n",
      "2025-12-02T19:15:13.870443+0000 | compress | METRIC - error 0.12\n",
      "2025-12-02T19:15:13.871248+0000 | compress | METRIC - GPU 0 | usage: 88.99% | total memory: 48 GB\n",
      "2025-12-02T19:15:13.871665+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(8/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 88.37it/s]\n",
      "(9/33): Calibrating:   4%|▎         | 19/512 [00:00<00:14, 35.04it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:16:23.268658+0000 | compress | METRIC - time 5.56s\n",
      "2025-12-02T19:16:23.269891+0000 | compress | METRIC - error 0.13\n",
      "2025-12-02T19:16:23.270642+0000 | compress | METRIC - GPU 0 | usage: 90.69% | total memory: 48 GB\n",
      "2025-12-02T19:16:23.271244+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(10/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 88.71it/s]\n",
      "(11/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 35.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:16:43.497521+0000 | compress_modules | INFO - Quantizing model.layers.10.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:16:45.011087+0000 | compress | METRIC - time 1.51s\n",
      "2025-12-02T19:16:45.012201+0000 | compress | METRIC - error 46.20\n",
      "2025-12-02T19:16:45.012922+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:16:45.013559+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:16:45.014478+0000 | compress_modules | INFO - Quantizing model.layers.10.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:16:46.479586+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-02T19:16:46.480632+0000 | compress | METRIC - error 45.02\n",
      "2025-12-02T19:16:46.481512+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:16:46.482065+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:16:46.482629+0000 | compress_modules | INFO - Quantizing model.layers.10.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:16:47.951789+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-02T19:16:47.952827+0000 | compress | METRIC - error 0.73\n",
      "2025-12-02T19:16:47.954057+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:16:47.954647+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:16:47.955249+0000 | compress_modules | INFO - Quantizing model.layers.10.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:16:49.431220+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-02T19:16:49.432358+0000 | compress | METRIC - error 0.07\n",
      "2025-12-02T19:16:49.433062+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:16:49.433485+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:16:49.434149+0000 | compress_modules | INFO - Quantizing model.layers.10.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:16:50.978201+0000 | compress | METRIC - time 1.54s\n",
      "2025-12-02T19:16:50.979637+0000 | compress | METRIC - error 22.13\n",
      "2025-12-02T19:16:50.980589+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:16:50.981048+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:16:50.981836+0000 | compress_modules | INFO - Quantizing model.layers.10.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:16:52.539936+0000 | compress | METRIC - time 1.56s\n",
      "2025-12-02T19:16:52.541676+0000 | compress | METRIC - error 10.57\n",
      "2025-12-02T19:16:52.542460+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:16:52.542899+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:16:52.543557+0000 | compress_modules | INFO - Quantizing model.layers.10.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:16:58.023847+0000 | compress | METRIC - time 5.48s\n",
      "2025-12-02T19:16:58.024944+0000 | compress | METRIC - error 0.14\n",
      "2025-12-02T19:16:58.025881+0000 | compress | METRIC - GPU 0 | usage: 88.99% | total memory: 48 GB\n",
      "2025-12-02T19:16:58.026459+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(11/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 89.52it/s]\n",
      "(12/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 35.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:17:18.251075+0000 | compress_modules | INFO - Quantizing model.layers.11.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:17:19.751347+0000 | compress | METRIC - time 1.50s\n",
      "2025-12-02T19:17:19.753175+0000 | compress | METRIC - error 37.85\n",
      "2025-12-02T19:17:19.754001+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:17:19.754554+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:17:19.755187+0000 | compress_modules | INFO - Quantizing model.layers.11.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:17:21.195035+0000 | compress | METRIC - time 1.44s\n",
      "2025-12-02T19:17:21.196153+0000 | compress | METRIC - error 36.09\n",
      "2025-12-02T19:17:21.196811+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:17:21.197369+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:17:21.198387+0000 | compress_modules | INFO - Quantizing model.layers.11.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:17:22.664171+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-02T19:17:22.665265+0000 | compress | METRIC - error 0.89\n",
      "2025-12-02T19:17:22.666005+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:17:22.666508+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:17:22.667075+0000 | compress_modules | INFO - Quantizing model.layers.11.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:17:24.126652+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-02T19:17:24.127740+0000 | compress | METRIC - error 0.09\n",
      "2025-12-02T19:17:24.128613+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:17:24.129050+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:17:24.129675+0000 | compress_modules | INFO - Quantizing model.layers.11.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:17:25.711885+0000 | compress | METRIC - time 1.58s\n",
      "2025-12-02T19:17:25.713032+0000 | compress | METRIC - error 24.66\n",
      "2025-12-02T19:17:25.713730+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:17:25.714254+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:17:25.714826+0000 | compress_modules | INFO - Quantizing model.layers.11.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:17:27.309790+0000 | compress | METRIC - time 1.59s\n",
      "2025-12-02T19:17:27.310838+0000 | compress | METRIC - error 12.00\n",
      "2025-12-02T19:17:27.311612+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:17:27.312132+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:17:27.312669+0000 | compress_modules | INFO - Quantizing model.layers.11.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:17:32.891298+0000 | compress | METRIC - time 5.58s\n",
      "2025-12-02T19:17:32.892626+0000 | compress | METRIC - error 0.17\n",
      "2025-12-02T19:17:32.893490+0000 | compress | METRIC - GPU 0 | usage: 88.99% | total memory: 48 GB\n",
      "2025-12-02T19:17:32.893894+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(12/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 87.88it/s]\n",
      "(13/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 35.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:17:53.331125+0000 | compress_modules | INFO - Quantizing model.layers.12.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:17:54.850391+0000 | compress | METRIC - time 1.52s\n",
      "2025-12-02T19:17:54.851503+0000 | compress | METRIC - error 41.64\n",
      "2025-12-02T19:17:54.852384+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:17:54.852921+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:17:54.853485+0000 | compress_modules | INFO - Quantizing model.layers.12.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:17:56.339085+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-02T19:17:56.340187+0000 | compress | METRIC - error 29.62\n",
      "2025-12-02T19:17:56.340789+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:17:56.341289+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:17:56.341877+0000 | compress_modules | INFO - Quantizing model.layers.12.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:17:57.833907+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-02T19:17:57.835055+0000 | compress | METRIC - error 1.01\n",
      "2025-12-02T19:17:57.835589+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:17:57.836050+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:17:57.837125+0000 | compress_modules | INFO - Quantizing model.layers.12.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:17:59.337504+0000 | compress | METRIC - time 1.50s\n",
      "2025-12-02T19:17:59.338612+0000 | compress | METRIC - error 0.09\n",
      "2025-12-02T19:17:59.339870+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:17:59.340263+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:17:59.340918+0000 | compress_modules | INFO - Quantizing model.layers.12.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:18:00.938852+0000 | compress | METRIC - time 1.60s\n",
      "2025-12-02T19:18:00.939996+0000 | compress | METRIC - error 28.72\n",
      "2025-12-02T19:18:00.940858+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:18:00.941385+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:18:00.941993+0000 | compress_modules | INFO - Quantizing model.layers.12.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:18:02.559301+0000 | compress | METRIC - time 1.62s\n",
      "2025-12-02T19:18:02.560328+0000 | compress | METRIC - error 14.83\n",
      "2025-12-02T19:18:02.561009+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:18:02.561525+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:18:02.562129+0000 | compress_modules | INFO - Quantizing model.layers.12.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:18:08.100683+0000 | compress | METRIC - time 5.54s\n",
      "2025-12-02T19:18:08.101848+0000 | compress | METRIC - error 0.19\n",
      "2025-12-02T19:18:08.103069+0000 | compress | METRIC - GPU 0 | usage: 90.69% | total memory: 48 GB\n",
      "2025-12-02T19:18:08.103580+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(13/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 87.27it/s]\n",
      "(14/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 34.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:18:28.797829+0000 | compress_modules | INFO - Quantizing model.layers.13.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:18:30.307183+0000 | compress | METRIC - time 1.51s\n",
      "2025-12-02T19:18:30.307955+0000 | compress | METRIC - error 46.34\n",
      "2025-12-02T19:18:30.308660+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:18:30.309086+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:18:30.309692+0000 | compress_modules | INFO - Quantizing model.layers.13.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:18:31.784105+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-02T19:18:31.784829+0000 | compress | METRIC - error 70.13\n",
      "2025-12-02T19:18:31.785401+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:18:31.785874+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:18:31.786384+0000 | compress_modules | INFO - Quantizing model.layers.13.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:18:33.268222+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-02T19:18:33.268968+0000 | compress | METRIC - error 1.21\n",
      "2025-12-02T19:18:33.269650+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:18:33.270074+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:18:33.270683+0000 | compress_modules | INFO - Quantizing model.layers.13.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:18:34.753125+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-02T19:18:34.753871+0000 | compress | METRIC - error 0.09\n",
      "2025-12-02T19:18:34.754518+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:18:34.754890+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:18:34.755446+0000 | compress_modules | INFO - Quantizing model.layers.13.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:18:36.374175+0000 | compress | METRIC - time 1.62s\n",
      "2025-12-02T19:18:36.374956+0000 | compress | METRIC - error 31.77\n",
      "2025-12-02T19:18:36.375549+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:18:36.376044+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:18:36.376560+0000 | compress_modules | INFO - Quantizing model.layers.13.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:18:38.002750+0000 | compress | METRIC - time 1.63s\n",
      "2025-12-02T19:18:38.003505+0000 | compress | METRIC - error 15.00\n",
      "2025-12-02T19:18:38.004183+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:18:38.004548+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:18:38.005139+0000 | compress_modules | INFO - Quantizing model.layers.13.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:18:43.589766+0000 | compress | METRIC - time 5.58s\n",
      "2025-12-02T19:18:43.590577+0000 | compress | METRIC - error 0.18\n",
      "2025-12-02T19:18:43.591307+0000 | compress | METRIC - GPU 0 | usage: 88.99% | total memory: 48 GB\n",
      "2025-12-02T19:18:43.591694+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(14/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 89.22it/s]\n",
      "(15/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 35.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:19:03.938553+0000 | compress_modules | INFO - Quantizing model.layers.14.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:19:05.465451+0000 | compress | METRIC - time 1.53s\n",
      "2025-12-02T19:19:05.466137+0000 | compress | METRIC - error 49.05\n",
      "2025-12-02T19:19:05.466972+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:19:05.467351+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:19:05.467967+0000 | compress_modules | INFO - Quantizing model.layers.14.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:19:06.946919+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-02T19:19:06.947809+0000 | compress | METRIC - error 69.38\n",
      "2025-12-02T19:19:06.948363+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:19:06.948866+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:19:06.949391+0000 | compress_modules | INFO - Quantizing model.layers.14.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:19:08.435150+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-02T19:19:08.435915+0000 | compress | METRIC - error 1.64\n",
      "2025-12-02T19:19:08.436574+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:19:08.437105+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:19:08.437621+0000 | compress_modules | INFO - Quantizing model.layers.14.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:19:09.937762+0000 | compress | METRIC - time 1.50s\n",
      "2025-12-02T19:19:09.938497+0000 | compress | METRIC - error 0.09\n",
      "2025-12-02T19:19:09.939212+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:19:09.939583+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:19:09.940189+0000 | compress_modules | INFO - Quantizing model.layers.14.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:19:11.550770+0000 | compress | METRIC - time 1.61s\n",
      "2025-12-02T19:19:11.551470+0000 | compress | METRIC - error 37.53\n",
      "2025-12-02T19:19:11.552181+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:19:11.552617+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:19:11.553125+0000 | compress_modules | INFO - Quantizing model.layers.14.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:19:13.177574+0000 | compress | METRIC - time 1.62s\n",
      "2025-12-02T19:19:13.178365+0000 | compress | METRIC - error 15.82\n",
      "2025-12-02T19:19:13.179177+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:19:13.179546+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:19:13.180154+0000 | compress_modules | INFO - Quantizing model.layers.14.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:19:18.721423+0000 | compress | METRIC - time 5.54s\n",
      "2025-12-02T19:19:18.723047+0000 | compress | METRIC - error 0.24\n",
      "2025-12-02T19:19:18.723803+0000 | compress | METRIC - GPU 0 | usage: 88.99% | total memory: 48 GB\n",
      "2025-12-02T19:19:18.724232+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(15/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 89.44it/s]\n",
      "(16/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 35.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:19:39.054729+0000 | compress_modules | INFO - Quantizing model.layers.15.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:19:40.544323+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-02T19:19:40.545329+0000 | compress | METRIC - error 64.21\n",
      "2025-12-02T19:19:40.546158+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:19:40.546557+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:19:40.547236+0000 | compress_modules | INFO - Quantizing model.layers.15.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:19:41.982269+0000 | compress | METRIC - time 1.43s\n",
      "2025-12-02T19:19:41.983292+0000 | compress | METRIC - error 58.99\n",
      "2025-12-02T19:19:41.984131+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:19:41.984540+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:19:41.985198+0000 | compress_modules | INFO - Quantizing model.layers.15.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:19:43.437828+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-02T19:19:43.438889+0000 | compress | METRIC - error 1.61\n",
      "2025-12-02T19:19:43.439433+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:19:43.439971+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:19:43.440523+0000 | compress_modules | INFO - Quantizing model.layers.15.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:19:44.918044+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-02T19:19:44.920215+0000 | compress | METRIC - error 0.10\n",
      "2025-12-02T19:19:44.921219+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:19:44.921809+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:19:44.922490+0000 | compress_modules | INFO - Quantizing model.layers.15.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:19:46.491190+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-02T19:19:46.492371+0000 | compress | METRIC - error 43.97\n",
      "2025-12-02T19:19:46.493664+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:19:46.494150+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:19:46.494822+0000 | compress_modules | INFO - Quantizing model.layers.15.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:19:48.074627+0000 | compress | METRIC - time 1.58s\n",
      "2025-12-02T19:19:48.075819+0000 | compress | METRIC - error 15.30\n",
      "2025-12-02T19:19:48.076548+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:19:48.077105+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:19:48.077679+0000 | compress_modules | INFO - Quantizing model.layers.15.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:19:53.706614+0000 | compress | METRIC - time 5.63s\n",
      "2025-12-02T19:19:53.708457+0000 | compress | METRIC - error 0.24\n",
      "2025-12-02T19:19:53.709209+0000 | compress | METRIC - GPU 0 | usage: 90.69% | total memory: 48 GB\n",
      "2025-12-02T19:19:53.709668+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(16/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 89.32it/s]\n",
      "(17/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 35.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:20:14.122504+0000 | compress_modules | INFO - Quantizing model.layers.16.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:20:15.611937+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-02T19:20:15.612869+0000 | compress | METRIC - error 56.79\n",
      "2025-12-02T19:20:15.613895+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:20:15.614408+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:20:15.614996+0000 | compress_modules | INFO - Quantizing model.layers.16.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:20:17.090177+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-02T19:20:17.091217+0000 | compress | METRIC - error 65.52\n",
      "2025-12-02T19:20:17.092063+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:20:17.092581+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:20:17.093183+0000 | compress_modules | INFO - Quantizing model.layers.16.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:20:18.549557+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-02T19:20:18.550769+0000 | compress | METRIC - error 2.12\n",
      "2025-12-02T19:20:18.551498+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:20:18.551959+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:20:18.552642+0000 | compress_modules | INFO - Quantizing model.layers.16.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:20:20.030079+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-02T19:20:20.031400+0000 | compress | METRIC - error 0.08\n",
      "2025-12-02T19:20:20.032165+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:20:20.032587+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:20:20.033337+0000 | compress_modules | INFO - Quantizing model.layers.16.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:20:21.603643+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-02T19:20:21.605521+0000 | compress | METRIC - error 38.19\n",
      "2025-12-02T19:20:21.606155+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:20:21.606575+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:20:21.607283+0000 | compress_modules | INFO - Quantizing model.layers.16.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:20:23.180541+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-02T19:20:23.181733+0000 | compress | METRIC - error 14.21\n",
      "2025-12-02T19:20:23.182475+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:20:23.183151+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:20:23.184086+0000 | compress_modules | INFO - Quantizing model.layers.16.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:20:28.740874+0000 | compress | METRIC - time 5.56s\n",
      "2025-12-02T19:20:28.742050+0000 | compress | METRIC - error 0.34\n",
      "2025-12-02T19:20:28.742685+0000 | compress | METRIC - GPU 0 | usage: 88.99% | total memory: 48 GB\n",
      "2025-12-02T19:20:28.743224+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(17/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 88.78it/s]\n",
      "(20/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 34.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:21:59.570045+0000 | compress_modules | INFO - Quantizing model.layers.19.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:22:01.104110+0000 | compress | METRIC - time 1.53s\n",
      "2025-12-02T19:22:01.104901+0000 | compress | METRIC - error 46.11\n",
      "2025-12-02T19:22:01.105611+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:22:01.106135+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:22:01.106742+0000 | compress_modules | INFO - Quantizing model.layers.19.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:22:02.594494+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-02T19:22:02.595348+0000 | compress | METRIC - error 44.19\n",
      "2025-12-02T19:22:02.595927+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:22:02.596340+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:22:02.596954+0000 | compress_modules | INFO - Quantizing model.layers.19.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:22:04.098406+0000 | compress | METRIC - time 1.50s\n",
      "2025-12-02T19:22:04.099190+0000 | compress | METRIC - error 2.39\n",
      "2025-12-02T19:22:04.099871+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:22:04.100242+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:22:04.100808+0000 | compress_modules | INFO - Quantizing model.layers.19.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:22:05.612703+0000 | compress | METRIC - time 1.51s\n",
      "2025-12-02T19:22:05.613445+0000 | compress | METRIC - error 0.03\n",
      "2025-12-02T19:22:05.614247+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:22:05.614621+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:22:05.615212+0000 | compress_modules | INFO - Quantizing model.layers.19.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:22:07.235669+0000 | compress | METRIC - time 1.62s\n",
      "2025-12-02T19:22:07.236570+0000 | compress | METRIC - error 29.07\n",
      "2025-12-02T19:22:07.237241+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:22:07.237624+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:22:07.238251+0000 | compress_modules | INFO - Quantizing model.layers.19.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:22:08.835555+0000 | compress | METRIC - time 1.60s\n",
      "2025-12-02T19:22:08.836319+0000 | compress | METRIC - error 11.70\n",
      "2025-12-02T19:22:08.836999+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:22:08.837460+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:22:08.837982+0000 | compress_modules | INFO - Quantizing model.layers.19.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:22:14.493377+0000 | compress | METRIC - time 5.65s\n",
      "2025-12-02T19:22:14.494164+0000 | compress | METRIC - error 0.28\n",
      "2025-12-02T19:22:14.494894+0000 | compress | METRIC - GPU 0 | usage: 88.99% | total memory: 48 GB\n",
      "2025-12-02T19:22:14.495374+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(20/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 87.87it/s]\n",
      "(21/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 34.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:22:35.368315+0000 | compress_modules | INFO - Quantizing model.layers.20.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:22:36.854481+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-02T19:22:36.855451+0000 | compress | METRIC - error 49.41\n",
      "2025-12-02T19:22:36.856478+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:22:36.857030+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:22:36.857628+0000 | compress_modules | INFO - Quantizing model.layers.20.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:22:38.296521+0000 | compress | METRIC - time 1.44s\n",
      "2025-12-02T19:22:38.297580+0000 | compress | METRIC - error 52.49\n",
      "2025-12-02T19:22:38.298525+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:22:38.299069+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:22:38.299664+0000 | compress_modules | INFO - Quantizing model.layers.20.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:22:39.765196+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-02T19:22:39.765871+0000 | compress | METRIC - error 2.01\n",
      "2025-12-02T19:22:39.766535+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:22:39.766938+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:22:39.767514+0000 | compress_modules | INFO - Quantizing model.layers.20.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:22:41.234110+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-02T19:22:41.234993+0000 | compress | METRIC - error 0.03\n",
      "2025-12-02T19:22:41.235503+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:22:41.235890+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:22:41.236458+0000 | compress_modules | INFO - Quantizing model.layers.20.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:22:42.866839+0000 | compress | METRIC - time 1.63s\n",
      "2025-12-02T19:22:42.867552+0000 | compress | METRIC - error 29.19\n",
      "2025-12-02T19:22:42.868291+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:22:42.868759+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:22:42.869274+0000 | compress_modules | INFO - Quantizing model.layers.20.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:22:44.463907+0000 | compress | METRIC - time 1.59s\n",
      "2025-12-02T19:22:44.464633+0000 | compress | METRIC - error 12.18\n",
      "2025-12-02T19:22:44.506087+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:22:44.506899+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:22:44.507666+0000 | compress_modules | INFO - Quantizing model.layers.20.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:22:50.418870+0000 | compress | METRIC - time 5.91s\n",
      "2025-12-02T19:22:50.419789+0000 | compress | METRIC - error 0.30\n",
      "2025-12-02T19:22:50.420440+0000 | compress | METRIC - GPU 0 | usage: 88.99% | total memory: 48 GB\n",
      "2025-12-02T19:22:50.420926+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(21/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 89.06it/s]\n",
      "(22/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 35.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:23:10.580522+0000 | compress_modules | INFO - Quantizing model.layers.21.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:23:12.077837+0000 | compress | METRIC - time 1.50s\n",
      "2025-12-02T19:23:12.078563+0000 | compress | METRIC - error 49.98\n",
      "2025-12-02T19:23:12.079270+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:23:12.079642+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:23:12.080239+0000 | compress_modules | INFO - Quantizing model.layers.21.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:23:13.536975+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-02T19:23:13.537817+0000 | compress | METRIC - error 48.85\n",
      "2025-12-02T19:23:13.538335+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:23:13.538814+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:23:13.539309+0000 | compress_modules | INFO - Quantizing model.layers.21.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:23:15.007452+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-02T19:23:15.008104+0000 | compress | METRIC - error 2.69\n",
      "2025-12-02T19:23:15.008779+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:23:15.009183+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:23:15.009776+0000 | compress_modules | INFO - Quantizing model.layers.21.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:23:16.482769+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-02T19:23:16.483535+0000 | compress | METRIC - error 0.05\n",
      "2025-12-02T19:23:16.484275+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:23:16.484640+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:23:16.485291+0000 | compress_modules | INFO - Quantizing model.layers.21.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:23:18.084457+0000 | compress | METRIC - time 1.60s\n",
      "2025-12-02T19:23:18.085335+0000 | compress | METRIC - error 33.63\n",
      "2025-12-02T19:23:18.085824+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:23:18.086271+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:23:18.086839+0000 | compress_modules | INFO - Quantizing model.layers.21.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:23:19.701426+0000 | compress | METRIC - time 1.61s\n",
      "2025-12-02T19:23:19.702179+0000 | compress | METRIC - error 13.16\n",
      "2025-12-02T19:23:19.702778+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:23:19.703246+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:23:19.703780+0000 | compress_modules | INFO - Quantizing model.layers.21.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:23:25.433598+0000 | compress | METRIC - time 5.73s\n",
      "2025-12-02T19:23:25.434370+0000 | compress | METRIC - error 0.36\n",
      "2025-12-02T19:23:25.435033+0000 | compress | METRIC - GPU 0 | usage: 90.69% | total memory: 48 GB\n",
      "2025-12-02T19:23:25.435389+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(22/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 88.94it/s]\n",
      "(23/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 36.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:23:45.469675+0000 | compress_modules | INFO - Quantizing model.layers.22.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:23:46.983553+0000 | compress | METRIC - time 1.51s\n",
      "2025-12-02T19:23:46.984200+0000 | compress | METRIC - error 51.83\n",
      "2025-12-02T19:23:46.984955+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:23:46.985439+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:23:46.985969+0000 | compress_modules | INFO - Quantizing model.layers.22.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:23:48.446488+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-02T19:23:48.447378+0000 | compress | METRIC - error 54.52\n",
      "2025-12-02T19:23:48.447965+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:23:48.448337+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:23:48.448928+0000 | compress_modules | INFO - Quantizing model.layers.22.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:23:49.927314+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-02T19:23:49.927993+0000 | compress | METRIC - error 2.86\n",
      "2025-12-02T19:23:49.928591+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:23:49.928978+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:23:49.929565+0000 | compress_modules | INFO - Quantizing model.layers.22.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:23:51.402619+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-02T19:23:51.403347+0000 | compress | METRIC - error 0.04\n",
      "2025-12-02T19:23:51.404015+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:23:51.404447+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:23:51.405145+0000 | compress_modules | INFO - Quantizing model.layers.22.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:23:52.993202+0000 | compress | METRIC - time 1.59s\n",
      "2025-12-02T19:23:52.993991+0000 | compress | METRIC - error 35.63\n",
      "2025-12-02T19:23:52.994646+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:23:52.995137+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:23:52.995639+0000 | compress_modules | INFO - Quantizing model.layers.22.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:23:54.583450+0000 | compress | METRIC - time 1.59s\n",
      "2025-12-02T19:23:54.584337+0000 | compress | METRIC - error 13.56\n",
      "2025-12-02T19:23:54.584989+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:23:54.585396+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:23:54.585968+0000 | compress_modules | INFO - Quantizing model.layers.22.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:24:00.137384+0000 | compress | METRIC - time 5.55s\n",
      "2025-12-02T19:24:00.138188+0000 | compress | METRIC - error 0.34\n",
      "2025-12-02T19:24:00.138817+0000 | compress | METRIC - GPU 0 | usage: 88.99% | total memory: 48 GB\n",
      "2025-12-02T19:24:00.139179+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(23/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 89.10it/s]\n",
      "(24/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 36.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:24:20.172086+0000 | compress_modules | INFO - Quantizing model.layers.23.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:24:21.662356+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-02T19:24:21.663050+0000 | compress | METRIC - error 51.13\n",
      "2025-12-02T19:24:21.663834+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:24:21.664234+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:24:21.664817+0000 | compress_modules | INFO - Quantizing model.layers.23.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:24:23.122125+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-02T19:24:23.122849+0000 | compress | METRIC - error 47.47\n",
      "2025-12-02T19:24:23.123453+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:24:23.123922+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:24:23.124415+0000 | compress_modules | INFO - Quantizing model.layers.23.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:24:24.582771+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-02T19:24:24.583517+0000 | compress | METRIC - error 2.73\n",
      "2025-12-02T19:24:24.584084+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:24:24.584452+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:24:24.585025+0000 | compress_modules | INFO - Quantizing model.layers.23.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:24:26.048613+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-02T19:24:26.049325+0000 | compress | METRIC - error 0.04\n",
      "2025-12-02T19:24:26.049994+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:24:26.050356+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:24:26.050933+0000 | compress_modules | INFO - Quantizing model.layers.23.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:24:27.642169+0000 | compress | METRIC - time 1.59s\n",
      "2025-12-02T19:24:27.643024+0000 | compress | METRIC - error 33.29\n",
      "2025-12-02T19:24:27.643573+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:24:27.643947+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:24:27.644486+0000 | compress_modules | INFO - Quantizing model.layers.23.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:24:29.233765+0000 | compress | METRIC - time 1.59s\n",
      "2025-12-02T19:24:29.234506+0000 | compress | METRIC - error 14.44\n",
      "2025-12-02T19:24:29.235211+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:24:29.235575+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:24:29.236155+0000 | compress_modules | INFO - Quantizing model.layers.23.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:24:34.771731+0000 | compress | METRIC - time 5.54s\n",
      "2025-12-02T19:24:34.772513+0000 | compress | METRIC - error 0.37\n",
      "2025-12-02T19:24:34.773276+0000 | compress | METRIC - GPU 0 | usage: 88.99% | total memory: 48 GB\n",
      "2025-12-02T19:24:34.773642+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(24/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 88.93it/s]\n",
      "(25/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 36.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:24:54.815589+0000 | compress_modules | INFO - Quantizing model.layers.24.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:24:56.312279+0000 | compress | METRIC - time 1.50s\n",
      "2025-12-02T19:24:56.313044+0000 | compress | METRIC - error 50.92\n",
      "2025-12-02T19:24:56.313761+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:24:56.314148+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:24:56.314734+0000 | compress_modules | INFO - Quantizing model.layers.24.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:24:57.768804+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-02T19:24:57.769439+0000 | compress | METRIC - error 47.75\n",
      "2025-12-02T19:24:57.770122+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:24:57.770561+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:24:57.771108+0000 | compress_modules | INFO - Quantizing model.layers.24.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:24:59.277166+0000 | compress | METRIC - time 1.51s\n",
      "2025-12-02T19:24:59.277902+0000 | compress | METRIC - error 3.96\n",
      "2025-12-02T19:24:59.278442+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:24:59.278821+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:24:59.279431+0000 | compress_modules | INFO - Quantizing model.layers.24.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:25:00.758792+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-02T19:25:00.759537+0000 | compress | METRIC - error 0.06\n",
      "2025-12-02T19:25:00.760207+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:25:00.760664+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:25:00.761201+0000 | compress_modules | INFO - Quantizing model.layers.24.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:25:02.384903+0000 | compress | METRIC - time 1.62s\n",
      "2025-12-02T19:25:02.385628+0000 | compress | METRIC - error 32.00\n",
      "2025-12-02T19:25:02.386362+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:25:02.386855+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:25:02.387366+0000 | compress_modules | INFO - Quantizing model.layers.24.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:25:04.007455+0000 | compress | METRIC - time 1.62s\n",
      "2025-12-02T19:25:04.008730+0000 | compress | METRIC - error 15.06\n",
      "2025-12-02T19:25:04.009539+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:25:04.009959+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:25:04.010616+0000 | compress_modules | INFO - Quantizing model.layers.24.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:25:09.537766+0000 | compress | METRIC - time 5.53s\n",
      "2025-12-02T19:25:09.538980+0000 | compress | METRIC - error 0.41\n",
      "2025-12-02T19:25:09.539777+0000 | compress | METRIC - GPU 0 | usage: 90.69% | total memory: 48 GB\n",
      "2025-12-02T19:25:09.540373+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(25/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 88.36it/s]\n",
      "(26/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 36.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:25:29.661911+0000 | compress_modules | INFO - Quantizing model.layers.25.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:25:31.194100+0000 | compress | METRIC - time 1.53s\n",
      "2025-12-02T19:25:31.195187+0000 | compress | METRIC - error 50.90\n",
      "2025-12-02T19:25:31.196087+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:25:31.196517+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:25:31.197179+0000 | compress_modules | INFO - Quantizing model.layers.25.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:25:32.688009+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-02T19:25:32.688985+0000 | compress | METRIC - error 39.29\n",
      "2025-12-02T19:25:32.689957+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:25:32.690446+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:25:32.691065+0000 | compress_modules | INFO - Quantizing model.layers.25.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:25:34.156778+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-02T19:25:34.157889+0000 | compress | METRIC - error 4.20\n",
      "2025-12-02T19:25:34.158525+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:25:34.159067+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:25:34.159624+0000 | compress_modules | INFO - Quantizing model.layers.25.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:25:35.640220+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-02T19:25:35.641528+0000 | compress | METRIC - error 0.06\n",
      "2025-12-02T19:25:35.642256+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:25:35.642797+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:25:35.643372+0000 | compress_modules | INFO - Quantizing model.layers.25.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:25:37.248165+0000 | compress | METRIC - time 1.60s\n",
      "2025-12-02T19:25:37.249331+0000 | compress | METRIC - error 32.90\n",
      "2025-12-02T19:25:37.250254+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:25:37.250667+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:25:37.251342+0000 | compress_modules | INFO - Quantizing model.layers.25.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:25:38.876167+0000 | compress | METRIC - time 1.62s\n",
      "2025-12-02T19:25:38.877387+0000 | compress | METRIC - error 16.40\n",
      "2025-12-02T19:25:38.878265+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:25:38.878790+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:25:38.879357+0000 | compress_modules | INFO - Quantizing model.layers.25.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:25:44.522198+0000 | compress | METRIC - time 5.64s\n",
      "2025-12-02T19:25:44.523281+0000 | compress | METRIC - error 0.47\n",
      "2025-12-02T19:25:44.524010+0000 | compress | METRIC - GPU 0 | usage: 88.99% | total memory: 48 GB\n",
      "2025-12-02T19:25:44.524426+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(26/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 88.01it/s]\n",
      "(27/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 35.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:26:04.784867+0000 | compress_modules | INFO - Quantizing model.layers.26.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:26:06.273414+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-02T19:26:06.274398+0000 | compress | METRIC - error 56.28\n",
      "2025-12-02T19:26:06.275184+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:26:06.275593+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:26:06.276249+0000 | compress_modules | INFO - Quantizing model.layers.26.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:26:07.731231+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-02T19:26:07.732326+0000 | compress | METRIC - error 52.20\n",
      "2025-12-02T19:26:07.733098+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:26:07.733511+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:26:07.734135+0000 | compress_modules | INFO - Quantizing model.layers.26.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:26:09.182175+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-02T19:26:09.183189+0000 | compress | METRIC - error 2.98\n",
      "2025-12-02T19:26:09.184044+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:26:09.184561+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:26:09.185141+0000 | compress_modules | INFO - Quantizing model.layers.26.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:26:10.647440+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-02T19:26:10.648559+0000 | compress | METRIC - error 0.17\n",
      "2025-12-02T19:26:10.649252+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:26:10.649645+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:26:10.650288+0000 | compress_modules | INFO - Quantizing model.layers.26.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:26:12.220854+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-02T19:26:12.221919+0000 | compress | METRIC - error 35.44\n",
      "2025-12-02T19:26:12.222594+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:26:12.223009+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:26:12.223637+0000 | compress_modules | INFO - Quantizing model.layers.26.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:26:13.793274+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-02T19:26:13.794485+0000 | compress | METRIC - error 17.92\n",
      "2025-12-02T19:26:13.795310+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:26:13.795755+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:26:13.796431+0000 | compress_modules | INFO - Quantizing model.layers.26.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:26:19.311372+0000 | compress | METRIC - time 5.51s\n",
      "2025-12-02T19:26:19.312636+0000 | compress | METRIC - error 0.51\n",
      "2025-12-02T19:26:19.313345+0000 | compress | METRIC - GPU 0 | usage: 88.99% | total memory: 48 GB\n",
      "2025-12-02T19:26:19.313881+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(27/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 87.82it/s]\n",
      "(28/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 35.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:26:39.703805+0000 | compress_modules | INFO - Quantizing model.layers.27.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:26:41.197561+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-02T19:26:41.198587+0000 | compress | METRIC - error 52.21\n",
      "2025-12-02T19:26:41.199606+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:26:41.200149+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:26:41.200740+0000 | compress_modules | INFO - Quantizing model.layers.27.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:26:42.642158+0000 | compress | METRIC - time 1.44s\n",
      "2025-12-02T19:26:42.643224+0000 | compress | METRIC - error 47.23\n",
      "2025-12-02T19:26:42.643953+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:26:42.644448+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:26:42.645032+0000 | compress_modules | INFO - Quantizing model.layers.27.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:26:44.101359+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-02T19:26:44.102420+0000 | compress | METRIC - error 6.52\n",
      "2025-12-02T19:26:44.103115+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:26:44.103541+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:26:44.104190+0000 | compress_modules | INFO - Quantizing model.layers.27.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:26:45.563419+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-02T19:26:45.564486+0000 | compress | METRIC - error 0.20\n",
      "2025-12-02T19:26:45.565086+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:26:45.565658+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:26:45.566256+0000 | compress_modules | INFO - Quantizing model.layers.27.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:26:47.113974+0000 | compress | METRIC - time 1.55s\n",
      "2025-12-02T19:26:47.115212+0000 | compress | METRIC - error 39.57\n",
      "2025-12-02T19:26:47.115919+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:26:47.116410+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:26:47.116995+0000 | compress_modules | INFO - Quantizing model.layers.27.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:26:48.671284+0000 | compress | METRIC - time 1.55s\n",
      "2025-12-02T19:26:48.672519+0000 | compress | METRIC - error 21.30\n",
      "2025-12-02T19:26:48.673252+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:26:48.673637+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:26:48.674301+0000 | compress_modules | INFO - Quantizing model.layers.27.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:26:54.188732+0000 | compress | METRIC - time 5.51s\n",
      "2025-12-02T19:26:54.190085+0000 | compress | METRIC - error 0.73\n",
      "2025-12-02T19:26:54.190866+0000 | compress | METRIC - GPU 0 | usage: 90.69% | total memory: 48 GB\n",
      "2025-12-02T19:26:54.191291+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(28/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 87.69it/s]\n",
      "(29/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 34.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:27:14.789428+0000 | compress_modules | INFO - Quantizing model.layers.28.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:27:16.289006+0000 | compress | METRIC - time 1.50s\n",
      "2025-12-02T19:27:16.289624+0000 | compress | METRIC - error 53.02\n",
      "2025-12-02T19:27:16.290450+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:27:16.290869+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:27:16.291445+0000 | compress_modules | INFO - Quantizing model.layers.28.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:27:17.791781+0000 | compress | METRIC - time 1.50s\n",
      "2025-12-02T19:27:17.792440+0000 | compress | METRIC - error 42.16\n",
      "2025-12-02T19:27:17.793156+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:27:17.793517+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:27:17.794131+0000 | compress_modules | INFO - Quantizing model.layers.28.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:27:19.274549+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-02T19:27:19.275414+0000 | compress | METRIC - error 3.54\n",
      "2025-12-02T19:27:19.275951+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:27:19.276432+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:27:19.277021+0000 | compress_modules | INFO - Quantizing model.layers.28.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:27:20.768788+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-02T19:27:20.769660+0000 | compress | METRIC - error 0.33\n",
      "2025-12-02T19:27:20.770343+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:27:20.770733+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:27:20.771321+0000 | compress_modules | INFO - Quantizing model.layers.28.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:27:22.371850+0000 | compress | METRIC - time 1.60s\n",
      "2025-12-02T19:27:22.372550+0000 | compress | METRIC - error 44.12\n",
      "2025-12-02T19:27:22.373368+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:27:22.373837+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:27:22.374357+0000 | compress_modules | INFO - Quantizing model.layers.28.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:27:23.991446+0000 | compress | METRIC - time 1.62s\n",
      "2025-12-02T19:27:23.992201+0000 | compress | METRIC - error 23.79\n",
      "2025-12-02T19:27:23.992922+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:27:23.993383+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:27:23.993917+0000 | compress_modules | INFO - Quantizing model.layers.28.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:27:29.530250+0000 | compress | METRIC - time 5.54s\n",
      "2025-12-02T19:27:29.531162+0000 | compress | METRIC - error 0.97\n",
      "2025-12-02T19:27:29.531835+0000 | compress | METRIC - GPU 0 | usage: 88.99% | total memory: 48 GB\n",
      "2025-12-02T19:27:29.532352+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(29/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 88.88it/s]\n",
      "(30/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 35.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:27:49.753386+0000 | compress_modules | INFO - Quantizing model.layers.29.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:27:51.242535+0000 | compress | METRIC - time 1.49s\n",
      "2025-12-02T19:27:51.243185+0000 | compress | METRIC - error 45.49\n",
      "2025-12-02T19:27:51.244060+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:27:51.244574+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:27:51.245159+0000 | compress_modules | INFO - Quantizing model.layers.29.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:27:52.689673+0000 | compress | METRIC - time 1.44s\n",
      "2025-12-02T19:27:52.690645+0000 | compress | METRIC - error 34.66\n",
      "2025-12-02T19:27:52.691534+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:27:52.692078+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:27:52.692637+0000 | compress_modules | INFO - Quantizing model.layers.29.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:27:54.147652+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-02T19:27:54.148522+0000 | compress | METRIC - error 5.23\n",
      "2025-12-02T19:27:54.149440+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:27:54.149878+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:27:54.150484+0000 | compress_modules | INFO - Quantizing model.layers.29.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:27:55.608518+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-02T19:27:55.609520+0000 | compress | METRIC - error 0.65\n",
      "2025-12-02T19:27:55.610235+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:27:55.610748+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:27:55.611312+0000 | compress_modules | INFO - Quantizing model.layers.29.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:27:57.157981+0000 | compress | METRIC - time 1.55s\n",
      "2025-12-02T19:27:57.159148+0000 | compress | METRIC - error 46.57\n",
      "2025-12-02T19:27:57.159966+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:27:57.160494+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:27:57.161090+0000 | compress_modules | INFO - Quantizing model.layers.29.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:27:58.715242+0000 | compress | METRIC - time 1.55s\n",
      "2025-12-02T19:27:58.716118+0000 | compress | METRIC - error 27.77\n",
      "2025-12-02T19:27:58.716897+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:27:58.717423+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:27:58.718005+0000 | compress_modules | INFO - Quantizing model.layers.29.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:28:04.243186+0000 | compress | METRIC - time 5.52s\n",
      "2025-12-02T19:28:04.244585+0000 | compress | METRIC - error 1.52\n",
      "2025-12-02T19:28:04.245193+0000 | compress | METRIC - GPU 0 | usage: 88.99% | total memory: 48 GB\n",
      "2025-12-02T19:28:04.245609+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(30/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 89.16it/s]\n",
      "(31/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 35.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:28:24.399616+0000 | compress_modules | INFO - Quantizing model.layers.30.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:28:25.883535+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-02T19:28:25.884688+0000 | compress | METRIC - error 60.39\n",
      "2025-12-02T19:28:25.885537+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:28:25.886127+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:28:25.886733+0000 | compress_modules | INFO - Quantizing model.layers.30.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:28:27.323413+0000 | compress | METRIC - time 1.44s\n",
      "2025-12-02T19:28:27.324368+0000 | compress | METRIC - error 56.28\n",
      "2025-12-02T19:28:27.325017+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:28:27.325519+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:28:27.326101+0000 | compress_modules | INFO - Quantizing model.layers.30.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:28:28.778763+0000 | compress | METRIC - time 1.45s\n",
      "2025-12-02T19:28:28.779634+0000 | compress | METRIC - error 8.59\n",
      "2025-12-02T19:28:28.780510+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:28:28.781028+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:28:28.781587+0000 | compress_modules | INFO - Quantizing model.layers.30.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:28:30.250421+0000 | compress | METRIC - time 1.47s\n",
      "2025-12-02T19:28:30.251469+0000 | compress | METRIC - error 0.68\n",
      "2025-12-02T19:28:30.252123+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:28:30.252522+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:28:30.253178+0000 | compress_modules | INFO - Quantizing model.layers.30.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:28:31.802093+0000 | compress | METRIC - time 1.55s\n",
      "2025-12-02T19:28:31.803349+0000 | compress | METRIC - error 55.96\n",
      "2025-12-02T19:28:31.804016+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:28:31.804415+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:28:31.805058+0000 | compress_modules | INFO - Quantizing model.layers.30.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:28:33.357771+0000 | compress | METRIC - time 1.55s\n",
      "2025-12-02T19:28:33.358796+0000 | compress | METRIC - error 33.57\n",
      "2025-12-02T19:28:33.359748+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:28:33.360266+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:28:33.360883+0000 | compress_modules | INFO - Quantizing model.layers.30.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:28:38.873590+0000 | compress | METRIC - time 5.51s\n",
      "2025-12-02T19:28:38.874681+0000 | compress | METRIC - error 3.14\n",
      "2025-12-02T19:28:38.875404+0000 | compress | METRIC - GPU 0 | usage: 90.69% | total memory: 48 GB\n",
      "2025-12-02T19:28:38.875965+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(31/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 89.51it/s]\n",
      "(32/33): Calibrating: 100%|██████████| 512/512 [00:14<00:00, 35.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:28:58.965532+0000 | compress_modules | INFO - Quantizing model.layers.31.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:29:00.465687+0000 | compress | METRIC - time 1.50s\n",
      "2025-12-02T19:29:00.466953+0000 | compress | METRIC - error 41.52\n",
      "2025-12-02T19:29:00.467663+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:29:00.468104+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:29:00.468729+0000 | compress_modules | INFO - Quantizing model.layers.31.self_attn.k_proj using 512 samples\n",
      "2025-12-02T19:29:01.924286+0000 | compress | METRIC - time 1.46s\n",
      "2025-12-02T19:29:01.925151+0000 | compress | METRIC - error 28.77\n",
      "2025-12-02T19:29:01.925676+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:29:01.926058+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:29:01.926618+0000 | compress_modules | INFO - Quantizing model.layers.31.self_attn.v_proj using 512 samples\n",
      "2025-12-02T19:29:03.406542+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-02T19:29:03.407299+0000 | compress | METRIC - error 6.81\n",
      "2025-12-02T19:29:03.408070+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:29:03.408463+0000 | compress | METRIC - Compressed module size: 8.39168 MB\n",
      "2025-12-02T19:29:03.409036+0000 | compress_modules | INFO - Quantizing model.layers.31.self_attn.o_proj using 512 samples\n",
      "2025-12-02T19:29:04.884571+0000 | compress | METRIC - time 1.48s\n",
      "2025-12-02T19:29:04.885308+0000 | compress | METRIC - error 1.50\n",
      "2025-12-02T19:29:04.886079+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:29:04.886484+0000 | compress | METRIC - Compressed module size: 33.56672 MB\n",
      "2025-12-02T19:29:04.887081+0000 | compress_modules | INFO - Quantizing model.layers.31.mlp.gate_proj using 512 samples\n",
      "2025-12-02T19:29:06.439529+0000 | compress | METRIC - time 1.55s\n",
      "2025-12-02T19:29:06.440301+0000 | compress | METRIC - error 51.20\n",
      "2025-12-02T19:29:06.440982+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:29:06.441507+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:29:06.442033+0000 | compress_modules | INFO - Quantizing model.layers.31.mlp.up_proj using 512 samples\n",
      "2025-12-02T19:29:08.009052+0000 | compress | METRIC - time 1.57s\n",
      "2025-12-02T19:29:08.009842+0000 | compress | METRIC - error 71.93\n",
      "2025-12-02T19:29:08.010509+0000 | compress | METRIC - GPU 0 | usage: 87.28% | total memory: 48 GB\n",
      "2025-12-02T19:29:08.010984+0000 | compress | METRIC - Compressed module size: 117.48352 MB\n",
      "2025-12-02T19:29:08.011503+0000 | compress_modules | INFO - Quantizing model.layers.31.mlp.down_proj using 512 samples\n",
      "2025-12-02T19:29:13.576293+0000 | compress | METRIC - time 5.56s\n",
      "2025-12-02T19:29:13.577521+0000 | compress | METRIC - error 26.14\n",
      "2025-12-02T19:29:13.578266+0000 | compress | METRIC - GPU 0 | usage: 88.99% | total memory: 48 GB\n",
      "2025-12-02T19:29:13.578682+0000 | compress | METRIC - Compressed module size: 117.4528 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(32/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 87.24it/s]\n",
      "(33/33): Calibrating: 100%|██████████| 512/512 [00:05<00:00, 87.82it/s]\n",
      "(33/33): Propagating: 100%|██████████| 512/512 [00:05<00:00, 87.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T19:29:31.494022+0000 | finalize | INFO - Compression lifecycle finalized for 2 modifiers\n",
      "2025-12-02T19:29:31.538355+0000 | get_model_compressor | INFO - skip_sparsity_compression_stats set to True. Skipping sparsity compression statistic calculations. No sparsity compressor will be applied.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compressing model: 77it [00:00, 107.74it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the quantization scheme\n",
    "scheme = \"W8A8\"  # W8A8 means 8-bit weights and 8-bit activations\n",
    "\n",
    "# Strength for SmoothQuant smoothing\n",
    "# This controls how much the activation values are smoothed to reduce outliers\n",
    "smoothing_strength = 0.8\n",
    "\n",
    "# Create SmoothQuant modifier\n",
    "# - smooths activations before quantization to improve stability and reduce degradation\n",
    "smooth_quant = SmoothQuantModifier(smoothing_strength=smoothing_strength)\n",
    "\n",
    "# Create GPTQ modifier\n",
    "# - targets=\"Linear\" quantizes only Linear layers (e.g., feedforward layers)\n",
    "# - scheme=scheme uses the W8A8 quantization scheme\n",
    "# - ignore=[\"lm_head\"] preserves the LM head to avoid generation quality loss\n",
    "quantizer = GPTQModifier(targets=\"Linear\", scheme=scheme, ignore=[\"lm_head\"])\n",
    "\n",
    "# Combine the modifiers into a recipe list\n",
    "# The order matters: first apply SmoothQuant, then GPTQ\n",
    "recipe = [\n",
    "    smooth_quant,\n",
    "    quantizer\n",
    "]\n",
    "\n",
    "# Perform quantization\n",
    "oneshot(\n",
    "    model=model_name,                # Model to quantize\n",
    "    dataset=ds,                      # Calibration dataset, used for both SmoothQuant & GPTQ\n",
    "    recipe=recipe,                    # List of quantization modifiers to apply\n",
    "    output_dir=compressed_model_path, # Directory to save the quantized model\n",
    "    max_seq_length=2048,              # Maximum sequence length for calibration\n",
    "    num_calibration_samples=512       # Number of samples used for calibration\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56836404-daab-4638-8abf-957b71f82507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 16.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (GB): 8.460090637207031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load quantized model\n",
    "model_quant = AutoModelForCausalLM.from_pretrained(compressed_model_path)\n",
    "model_size = model_size_gb(model_quant)\n",
    "print(f\"Model size (GB): {model_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e882026b-2c4c-4e1f-b20f-75fdaf71b7f3",
   "metadata": {},
   "source": [
    "### Observation\n",
    "After quantizing the model, the size has clearly reduced from 14GB to 7GB. Now that we have reduced the model size, the next step is to evaluate this compressed model to make sure the accuracy has retained after compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "abce1338-97f8-4ef3-8f6f-29f883ffb22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qwen 1.5b (dtype = not defined)\n",
    "    # base model size = 5GB\n",
    "    # compressed model(8bit) = 2.1\n",
    "\n",
    "# qwen 1.5b (dtype = 16bit)\n",
    "    # base model size = 2.9GB\n",
    "    # compressed model(8bit) = 2.1\n",
    "\n",
    "# qwen 1.5b (dtype = auto)\n",
    "    # base model size = 2.9GB\n",
    "\n",
    "# lama 1b (dtype = not defined)\n",
    "    # base model size = 4.0980GB\n",
    "    # compressed model(8bit) = \n",
    "\n",
    "# lama 1b (dtype = auto)\n",
    "    # base model size = 2.05GB\n",
    "    # compressed model(8bit) = \n",
    "\n",
    "# lama 1b (dtype = 16bit)\n",
    "    # base model size = 2.05GB\n",
    "    # compressed model(8bit) = 1.147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b228e92e-95e6-4a8c-a1e4-0c59a25b4d31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
